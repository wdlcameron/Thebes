{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from math import isinf\n",
    "from statistics import mean\n",
    "import argparse\n",
    "import torch\n",
    "import visdom\n",
    "import numpy as np\n",
    "import brambox.boxes as bbb\n",
    "import lightnet as ln\n",
    "from lightnet.engine import Engine\n",
    "from dataset import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[37mINFO      \u001b[00m Loaded weights from C:\\Users\\William\\Desktop\\Lightnet\\examples\\yolo-voc\\backup\\final.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training False\n",
      "Taking this path!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[37mINFO      \u001b[00m C:\\Users\\William\\Desktop\\Lightnet\\examples\\basic\\dog.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got to here C:\\Users\\William\\Desktop\\Lightnet\\examples\\basic\\dog.jpg\n",
      "576 768\n",
      "<class 'numpy.ndarray'>\n",
      "(576, 768, 3) <class 'torch.Tensor'>\n",
      "[Detection {class_label = car, object_id = None, x = 475.36076670040484, y = 83.28681680161944, w = 199.27805541497975, h = 83.75262525303644, confidence = 0.8246340751647949}, Detection {class_label = dog, object_id = None, x = 147.62779921558703, y = 256.20344129554655, w = 158.6321799089069, h = 197.98650999493927, confidence = 0.6342375874519348}, Detection {class_label = motorbike, object_id = None, x = 61.96438512145749, y = 82.2682818825911, w = 48.649050322621456, h = 44.451824234564775, confidence = 0.6162376403808594}, Detection {class_label = aeroplane, object_id = None, x = 485.48589321862346, y = 372.2284286437247, w = 278.7211222165992, h = 195.79989562246965, confidence = 0.49685728549957275}, Detection {class_label = car, object_id = None, x = 518.3626012145749, y = 194.49772267206478, w = 217.60414030870444, h = 195.60978618421052, confidence = 0.35590022802352905}, Detection {class_label = chair, object_id = None, x = 25.27684558451417, y = 231.60096153846155, w = 166.05849886133603, h = 181.2746710526316, confidence = 0.31922152638435364}, Detection {class_label = bicycle, object_id = None, x = 325.1938259109312, y = 243.73633603238866, w = 235.59956983805668, h = 148.7503479251012, confidence = 0.29254579544067383}, Detection {class_label = person, object_id = None, x = 727.0229630566802, y = 384.54611589068827, w = 34.41884251644737, h = 176.51072241902835, confidence = 0.2901047468185425}, Detection {class_label = pottedplant, object_id = None, x = 446.37664473684214, y = 2.9048266700404857, w = 62.322834956983804, h = 76.05566801619433, confidence = 0.26978766918182373}, Detection {class_label = motorbike, object_id = None, x = 54.65464480010122, y = 92.85741396761134, w = 45.969947969382595, h = 53.47074661563765, confidence = 0.24280355870723724}, Detection {class_label = bicycle, object_id = None, x = 256.79276315789474, y = 199.93984058704453, w = 204.7290612348178, h = 172.26565662955466, confidence = 0.2413043975830078}, Detection {class_label = bicycle, object_id = None, x = 169.61731401821862, y = 99.64280743927125, w = 177.71652011639677, h = 213.55305857793522, confidence = 0.23483969271183014}, Detection {class_label = person, object_id = None, x = 52.4722608805668, y = 66.52524038461539, w = 51.70707869433198, h = 52.793731813006076, confidence = 0.23210664093494415}, Detection {class_label = motorbike, object_id = None, x = 687.7070470647774, y = -0.03352732793522267, w = 46.363474981022264, h = 16.696553960020243, confidence = 0.21891872584819794}, Detection {class_label = pottedplant, object_id = None, x = 535.544850708502, y = 11.459261133603238, w = 85.40636861082996, h = 95.87260406123482, confidence = 0.20989990234375}]\n",
      "199.27805541497975\n",
      "X: 475.36076670040484, Y: 83.28681680161944, Width: 199.27805541497975, Height: 83.75262525303644 car, None\n",
      "X: 147.62779921558703, Y: 256.20344129554655, Width: 158.6321799089069, Height: 197.98650999493927 dog, None\n",
      "X: 61.96438512145749, Y: 82.2682818825911, Width: 48.649050322621456, Height: 44.451824234564775 motorbike, None\n",
      "X: 485.48589321862346, Y: 372.2284286437247, Width: 278.7211222165992, Height: 195.79989562246965 aeroplane, None\n",
      "X: 518.3626012145749, Y: 194.49772267206478, Width: 217.60414030870444, Height: 195.60978618421052 car, None\n",
      "X: 25.27684558451417, Y: 231.60096153846155, Width: 166.05849886133603, Height: 181.2746710526316 chair, None\n",
      "X: 325.1938259109312, Y: 243.73633603238866, Width: 235.59956983805668, Height: 148.7503479251012 bicycle, None\n",
      "X: 727.0229630566802, Y: 384.54611589068827, Width: 34.41884251644737, Height: 176.51072241902835 person, None\n",
      "X: 446.37664473684214, Y: 2.9048266700404857, Width: 62.322834956983804, Height: 76.05566801619433 pottedplant, None\n",
      "X: 54.65464480010122, Y: 92.85741396761134, Width: 45.969947969382595, Height: 53.47074661563765 motorbike, None\n",
      "X: 256.79276315789474, Y: 199.93984058704453, Width: 204.7290612348178, Height: 172.26565662955466 bicycle, None\n",
      "X: 169.61731401821862, Y: 99.64280743927125, Width: 177.71652011639677, Height: 213.55305857793522 bicycle, None\n",
      "X: 52.4722608805668, Y: 66.52524038461539, Width: 51.70707869433198, Height: 52.793731813006076 person, None\n",
      "X: 687.7070470647774, Y: -0.03352732793522267, Width: 46.363474981022264, Height: 16.696553960020243 motorbike, None\n",
      "X: 535.544850708502, Y: 11.459261133603238, Width: 85.40636861082996, Height: 95.87260406123482 pottedplant, None\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#\n",
    "#   Copyright EAVISE\n",
    "#   Example: Perform a single image detection with the Lightnet tiny yolo network\n",
    "#\n",
    "\"\"\"\n",
    "Detection Module!!\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "import brambox.boxes as bbb\n",
    "import lightnet as ln\n",
    "\n",
    "\n",
    "import javabridge \n",
    "import bioformats\n",
    "javabridge.start_vm(class_path=bioformats.JARS, max_heap_size='8G')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "log = logging.getLogger('lightnet.detect')\n",
    "\n",
    "# Parameters\n",
    "CLASSES = 20\n",
    "#NETWORK_SIZE = (416, 416)\n",
    "NETWORK_SIZE = (1482, 2535)\n",
    "LABELS = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "          'bus', 'car', 'cat', 'chair', 'cow',\n",
    "          'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "          'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "CONF_THRESH = .20\n",
    "NMS_THRESH = .4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Functions\n",
    "\n",
    "def post_transform(boxes, scale, pad):\n",
    "    for box in boxes:\n",
    "        box.x_top_left -= pad[0]\n",
    "        box.y_top_left -= pad[1]\n",
    "\n",
    "        box.x_top_left *= scale\n",
    "        box.y_top_left *= scale\n",
    "        box.width *= scale\n",
    "        box.height *= scale\n",
    "    return boxes\n",
    "\n",
    "\n",
    "\n",
    "def create_network(weights):\n",
    "    \"\"\" Create the lightnet network \"\"\"\n",
    "    net = ln.models.Yolo(CLASSES, \n",
    "                         conf_thresh = CONF_THRESH,\n",
    "                         nms_thresh = NMS_THRESH,)\n",
    "    \n",
    "    net.postprocess.append(ln.data.transform.TensorToBrambox(NETWORK_SIZE, LABELS))\n",
    "    net.load(weights)\n",
    "    \n",
    "    net = net.to(device)\n",
    "    return net\n",
    "\n",
    "\n",
    "def detect(net, img_path):\n",
    "    \"\"\" Perform a detection \"\"\"\n",
    "    # Load image\n",
    "    print (\"Got to here\", img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    im_h, im_w = img.shape[:2]\n",
    "    \n",
    "    print (im_h, im_w)\n",
    "\n",
    "    img_tf = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_tf = ln.data.transform.Letterbox.apply(img_tf, dimension=NETWORK_SIZE)\n",
    "    print (type(img_tf))\n",
    "    img_tf = tf.ToTensor()(img_tf)\n",
    "    img_tf.unsqueeze_(0)\n",
    "    img_tf = img_tf.to(device)\n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    filepath = \"C://Users//William//Desktop//Box Testing Baseline//Baseline_1//Baseline_1_MMStack_1-Pos_000_002.ome.tif\"\n",
    "    \n",
    "    image_open = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=3, rescale=False))\n",
    "    image_para = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=4, rescale=False))\n",
    "    image_perp = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=5, rescale=False))\n",
    "    \n",
    "    img = np.dstack([image_open, image_para, image_perp])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img/np.amax(img)\n",
    "    img = img*255\n",
    "    img = img.astype('uint8')\n",
    "    \n",
    "    im_h, im_w = img.shape[:2]\n",
    "    img_tf = ln.data.transform.Letterbox.apply(img, dimension = NETWORK_SIZE)\n",
    "    img_tf = tf.ToTensor()(img_tf)\n",
    "    img_tf.unsqueeze_(0)\n",
    "    img_tf = img_tf.to(device)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    print (img.shape, type(img_tf))\n",
    "\n",
    "    # Run detector\n",
    "    with torch.no_grad():\n",
    "        out = net(img_tf)\n",
    "        \n",
    "    #print (out)\n",
    "    #out = ln.data.transform.ReverseLetterbox.apply(out, NETWORK_SIZE, (im_w, im_h)) # Resize bb to true image dimensions\n",
    "    #tsfm = ln.data.transform.ReverseLetterbox(network_size = NETWORK_SIZE, image_size = (im_w, im_h))\n",
    "    \n",
    "    #print (tsfm.apply({\"data\": out, \"network_size\" : NETWORK_SIZE, \"image_size\" : (im_w, im_h)}, network_size = NETWORK_SIZE, image_size = (im_w, im_h)))\n",
    "    \n",
    "    net_w, net_h = NETWORK_SIZE\n",
    "\n",
    "    if im_w == net_w and im_h == net_h:\n",
    "        scale = 1\n",
    "    elif im_w / net_w >= im_h / net_h:\n",
    "        scale = im_w/net_w\n",
    "    else:\n",
    "        scale = im_h/net_h\n",
    "        \n",
    "    pad = int((net_w - im_w/scale) / 2), int((net_h - im_h/scale) / 2)\n",
    "\n",
    "    converted_boxes = []\n",
    "    for b in out:\n",
    "        converted_boxes.append(post_transform(b, scale, pad))\n",
    "    \n",
    "    out = converted_boxes\n",
    "    #print (converted_boxes)\n",
    "\n",
    "    return img, out\n",
    "\n",
    "\n",
    "\n",
    "def output_ROIs (detections):\n",
    "    for ROIs in detections:\n",
    "        print (f'X: {ROIs.x_top_left}, Y: {ROIs.y_top_left}, Width: {ROIs.width}, Height: {ROIs.height} {ROIs.class_label}, {ROIs.object_id}')\n",
    "\n",
    "\n",
    "# Main\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"parser = argparse.ArgumentParser(description='Run an image through the lightnet yolo network')\n",
    "    parser.add_argument('weight', help='Path to weight file')\n",
    "    parser.add_argument('image', help='Path to image file(s)', nargs='*')\n",
    "    parser.add_argument('-c', '--cuda', action='store_true', help='Use cuda')\n",
    "    parser.add_argument('-s', '--save', action='store_true', help='Save image in stead of displaying it')\n",
    "    parser.add_argument('-l', '--label', action='store_true', help='Print labels and scores on the image')\n",
    "    args = parser.parse_args()\n",
    "    \"\"\"\n",
    "    \n",
    "    #Dog\n",
    "    image_path = [f\"C:{os.sep}Users{os.sep}William{os.sep}Desktop{os.sep}Lightnet{os.sep}examples{os.sep}basic{os.sep}dog.jpg\"]\n",
    "    #weights_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Desktop{os.sep}Lightnet{os.sep}examples{os.sep}weights{os.sep}darknet19_448.conv.23.pt\"\n",
    "    \n",
    "    #image_path = [f\"C:{os.sep}Users{os.sep}William{os.sep}Desktop{os.sep}Box Testing Baseline{os.sep}JPEGImages{os.sep}Baseline_1{os.sep}Baseline_1_MMStack_1-Pos_000_00003.jpg\"]\n",
    "    weights_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Desktop{os.sep}Lightnet{os.sep}examples{os.sep}yolo-voc{os.sep}backup{os.sep}final.pt\"\n",
    "    \n",
    "    save_check = False\n",
    "    show_label = True\n",
    "    \n",
    "    \n",
    "    use_cuda = True\n",
    "    \n",
    "    \n",
    "    # Parse Arguments\n",
    "    device = torch.device('cpu')\n",
    "    if use_cuda:\n",
    "        if torch.cuda.is_available():\n",
    "            log.debug('CUDA enabled')\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            log.error('CUDA not available')\n",
    "\n",
    "    # Network\n",
    "    network = create_network(weights_path)\n",
    "    #print(network)\n",
    "    #print()\n",
    "    network.training = False\n",
    "    print(\"Training\", network.training)\n",
    "    \n",
    "    \n",
    "    # Detection\n",
    "    if len(image_path) > 0:\n",
    "        print(\"Taking this path!\")\n",
    "        for img_name in image_path:\n",
    "            log.info(img_name)\n",
    "            image, output = detect(network, img_name)\n",
    "            \n",
    "            print (output[0])\n",
    "            print (output[0][0].width)\n",
    "            output_ROIs(output[0])\n",
    "\n",
    "            image = bbb.draw_boxes(image, output[0], show_labels=show_label)\n",
    "            \n",
    "            #image = cv2.rectangle(image, (0,200),(10,500),(255,0,0), 20)\n",
    "            if save_check:\n",
    "                cv2.imwrite('detections.png', image)\n",
    "            else:\n",
    "                cv2.imshow('image', image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "    else:\n",
    "        log.error('Invalid file path')\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                img_path = input('Enter image path: ')    \n",
    "            except (KeyboardInterrupt, EOFError):\n",
    "                print('')\n",
    "                break\n",
    "        \n",
    "            if not os.path.isfile(img_path):\n",
    "                log.error(f'\\'{img_path}\\' is not a valid path')\n",
    "                break\n",
    "\n",
    "            image, output = detect(network, img_path)\n",
    "            image = bbb.draw_boxes(image, output[0], show_labels=show_labels)\n",
    "            if save_check:\n",
    "                cv2.imwrite('detections.png', image)\n",
    "            else:\n",
    "                cv2.imshow('image', image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "            \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger('lightnet.VOC.train')\n",
    "\n",
    "\n",
    "class TrainEngine(Engine):\n",
    "    def start(self):\n",
    "        self.params.to(self.device)\n",
    "        if self.valid_loader is not None:\n",
    "            self.epoch_end()(self.test)\n",
    "\n",
    "        self.train_loss = {'tot': [], 'coord': [], 'conf': [], 'cls': []}\n",
    "        self.plot_train_loss = ln.engine.LinePlotter(self.visdom, 'train_loss', opts=dict(xlabel='Batch', ylabel='Loss', title='Training Loss', showlegend=True, legend=['Total loss', 'Coordinate loss', 'Confidence loss', 'Class loss']))\n",
    "        self.plot_valid_loss = ln.engine.LinePlotter(self.visdom, 'valid_loss', name='Total loss', opts=dict(xlabel='Batch', ylabel='Loss', title='Validation Loss', showlegend=True))\n",
    "        self.plot_lr = ln.engine.LinePlotter(self.visdom, 'learning_rate', name='Learning Rate', opts=dict(xlabel='Batch', ylabel='Learning Rate', title='Learning Rate Schedule'))\n",
    "        self.plot_valid_pr = ln.engine.LinePlotter(self.visdom, 'valid_pr', name='latest', opts=dict(xlabel='Recall', ylabel='Precision', title='Validation PR', xtickmin=0, xtickmax=1, ytickmin=0, ytickmax=1, showlegend=True))\n",
    "        self.best_map = 0\n",
    "\n",
    "        self.dataloader.change_input_dim()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def process_batch(self, data):\n",
    "        data, target = data\n",
    "        data = data.to(self.device)\n",
    "\n",
    "        loss = self.network(data, target)\n",
    "        loss.backward()\n",
    "\n",
    "        self.train_loss['tot'].append(self.network.loss.loss_tot.item())\n",
    "        self.train_loss['coord'].append(self.network.loss.loss_coord.item())\n",
    "        self.train_loss['conf'].append(self.network.loss.loss_conf.item())\n",
    "        self.train_loss['cls'].append(self.network.loss.loss_cls.item())\n",
    "\n",
    "    def train_batch(self):\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        tot = mean(self.train_loss['tot'])\n",
    "        coord = mean(self.train_loss['coord'])\n",
    "        conf = mean(self.train_loss['conf'])\n",
    "        cls = mean(self.train_loss['cls'])\n",
    "        self.train_loss = {'tot': [], 'coord': [], 'conf': [], 'cls': []}\n",
    "\n",
    "        self.plot_train_loss(np.array([[tot, coord, conf, cls]]), np.array([self.batch]))\n",
    "        self.log(f'{self.batch} Loss:{tot:.5f} (Coord:{coord:.2f} Conf:{conf:.2f} Cls:{cls:.2f})')\n",
    "\n",
    "        if isinf(tot):\n",
    "            log.error('Infinite loss')\n",
    "            self.sigint = True\n",
    "            return\n",
    "\n",
    "        self.scheduler.step(self.batch, epoch=self.batch)\n",
    "        self.plot_lr(np.array([self.optimizer.param_groups[0]['lr'] * self.batch_size]), np.array([self.batch]))\n",
    "\n",
    "    @Engine.batch_end(5000)\n",
    "    def backup(self):\n",
    "        self.params.save(os.path.join(self.backup_folder, f'weights_{self.batch}.state.pt'))\n",
    "        log.info(f'Saved backup')\n",
    "\n",
    "    @Engine.batch_end(10)\n",
    "    def resize(self):\n",
    "        self.dataloader.change_input_dim()\n",
    "\n",
    "    def test(self):\n",
    "        log.info('Start testing')\n",
    "        self.network.eval()\n",
    "        tot_loss = 0\n",
    "        anno, det = {}, {}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, (data, target) in enumerate(self.valid_loader):\n",
    "                data = data.to(self.device)\n",
    "                output, loss = self.network(data, target)\n",
    "                tot_loss += loss.item()*len(target)\n",
    "\n",
    "                key_val = len(anno)\n",
    "                anno.update({key_val+k: v for k,v in enumerate(target)})\n",
    "                det.update({key_val+k: v for k,v in enumerate(output)})\n",
    "\n",
    "                if self.sigint:\n",
    "                    self.network.train()\n",
    "                    return\n",
    "\n",
    "        pr = bbb.pr(det, anno)\n",
    "        m_ap = round(bbb.ap(*pr)*100, 2)\n",
    "        loss = tot_loss/len(anno)\n",
    "        self.log(f'Loss:{loss:.5f} mAP:{m_ap}%')\n",
    "        self.plot_valid_loss(np.array([loss]), np.array([self.batch]))\n",
    "        self.plot_valid_pr(np.array(pr[0]), np.array(pr[1]), update='replace')\n",
    "\n",
    "        if m_ap > self.best_map:\n",
    "            if self.best_map > 0:\n",
    "                self.plot_valid_pr(None, name=f'best - {self.best_map}%', update='remove', opts=None)\n",
    "            self.best_map = m_ap\n",
    "            self.network.save(os.path.join(self.backup_folder, 'best_map.pt'))\n",
    "            self.plot_valid_pr(np.array(pr[0]), np.array(pr[1]), name=f'best - {self.best_map}%', update='new', opts=dict(legend=[f'best - {self.best_map}%']))\n",
    "\n",
    "        self.network.train()\n",
    "\n",
    "    def quit(self):\n",
    "        if self.batch >= self.max_batches:\n",
    "            self.params.network.save(os.path.join(self.backup_folder, 'final.pt'))\n",
    "            return True\n",
    "        elif self.sigint:\n",
    "            self.params.save(os.path.join(self.backup_folder, 'backup.state.pt'))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "\u001b[01m\u001b[33mWARNING   \u001b[00m Backup folder does not exist, creating...\n",
      "\u001b[01m\u001b[33mWARNING   \u001b[00m Modules not matching, performing partial update\n",
      "\u001b[01m\u001b[37mINFO      \u001b[00m Loaded weights from C:\\Users\\William\\Desktop\\Lightnet\\examples\\yolo-voc\\weights\\darknet19_448.conv.23.pt\n",
      "INFO       [brambox.boxes.annotations.pickle] No 'keep_ignore' kwarg found, defaulting to False.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ba7e6ebdf6c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# Dataloaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     train_loader = ln.data.DataLoader(\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mVOCData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\Python Analysis\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, anno, params, augment)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0manno_tf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'anno_pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_label_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midentify\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manno_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mln\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBramboxDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_getitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightnet\\models\\_dataset_brambox.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, anno_format, anno_filename, input_dimension, class_label_map, identify, img_transform, anno_transform, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# Get annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbbb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manno_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manno_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midentify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_label_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_label_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\brambox\\boxes\\util\\convert.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(fmt, box_file, identify, offset, stride, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbox_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Parser <{parser.__class__.__name__}> requires a single annotation file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbox_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_mode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train.pkl'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Train network')\n",
    "    parser.add_argument('weight', help='Path to weight file', default=None, nargs='?')\n",
    "    parser.add_argument('-n', '--network', help='network config file')\n",
    "    parser.add_argument('-b', '--backup', metavar='folder', help='Backup folder', default='./backup')\n",
    "    parser.add_argument('-c', '--cuda', action='store_true', help='Use cuda')\n",
    "    parser.add_argument('-v', '--visdom', action='store_true', help='Visualize training data with visdom')\n",
    "    parser.add_argument('-e', '--visdom_env', help='Visdom environment to plot to', default='main')\n",
    "    parser.add_argument('-p', '--visdom_port', help='Port of the visdom server', type=int, default=8097)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    backup = f\"backup{os.sep}\"\n",
    "    weight = f'weights{os.sep}darknet19_448.conv.23.pt'\n",
    "    #weight = f'backup{os.sep}final.pt'\n",
    "    network = f'cfg{os.sep}yolo.py'\n",
    "    use_cuda = True\n",
    "    use_visdom = False\n",
    "    visdom_env = 'main'\n",
    "    visdom_port = 8097\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Parse arguments\n",
    "    device = torch.device('cpu')\n",
    "    if use_cuda:\n",
    "        if torch.cuda.is_available():\n",
    "            log.debug('CUDA enabled')\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            log.error('CUDA not available')\n",
    "\n",
    "    if not os.path.isdir(backup):\n",
    "        if not os.path.exists(backup):\n",
    "            log.warn('Backup folder does not exist, creating...')\n",
    "            os.makedirs(backup)\n",
    "        else:\n",
    "            raise ValueError('Backup path is not a folder')\n",
    "    \n",
    "    if use_visdom:\n",
    "        visdom = visdom.Visdom(port=visdom_port, env=visdom_env)\n",
    "    else:\n",
    "        visdom = None\n",
    "\n",
    "\n",
    "    params = ln.engine.HyperParameters.from_file(network)\n",
    "    if weight is not None:\n",
    "        if weight.endswith('.state.pt'):\n",
    "            params.load(weight)\n",
    "        else:\n",
    "            params.network.load(weight)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = ln.data.DataLoader(\n",
    "        VOCData(params.train_set, params, True),\n",
    "        batch_size = params.mini_batch_size,\n",
    "        shuffle = True,\n",
    "        drop_last = True,\n",
    "        num_workers = 0,\n",
    "        pin_memory = True,\n",
    "        collate_fn = ln.data.list_collate,\n",
    "    )\n",
    "\n",
    "    if params.valid_set is not None:\n",
    "        valid_loader = torch.utils.data.DataLoader(\n",
    "            VOCData(params.valid_set, params, False),\n",
    "            batch_size = params.mini_batch_size,\n",
    "            shuffle = False,\n",
    "            drop_last = False,\n",
    "            num_workers = 0,\n",
    "            pin_memory = True,\n",
    "            collate_fn = ln.data.list_collate,\n",
    "        )\n",
    "    else:\n",
    "        valid_loader = None\n",
    "\n",
    "    # Start training\n",
    "    eng = TrainEngine(\n",
    "        params, train_loader,\n",
    "        valid_loader=valid_loader, device=device, visdom=visdom, backup_folder=backup\n",
    "    )\n",
    "    b1 = eng.batch\n",
    "    t1 = time.time()\n",
    "    eng()\n",
    "    t2 = time.time()\n",
    "    b2 = eng.batch\n",
    "    log.info(f'Training {b2-b1} batches took {t2-t1:.2f} seconds [{(t2-t1)/(b2-b1):.3f} sec/batch]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Detect Module\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "backup = f\"backup{os.sep}\"\n",
    "weight = f'weights{os.sep}darknet19_448.conv.23.pt'\n",
    "network = f'cfg{os.sep}yolo.py'\n",
    "use_cuda = True\n",
    "use_visdom = False\n",
    "visdom_env = 'main'\n",
    "visdom_port = 8097\n",
    "\n",
    "\n",
    "image_path = f'C:{os.sep}Users{os.sep}William{os.sep}Desktop{os.sep}Lightnet{os.sep}examples{os.sep}basic{os.sep}dog.jpg' \n",
    "\n",
    "\n",
    "# Parse arguments\n",
    "device = torch.device('cpu')\n",
    "if use_cuda:\n",
    "    if torch.cuda.is_available():\n",
    "        log.debug('CUDA enabled')\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        log.error('CUDA not available')\n",
    "\n",
    "\n",
    "params = ln.engine.HyperParameters.from_file(network)\n",
    "if weight is not None:\n",
    "    if weight.endswith('.state.pt'):\n",
    "        params.load(weight)\n",
    "    else:\n",
    "        params.network.load(weight)\n",
    "\n",
    "        \n",
    "print (params.network)\n",
    "\n",
    "print (vars(params))\n",
    "\n",
    "\n",
    "#Hin, Win = 400,400\n",
    "#target = range(400)\n",
    "#im_data = torch.autograd.Variable(torch.randn(len(target), 3, Hin, Win))\n",
    "#output = params.network._forward(im_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import argparse\n",
    "import logging\n",
    "import copy\n",
    "import time\n",
    "from pathlib import Path\n",
    "from statistics import mean\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import lightnet as ln\n",
    "import brambox.boxes as bbb\n",
    "from dataset import *\n",
    "\n",
    "log = logging.getLogger('lightnet.VOC.test')\n",
    "\n",
    "\n",
    "class TestEngine:\n",
    "    workers = 8\n",
    "    pin_mem = True\n",
    "    coco_metric = False\n",
    "\n",
    "    def __init__(self, params, **kwargs):\n",
    "        self.params = params\n",
    "        self.device = kwargs['device']\n",
    "        self.loss = kwargs['loss']\n",
    "        self.fast_pr = kwargs['fast_pr']\n",
    "        self.network = params.network\n",
    "        self.network.eval()\n",
    "        self.network.to(self.device)\n",
    "\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(\n",
    "            VOCData(params.test_set, params, False),\n",
    "            batch_size = params.mini_batch_size,\n",
    "            shuffle = False,\n",
    "            drop_last = False,\n",
    "            num_workers = 8,\n",
    "            pin_memory = True,\n",
    "            collate_fn = ln.data.list_collate,\n",
    "        )\n",
    "\n",
    "    def __call__(self, csv_file):\n",
    "        if self.loss == 'none':\n",
    "            anno, det = self.test_none()\n",
    "        else:\n",
    "            anno, det = self.test_loss()\n",
    "\n",
    "        if self.coco_metric:\n",
    "            m_ap = []\n",
    "            for i in range(50, 95, 5):\n",
    "                m_ap.append(self.ap(det, anno, i/100))\n",
    "            m_ap = round(mean(m_ap), 2)\n",
    "            if self.csv_file:\n",
    "                log.error('CSV file is not possible with the coco metric')\n",
    "        else:\n",
    "            m_ap = self.ap(det, anno, csv=csv_file)\n",
    "\n",
    "        print(f'mAP: {m_ap:.2f}%')\n",
    "\n",
    "    def ap(self, det, anno, iou=.5, csv=None):\n",
    "        if csv is not None:\n",
    "            base_path = Path(csv)\n",
    "\n",
    "        if self.fast_pr:\n",
    "            pr = bbb.pr(det, anno, iou)\n",
    "\n",
    "            if csv is not None:\n",
    "                np.savetxt(str(base_path), np.array(pr), delimiter=',')\n",
    "\n",
    "            return round(100 * bbb.ap(*pr), 2)\n",
    "        else:\n",
    "            aps = []\n",
    "            for c in tqdm(self.params.class_label_map):\n",
    "                anno_c = bbb.filter_discard(copy.deepcopy(anno), [ lambda a: a.class_label == c ])\n",
    "                det_c  = bbb.filter_discard(copy.deepcopy(det), [ lambda d: d.class_label == c ])\n",
    "                pr = bbb.pr(det_c, anno_c)\n",
    "\n",
    "                if csv is not None:\n",
    "                    np.savetxt(str(base_path.with_name(base_path.stem + f'_{c}' + base_path.suffix)), np.array(pr), delimiter=',')\n",
    "\n",
    "                aps.append(bbb.ap(*pr))\n",
    "\n",
    "            return round(100 * mean(aps), 2)\n",
    "\n",
    "    def test_none(self):\n",
    "        anno, det = {}, {}\n",
    "\n",
    "        pp = self.network.postprocess\n",
    "        self.network.postprocess = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t_net = 0\n",
    "            t_pp = 0\n",
    "            for idx, (data, target) in enumerate(self.test_dataloader):\n",
    "                data = data.to(self.device)\n",
    "                t1 = time.perf_counter()\n",
    "                output = self.network(data)\n",
    "                torch.cuda.synchronize()\n",
    "                t2 = time.perf_counter()\n",
    "                output = pp(output)\n",
    "                torch.cuda.synchronize()\n",
    "                t3 = time.perf_counter()\n",
    "\n",
    "                t_net += t2 - t1\n",
    "                t_pp += t3 - t2\n",
    "\n",
    "                base_idx = idx*self.params.mini_batch_size\n",
    "                anno.update({self.test_dataloader.dataset.keys[base_idx+k]: v for k,v in enumerate(target)})\n",
    "                det.update({self.test_dataloader.dataset.keys[base_idx+k]: v for k,v in enumerate(output)})\n",
    "\n",
    "\n",
    "            t_net_img = t_net * 1000 / len(self.test_dataloader.dataset)\n",
    "            t_pp_img = t_pp * 1000 / len(self.test_dataloader.dataset)\n",
    "            t_tot_img = t_net_img + t_pp_img\n",
    "            log.info(f'Time:{t_tot_img:.2f}ms/img (Network:{t_net_img:.3f} Post:{t_pp_img:.3f})')\n",
    "\n",
    "            self.network.postprocess = pp\n",
    "\n",
    "            return anno, det\n",
    "\n",
    "    def test_loss(self):\n",
    "        loss_dict = {'tot': [], 'coord': [], 'conf': [], 'cls': []}\n",
    "        anno, det = {}, {}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, (data, target) in tqdm(enumerate(self.test_dataloader), total=len(self.test_dataloader)):\n",
    "                data = data.to(self.device)\n",
    "                output, loss = self.network(data, target)\n",
    "\n",
    "                loss_dict['tot'].append(self.network.loss.loss_tot.item()*len(target))\n",
    "                loss_dict['coord'].append(self.network.loss.loss_coord.item()*len(target))\n",
    "                loss_dict['conf'].append(self.network.loss.loss_conf.item()*len(target))\n",
    "                loss_dict['cls'].append(self.network.loss.loss_cls.item()*len(target))\n",
    "                base_idx = idx*self.params.mini_batch_size\n",
    "                anno.update({self.test_dataloader.dataset.keys[base_idx+k]: v for k,v in enumerate(target)})\n",
    "                det.update({self.test_dataloader.dataset.keys[base_idx+k]: v for k,v in enumerate(output)})\n",
    "\n",
    "        loss_tot = sum(loss_dict['tot'])/len(anno)\n",
    "        loss_coord = sum(loss_dict['coord'])/len(anno)\n",
    "        loss_conf = sum(loss_dict['conf'])/len(anno)\n",
    "        loss_cls = sum(loss_dict['cls'])/len(anno)\n",
    "        if self.loss == 'percent':\n",
    "            loss_coord *= 100 / loss_tot\n",
    "            loss_conf *= 100 / loss_tot\n",
    "            loss_cls *= 100 / loss_tot\n",
    "            log.info(f'Loss:{loss_tot:.5f} (Coord:{loss_coord:.2f}% Conf:{loss_conf:.2f}% Class:{loss_cls:.2f}%)')\n",
    "        else:\n",
    "            log.info(f'Loss:{loss_tot:.5f} (Coord:{loss_coord:.2f} Conf:{loss_conf:.2f} Class:{loss_cls:.2f})')\n",
    "\n",
    "        return anno, det\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Test trained network')\n",
    "    parser.add_argument('weight', help='Path to weight file', default=None)\n",
    "    parser.add_argument('--csv', help='Path for the csv file with the results', default=None)\n",
    "    parser.add_argument('-n', '--network', help='network config file')\n",
    "    parser.add_argument('-c', '--cuda', action='store_true', help='Use cuda')\n",
    "    parser.add_argument('-f', '--fast-pr', action='store_true', help='Use faster but less accurate PR computation method')\n",
    "    parser.add_argument('-l', '--loss', help='How to display loss', choices=['abs', 'percent', 'none'], default='abs')\n",
    "    parser.add_argument('-t', '--thresh', help='Detection Threshold', type=float, default=None)\n",
    "    parser.add_argument('-s', '--save', help='File to store network weights', default=None)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    backup = f\"backup{os.sep}\"\n",
    "    weight = f'weights{os.sep}darknet19_448.conv.23.pt'\n",
    "    network = f'cfg{os.sep}yolo.py'\n",
    "    use_cuda = True\n",
    "    use_visdom = False\n",
    "    visdom_env = 'main'\n",
    "    visdom_port = 8097\n",
    "    thresh = None\n",
    "    save = None\n",
    "    loss = 'abs'\n",
    "    csv = None\n",
    "    fast_pr = False\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    device = torch.device('cpu')\n",
    "    if use_cuda:\n",
    "        if torch.cuda.is_available():\n",
    "            log.debug('CUDA enabled')\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            log.error('CUDA not available')\n",
    "\n",
    "    params = ln.engine.HyperParameters.from_file(network)\n",
    "    if weight is not None:\n",
    "        if weight.endswith('.state.pt'):\n",
    "            params.load(weight)\n",
    "        else:\n",
    "            params.network.load(weight)\n",
    "    if thresh is not None:\n",
    "        params.network.postprocess[0].conf_thresh = thresh\n",
    "\n",
    "    if save is not None:\n",
    "        params.network.save(save)\n",
    "\n",
    "    # Start test\n",
    "    eng = TestEngine(params, device=device, loss=loss, fast_pr=fast_pr)\n",
    "    eng(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#\n",
    "#   Copyright EAVISE\n",
    "#   Example: Perform a single image detection with the Lightnet tiny yolo network\n",
    "#\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "import brambox.boxes as bbb\n",
    "import lightnet as ln\n",
    "\n",
    "log = logging.getLogger('lightnet.detect')\n",
    "\n",
    "# Parameters\n",
    "CLASSES = 20\n",
    "NETWORK_SIZE = [416, 416]\n",
    "LABELS = ['person']\n",
    "CONF_THRESH = .25\n",
    "NMS_THRESH = .4\n",
    "\n",
    "\n",
    "# Functions\n",
    "def create_network(weights):\n",
    "    \"\"\" Create the lightnet network \"\"\"\n",
    "    net = ln.models.Yolo(CLASSES, \n",
    "                         conf_thresh = .001,\n",
    "                         nms_thresh = .5,)\n",
    "    net.postprocess.append(ln.data.transform.TensorToBrambox(NETWORK_SIZE, LABELS))\n",
    "    net = net.to(device)\n",
    "    return net\n",
    "\n",
    "\n",
    "def detect(net, img_path):\n",
    "    \"\"\" Perform a detection \"\"\"\n",
    "    # Load image\n",
    "    print (\"Got to here\", img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    im_h, im_w = img.shape[:2]\n",
    "\n",
    "    img_tf = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_tf = ln.data.transform.Letterbox.apply(img_tf, dimension=NETWORK_SIZE)\n",
    "    img_tf = tf.ToTensor()(img_tf)\n",
    "    img_tf.unsqueeze_(0)\n",
    "    img_tf = img_tf.to(device)\n",
    "    \n",
    "    print (img_tf.shape, type(img_tf))\n",
    "\n",
    "    # Run detector\n",
    "    with torch.no_grad():\n",
    "        out = net(img_tf)\n",
    "    out = ln.data.transform.ReverseLetterbox.apply(out, NETWORK_SIZE, (im_w, im_h)) # Resize bb to true image dimensions\n",
    "\n",
    "    return img, out\n",
    "\n",
    "\n",
    "# Main\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"parser = argparse.ArgumentParser(description='Run an image through the lightnet yolo network')\n",
    "    parser.add_argument('weight', help='Path to weight file')\n",
    "    parser.add_argument('image', help='Path to image file(s)', nargs='*')\n",
    "    parser.add_argument('-c', '--cuda', action='store_true', help='Use cuda')\n",
    "    parser.add_argument('-s', '--save', action='store_true', help='Save image in stead of displaying it')\n",
    "    parser.add_argument('-l', '--label', action='store_true', help='Print labels and scores on the image')\n",
    "    args = parser.parse_args()\n",
    "    \"\"\"\n",
    "    \n",
    "    image_path = [f\"C:{os.sep}Users{os.sep}William{os.sep}Desktop{os.sep}Lightnet{os.sep}examples{os.sep}basic{os.sep}dog.jpg\"]\n",
    "    weights_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Desktop{os.sep}Lightnet{os.sep}examples{os.sep}basic{os.sep}yolov2-tiny.weights\"\n",
    "    save_check = False\n",
    "    \n",
    "    \n",
    "    use_cuda = True\n",
    "    \n",
    "    \n",
    "    # Parse Arguments\n",
    "    device = torch.device('cpu')\n",
    "    if use_cuda:\n",
    "        if torch.cuda.is_available():\n",
    "            log.debug('CUDA enabled')\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            log.error('CUDA not available')\n",
    "\n",
    "    # Network\n",
    "    network = create_network(weights_path)\n",
    "    #print(network)\n",
    "    #print()\n",
    "    network.training = False\n",
    "    print(\"Training\", network.training)\n",
    "    \n",
    "    \n",
    "    # Detection\n",
    "    if len(image_path) > 0:\n",
    "        for img_name in image_path:\n",
    "            log.info(img_name)\n",
    "            image, output = detect(network, img_name)\n",
    "\n",
    "            image = bbb.draw_boxes(image, output[0], show_labels=args.label)\n",
    "            if save_check:\n",
    "                cv2.imwrite('detections.png', image)\n",
    "            else:\n",
    "                cv2.imshow('image', image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "    else:\n",
    "        while True:\n",
    "            try:\n",
    "                img_path = input('Enter image path: ')    \n",
    "            except (KeyboardInterrupt, EOFError):\n",
    "                print('')\n",
    "                break\n",
    "        \n",
    "            if not os.path.isfile(img_path):\n",
    "                log.error(f'\\'{img_path}\\' is not a valid path')\n",
    "                break\n",
    "\n",
    "            image, output = detect(network, img_path)\n",
    "            image = bbb.draw_boxes(image, output[0], show_labels=args.label)\n",
    "            if args.save:\n",
    "                cv2.imwrite('detections.png', image)\n",
    "            else:\n",
    "                cv2.imshow('image', image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
