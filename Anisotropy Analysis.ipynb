{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from skimage import io\n",
    "from skimage.morphology import extrema\n",
    "from skimage.measure import label\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "import skimage\n",
    "\n",
    "import scipy\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import imageio\n",
    "\n",
    "import javabridge \n",
    "import bioformats\n",
    "javabridge.start_vm(class_path=bioformats.JARS, max_heap_size='8G')\n",
    "\n",
    "#import net.imageJ.ImageJ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#For the YOLO Network\n",
    "import logging\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "import brambox.boxes as bbb\n",
    "import lightnet as ln\n",
    "\n",
    "\n",
    "\n",
    "#For the GUI\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
    "\n",
    "#for key bindings\n",
    "from matplotlib.backend_bases import key_press_handler\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See your current version of python/anaconda\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagingParameters():\n",
    "    def __init__(self, data_path, **kwargs):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "            #print (key, value, getattr(self, key))\n",
    "            \n",
    "            \n",
    "        \n",
    "        #Assert that the core variables are all set correctly.\n",
    "        core_variables = ['channel_array', 'channel_thresholds', 'suffix', 'machine_learning_mode']\n",
    "        print (core_variables)\n",
    "        self.assert_variables(core_variables, \"Core\")\n",
    "\n",
    "        \n",
    "      \n",
    "        \n",
    "        #Store the dataframes from each of the experiments\n",
    "        self.directory_list = self.find_files(self.data_path, {})\n",
    "        self.dataframes = []\n",
    "        #print(self.directory_list)\n",
    "        \n",
    "        \n",
    "        #List containing all of the final dataframes for convenience\n",
    "        self.experiments = []\n",
    "        \n",
    "        \n",
    "        \n",
    "                 \n",
    "        machine_learning_args = [\"\"]\n",
    "        if (self.machine_learning_mode == True):\n",
    "            \n",
    "            network_variables = ['classes', 'network_size', 'labels', 'conf_thresh', 'nms_thresh', 'use_cuda']\n",
    "            self.assert_variables(network_variables, \"Network\")              \n",
    "                 \n",
    "            self.initializeROINetwork()\n",
    "            \n",
    "        else:\n",
    "            automatic_detection_variables = ['max_neighborhood_size', \n",
    "                                             'max_threshold', \n",
    "                                             'local_max_avg_radius', \n",
    "                                             'thresh_tolerance', 'IoU_match_thresh']\n",
    "            self.assert_variables(automatic_detection_variables, \"Local Max Detection\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        subframes = 0\n",
    "        for items in self.channel_array:\n",
    "            subframes += items\n",
    "            \n",
    "        self.frames_per_timepoint = subframes\n",
    "        \n",
    "        \n",
    "        \n",
    "        #If you are using the anisotropy analysis, create the relevant correction factors:\n",
    "\n",
    "        \n",
    "        if \"Anisotropy\" in self.image_type_array:\n",
    "            \n",
    "            \n",
    "            #Assert that the correct variables are defined\n",
    "            ani_variables = ['numerical_aperture', 'index_of_refraction', 'magnification', 'gFactor']\n",
    "            self.assert_variables(ani_variables, \"Anisotropy\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            asin = math.asin(self.numerical_aperture/self.index_of_refraction) \n",
    "            cos = math.cos(asin)\n",
    "\n",
    "            kA = (2.0 - 3.0 * cos + cos * cos * cos) / (6.0 * (1.0 - cos))\n",
    "            kB = (1.0 - 3.0 * cos + 3.0 * cos * cos - cos * cos * cos) / (24.0 * (1.0 - cos))\n",
    "            kC = (5.0 - 3.0 * cos - cos * cos - cos * cos * cos) / (8.0 * (1.0 - cos))\n",
    "\n",
    "\n",
    "            self.kA = kA\n",
    "            self.kB = kB\n",
    "            self.kC = kC\n",
    "\n",
    "            print (kA, kB, kC)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    def assert_variables(self, variables, identifier = \"\"):\n",
    "            for attribute in variables:\n",
    "                assert hasattr(self, attribute), f\"Error: {identifier} attribute {attribute} was not set.  Check your config file\"\n",
    "\n",
    "\n",
    "    def find_files(self, path, directory_list = {}):\n",
    "        all_files = os.listdir(path)\n",
    "        #print (all_files)\n",
    "        for files in all_files:\n",
    "            #print (path, os.path.dirname(path))\n",
    "\n",
    "            #When you find the appropriate file, add the directory to the dictionary for processing\n",
    "            if os.path.isfile(f'{path}{os.sep}{files}'):\n",
    "                #print (\"Found a file\")\n",
    "                if files.endswith(self.suffix):\n",
    "                    #print (f\"Ends with ome.tif ({files})\")\n",
    "                    prev_directory = os.path.dirname(path)\n",
    "                    current_directory = path.replace(prev_directory, \"\")\n",
    "                    if prev_directory in directory_list:\n",
    "                        directory_list[prev_directory][current_directory] = None\n",
    "\n",
    "                    else:\n",
    "                        directory_list[prev_directory] = {current_directory : None}\n",
    "\n",
    "\n",
    "\n",
    "            elif os.path.isdir(f'{path}{os.sep}{files}'):\n",
    "                directory_list = self.find_files(f'{path}{os.sep}{files}', directory_list)\n",
    "                #print (\"Found a directory\")\n",
    "\n",
    "\n",
    "        return (directory_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def iterate_through_files(self):\n",
    "        \"\"\"\n",
    "        The purpose of this function is to iterate through all of the files in the directory list and then\n",
    "        send them to the relevant analysis program\n",
    "        \"\"\" \n",
    "        \n",
    "        dataframes = self.dataframes\n",
    "        suffix = self.suffix\n",
    "        directory_list = self.directory_list\n",
    "        debug_mode = self.debug_mode\n",
    "        machine_learning_mode = self.machine_learning_mode\n",
    "\n",
    "\n",
    "        if debug_mode == True:\n",
    "            #Start a new dataframe each time\n",
    "            dataframes = []\n",
    "\n",
    "\n",
    "\n",
    "        #knowing the previous directory we looked at helps to determine whether we should append the\n",
    "            #results to a current dataframe or not.  You want to append if the data are from the same cells\n",
    "        prev_root = \"\"\n",
    "        new_dataframe = True\n",
    "\n",
    "\n",
    "        for root_dir in sorted(directory_list):\n",
    "            if os.path.dirname(os.path.dirname(prev_root)) == os.path.dirname(os.path.dirname(root_dir)):\n",
    "                print (\"From the same core directory\")\n",
    "                new_dataframe = False\n",
    "            else:\n",
    "                print (\"Not from the same core directory\")\n",
    "                #if they do not share the same root directory, you need to create a new dataframe\n",
    "                new_dataframe = True\n",
    "                dataframes.append({})\n",
    "                \n",
    "                \n",
    "            \n",
    "            #print (\"Dir:\" directories, os.path.dirname(os.path.dirname(directories)))\n",
    "            print(\"Root\", root_dir, \"Prev:\", prev_root)\n",
    "            \n",
    "            \n",
    "            #note: there will usually only be one subdirectory per root_dir\n",
    "            for directories in sorted(directory_list[root_dir]):\n",
    "\n",
    "                file_list = os.listdir(f'{root_dir}{directories}')\n",
    "\n",
    "\n",
    "                for files in sorted(file_list):\n",
    "                    if files.endswith(suffix):\n",
    "                        \n",
    "\n",
    "                        #store all the relevant information about the image in a new class                    \n",
    "                        current_Image = ImageClass(f'{root_dir}{directories}',\n",
    "                                                  files, Parameters.channel_array,\n",
    "                                                  Parameters.image_type_array, Parameters.channel_thresholds)\n",
    "\n",
    "                        #Analyze the image\n",
    "                        \n",
    "                        dataframes = image_Analysis(current_Image=current_Image, \n",
    "                                                         Parameters = Parameters, \n",
    "                                                         dataframes = dataframes)\n",
    "\n",
    "\n",
    "\n",
    "                #print (dataframes[-1].head())\n",
    "            prev_root = root_dir\n",
    "\n",
    "\n",
    "        #consolidate the dataframes\n",
    "        dataframes = self.consolidate_dataframes(dataframes)\n",
    "\n",
    "        self.dataframes = dataframes\n",
    "        return (dataframes)\n",
    "\n",
    "            \n",
    "            \n",
    "    def consolidate_dataframes(self, dataframes):\n",
    "\n",
    "        \"\"\"\n",
    "        Combine the dataframes from each image into one consolidated dataframe\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        #dataframes = self.dataframes\n",
    "       \n",
    "        for index, _  in enumerate(dataframes):   \n",
    "            final_dataframe = pd.DataFrame([])\n",
    "            for filenames in dataframes[index]:\n",
    "                #print (f\"current filename is: {filenames}\")\n",
    "                df_interest = dataframes[index][filenames]\n",
    "                #print (type(df_interest))\n",
    "                #print (df_interest)\n",
    "                if len(final_dataframe)==0:\n",
    "                    #print (\"need a new dataframe\")\n",
    "                    final_dataframe = df_interest\n",
    "                else:\n",
    "                    #print (\"Appending\")\n",
    "                    final_dataframe = final_dataframe.append(df_interest, ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "            dataframes[index] = {\"Total\": final_dataframe}\n",
    "            #print (self.experiments, dataframes)\n",
    "            self.experiments.append(final_dataframe)\n",
    "            #print (final_dataframe)\n",
    "\n",
    "\n",
    "        self.dataframes = dataframes\n",
    "        \n",
    "\n",
    "        return (dataframes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def initializeROINetwork(self):\n",
    "        #These will eventually be in a configuration file\n",
    "        self.log = logging.getLogger('lightnet.detect')\n",
    "        \n",
    "        \n",
    "        #self.classes = 20\n",
    "        #NETWORK_SIZE = (416, 416)\n",
    "        #self.network_size = [1482, 2535]  #Easier if a multiple of 13 or 26\n",
    "        #self.labels = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "        #          'bus', 'car', 'cat', 'chair', 'cow',\n",
    "        #          'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "        #          'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "        #self.conf_thresh = .20\n",
    "        #self.nms_thresh = .4\n",
    "        #self.use_cuda = True\n",
    "        \n",
    "\n",
    "        #Use the GPU if available and wanted\n",
    "        self.device = torch.device('cpu')\n",
    "        if self.use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                self.log.debug('CUDA enabled')\n",
    "                self.device = torch.device('cuda')\n",
    "            else:\n",
    "                self.log.error('CUDA not available')\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.network = ln.models.Yolo(self.classes,\n",
    "                                      conf_thresh = self.conf_thresh,\n",
    "                                      nms_thresh = self.nms_thresh,)\n",
    "    \n",
    "        self.network.postprocess.append(ln.data.transform.TensorToBrambox(self.network_size, self.labels))\n",
    "        self.network.load(self.weights_path)\n",
    "    \n",
    "        self.network = self.network.to(self.device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def create_pd_dataframe():\n",
    "    \n",
    "\n",
    "    dataframe = pd.DataFrame(columns=pd.MultiIndex.from_tuples([(-1, -1,  \"Image\"), (-1,-1,\"Index\"), (-1, -1, \"ROI\")]))\n",
    "    #dataframe = pd.DataFrame(columns=[\"Image\", \"Index\", \"ROI\"])\n",
    "        \n",
    "    \n",
    "    return (dataframe)\n",
    "\n",
    "#Should be a subclass of the imageing parameters\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClass():\n",
    "    def __init__(self, directory, filename, channel_array, image_type_array, channel_thresholds):\n",
    "        self.directory = directory \n",
    "        self.filename = filename\n",
    "        self.file_path = (f'{directory}{os.sep}{filename}')\n",
    "\n",
    "        \n",
    "        \n",
    "        self.dir_name = directory.replace(os.path.dirname(directory), \"\")\n",
    "        self.upper_dir_name = os.path.dirname(directory).replace (os.path.dirname(os.path.dirname(directory)), \"\")[1:]\n",
    "        \n",
    "        self.ROI_list = []\n",
    "        \n",
    "        \n",
    "        image = Image.open(self.file_path)\n",
    "        self.total_frames = image.n_frames\n",
    "        self.width = image.width\n",
    "        self.length = image.height\n",
    "        \n",
    "        self.channel_array = channel_array\n",
    "        self.image_type_array = image_type_array\n",
    "        \n",
    "        self.channel_thresholds = channel_thresholds\n",
    "        \n",
    "        assert (len(channel_array) == len(image_type_array)), \"Anisotropy and Channel arrays are not of equal length\"\n",
    "              \n",
    "        self.channel_offset = np.zeros(len(channel_array))\n",
    "        \n",
    "        images_per_timepoint = 0\n",
    "        for index, items in enumerate(channel_array):\n",
    "            #print (index, items, images_per_timepoint)\n",
    "            self.channel_offset[index] = images_per_timepoint\n",
    "            images_per_timepoint += items\n",
    "        \n",
    "        self.images_per_timepoint = images_per_timepoint\n",
    "        self.timepoints = self.total_frames // images_per_timepoint\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROIs():\n",
    "    def __init__(self, x, y, data, classification=None, confidence=None):\n",
    "        \"\"\"\n",
    "            ______x_______\n",
    "            |            |\n",
    "           y|            |\n",
    "            |            |\n",
    "            |____________|\n",
    "        \n",
    "        \n",
    "        Note: this standard was adopted as it conforms to both bramboxes and CV2 drawing formats.\n",
    "        For numpy arrays, axis 0 is Y and axis 1 is X.  Therefore indexing should be\n",
    "        np.array[y1:y1, x1:x2] when dealing with the images as numpy arrays\n",
    "        \n",
    "        \"\"\"       \n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.data = data\n",
    "        self.classification = classification\n",
    "        self.confidence = confidence\n",
    "        \n",
    "        y_length, x_length = data.shape\n",
    "        \n",
    "        self.x_length = x_length\n",
    "        self.y_length = y_length\n",
    "        \n",
    "    \n",
    "#Should make this a subfunction of the ROI class\n",
    "\n",
    "\n",
    "\n",
    "def calc_overlap(ROI1, ROI2, threshold = 0.8):\n",
    "    \"\"\"\n",
    "    Calculate the IoU for two ROIs\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    x1, y1, x1Len, y1Len = ROI1.x, ROI1.y,  ROI1.x_length, ROI1.y_length\n",
    "    x2, y2, x2Len, y2Len = ROI2.x, ROI2.y,  ROI2.x_length, ROI2.y_length\n",
    "    \n",
    "    \n",
    "    box1_Area = (x1Len * y1Len)\n",
    "    box2_Area = (x2Len * y2Len)\n",
    "    #print (\"b1 Area\", box1_Area, \"b2 Area\", box2_Area)\n",
    "    \n",
    "    \n",
    "    inter_Area = max(0, (min(x1+x1Len, x2+x2Len)-max(x1, x2)))*max(0, (min(y1+y1Len, y2+y2Len) - max(y1, y2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (box1_Area or box2_Area):\n",
    "        IoU = inter_Area / (box1_Area + box2_Area - inter_Area + 0.001)\n",
    "    else:\n",
    "        IoU = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (IoU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anisotropy(image, Parameters):\n",
    "    \"\"\"\n",
    "    Parameters contains:\n",
    "        NA - Numerical Aperture\n",
    "        index_of_refraction - Index of Refraction for the immersion media\n",
    "        mag - Magnification\n",
    "        gFactor - G-Factor for the detector\n",
    "        \n",
    "        kA - Correctional Factors for high NA\n",
    "        kB - Correctional Factors for high NA\n",
    "        kC - Correctional Factors for high NA\n",
    "        \n",
    "        \n",
    "    image.shape[-1] should be equal to 3 with channels: Open, Parallel, Perpendicular\n",
    "    \"\"\"\n",
    "    \n",
    "    #image.shape[-1] should be equal to 3 with channels: Open, Parallel, Perpendicular \n",
    "    assert image.shape[2] == 3, f\"Anisotropy image was expecting 3 channels, but got: {image.shape[2]}\"\n",
    "    \n",
    "    \n",
    "    Ka = Parameters.kA\n",
    "    Kb = Parameters.kB\n",
    "    Kc = Parameters.kC\n",
    "    \n",
    "    \n",
    "    G = Parameters.gFactor\n",
    "    \n",
    "    \n",
    "    anisotropy_image = np.zeros((image.shape))\n",
    "\n",
    "    Para = image[:,:,1]\n",
    "    Perp = image[:,:,2]\n",
    "\n",
    "    Ix = ((Kb * Para - Kc * Perp*G)/(Ka*Kb + Kb**2 -Ka*Kc - Kc**2))\n",
    "    Iy = ((((Ka + Kb) * Perp*G) - (Ka+Kc)*Para)/(Ka*Kb+Kb**2-Ka*Kc-Kc**2))\n",
    "    \n",
    "    anisotropy_image[:,:,0] = Iy\n",
    "    anisotropy_image[:,:,1] = Ix\n",
    "    anisotropy_image[:,:,2] = 0\n",
    "    \n",
    "    numerator = np.add(Iy, np.multiply(Ix, -2*G))\n",
    "    denominator = np.add(Iy, np.multiply(Ix, 2*G))\n",
    "       \n",
    "        \n",
    "    anisotropy_image[:,:,-1] = np.divide (numerator, denominator, where=denominator!=0)\n",
    "    #anisotropy_image[:,:,2] = np.divide((np.add(Iy, np.multiply(Ix, -2*G))),(np.add(Iy, np.multiply(Ix, 2*G)))) \n",
    "    \n",
    "    return (anisotropy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_Analysis(current_Image, Parameters, dataframes = []):\n",
    "    \"\"\"\n",
    "    Analyze the current file.  Whether you are using machine learning or an algorithm, much of the process is the same\n",
    "    \n",
    "    current_Image:\n",
    "        directory\n",
    "        filename\n",
    "        file_path\n",
    "        timepoints\n",
    "        total_frames\n",
    "        width\n",
    "        length\n",
    "        channel_array\n",
    "        channel_offset\n",
    "        image_type_array\n",
    "        images_per_timepoint\n",
    "        \n",
    "        dir_name\n",
    "        upper_dir_name\n",
    "        \n",
    "    \n",
    "    prev_images is a dictionary of all of the most current values from the previous images\n",
    "        If a cell is found in the first image but not the second, it will still show up in the prev_images for the third image \n",
    "    \n",
    "    \n",
    "    dataframes is a list of all the dataframes associated with the analysis.\n",
    "        different groups of data should have different dataframes (aka, data for a different graph)\n",
    "        \n",
    "        Dataframes is a list of dictionaries, each containing a dataframe for each image that it is analyzing.\n",
    "        Once the analysis is complete, the dictionary will be replaced with a single entry dictionary\n",
    "        {\"Total\": pd.DataFrame}\n",
    "    \n",
    "       \n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    #g_factor = Parameters.g_factor    \n",
    "\n",
    "        \n",
    "    #Import the relevant parameters from the ImagingParameters Class   \n",
    "    root_dir = Parameters.data_path\n",
    "    suffix = Parameters.suffix\n",
    "    debug_mode = Parameters.debug_mode\n",
    "    segmentation_outputs = Parameters.segmentation_outputs\n",
    "    machine_learning_mode = Parameters.machine_learning_mode\n",
    "    ROI_match_threshold = 0.4\n",
    "    \n",
    "    #Import the relevant parameters from the ImageClass Class    \n",
    "    directory = current_Image.directory\n",
    "    total_frames = current_Image.total_frames\n",
    "    timepoints = current_Image.timepoints\n",
    "    filepath = current_Image.file_path\n",
    "    filename = current_Image.filename\n",
    "    channel_offset = current_Image.channel_offset\n",
    "    image_type_array = current_Image.image_type_array\n",
    "    images_per_timepoint = current_Image.images_per_timepoint\n",
    "    upper_dir_name = current_Image.upper_dir_name\n",
    "    channel_thresholds = current_Image.channel_thresholds\n",
    "    \n",
    "    \n",
    "    \n",
    "    general_strings = ['Image', 'ROI']\n",
    "    anisotropy_strings = ['Para', 'Perp', 'AniPixel', 'AniAvg']\n",
    "    intensity_strings = ['Intensity']\n",
    "    \n",
    "    \n",
    "    para_intensity_str = f'Para'\n",
    "    perp_intensity_str = f'Perp'\n",
    "    anipix_intensity_str = f'AniPixel'\n",
    "    aniavg_intensity_str = f'AniAvg'\n",
    "\n",
    "    intensity_string = \"Intensity\"\n",
    "    \n",
    "    image_string = \"Image\"\n",
    "    image_ROI_string = \"ROI\"\n",
    "    \n",
    "\n",
    "        \n",
    "    if filename not in dataframes[-1]:\n",
    "        new_dataframe = create_pd_dataframe()\n",
    "        dataframes[-1].update({filename: new_dataframe})\n",
    "    \n",
    "    \n",
    "    current_dataframe = dataframes[-1][filename]\n",
    "    \n",
    "    \n",
    "    all_columns = current_dataframe.columns\n",
    "    \n",
    "    master_column_offset = 0\n",
    "    if len(all_columns)>3:\n",
    "        master_column_offset = max(all_columns[3:], key = lambda x: x[0])[0] + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(f'root_dir: {Parameters.data_path}')\n",
    "    #print (f'directory: {current_Image.directory}')\n",
    "    #print (f'filepath: {current_Image.file_path}')\n",
    "    #print (f'filename: {current_Image.filename}')\n",
    "    \n",
    "\n",
    "    \n",
    "    print (f'current image is :{current_Image.filename} in {upper_dir_name} and it has {timepoints} timepoints and length df: {len(dataframes)}')\n",
    "    for time in range(timepoints):\n",
    "        \n",
    "        #for string in general_strings:\n",
    "        #    current_dataframe[(t, channel, string)] = np.nan\n",
    "        \n",
    "        for channel, (image_type, offset) in enumerate(zip(image_type_array, channel_offset)):\n",
    "            #print (f\"Current time is: {t}, anisotropy value is {anisotropy} and offset is {offset}\")\n",
    "            total_offset = time * images_per_timepoint + offset\n",
    "            t = time + master_column_offset\n",
    "            \n",
    "            if image_type == \"Anisotropy\" or image_type == \"Intensity\":\n",
    "            \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Open the image\n",
    "                \n",
    "                Images = {}\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                if image_type == \"Anisotropy\":\n",
    "                    Images['Open'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 0, rescale=False))\n",
    "                    Images['Para'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 1, rescale=False))\n",
    "                    Images['Perp'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 2, rescale=False))\n",
    "\n",
    "                    raw_image = np.dstack((Images['Open'], Images['Para'], Images['Perp']))\n",
    "                    \n",
    "                    anisotropy_image = calculate_anisotropy(raw_image, Parameters)\n",
    "                    \n",
    "                    Images['AniPixel'] = anisotropy_image[:,:,2].copy()\n",
    "                                       \n",
    "                    image_for_ROIs = Images['Open']\n",
    "                    \n",
    "                    for string in anisotropy_strings:\n",
    "                            current_dataframe[(t, channel, string)] = np.nan\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                elif image_type == \"Intensity\":\n",
    "                    Images['Intensity'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 0, rescale=False))\n",
    "                    image_for_ROIs = Images['Intensity']\n",
    "                    \n",
    "                    for string in intensity_strings:\n",
    "                        current_dataframe[(t, channel, string)] = np.nan\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                #Preprocessing of the image\n",
    "                \n",
    "                \n",
    "                #thresholded_image = image_for_ROIs.copy()\n",
    "                #if we change to floats, this should be np.nan, which doesn't exist for ints!\n",
    "                #thresholded_image[thresholded_image < channel_thresholds[channel]] = 0\n",
    "                \n",
    "\n",
    "                debug_path = directory.replace(root_dir, f'{root_dir}{os.sep}debug_ml')\n",
    "                if not os.path.isdir(debug_path):\n",
    "                        os.makedirs(debug_path)\n",
    "                debug_save_path = f'{debug_path}{os.sep}{filename}'.replace(suffix, f'{channel}.jpg')\n",
    "                \n",
    "                #Find ROIs and iterate through them\n",
    "                \n",
    "                if machine_learning_mode == True:\n",
    "                    if image_type == \"Anisotropy\":\n",
    "                        ROI_list = detect_ROIs(Parameters, raw_image, debug_path = debug_save_path)\n",
    "                    elif image_type == \"Intensity\":\n",
    "                        ROI_list = detect_ROIs(Parameters, np.dstack([image_for_ROIs, \n",
    "                                                                      image_for_ROIs*0.5, \n",
    "                                                                      image_for_ROIs*0.4]), \n",
    "                                               debug_path = debug_save_path)\n",
    "                \n",
    "                else:\n",
    "                    ROI_list = find_ROIs(image_for_ROIs, \n",
    "                                         Parameters, \n",
    "                                         threshold = channel_thresholds[channel])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #Debug Mode: Output an image with all the ROIs\n",
    "                if debug_mode == True:\n",
    "                    debug_path = directory.replace(root_dir, f'{root_dir}{os.sep}debug')\n",
    "                    if not os.path.isdir(debug_path):\n",
    "                        os.makedirs(debug_path)\n",
    "                        \n",
    "                    debug_image = image_for_ROIs.copy()\n",
    "                    debug_image = np.dstack([debug_image, debug_image*0.9, debug_image*0.8])\n",
    "                    debug_image = ((debug_image/np.amax(debug_image))*255).astype('uint8')\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                #Output the ROIs as seperate images\n",
    "                #segmentation_outputs = True\n",
    "                if segmentation_outputs == True:\n",
    "                    segmentation_path = directory.replace(root_dir, f'{root_dir}{os.sep}segmentation')\n",
    "                    if not os.path.isdir(segmentation_path):\n",
    "                        os.makedirs(segmentation_path)\n",
    "\n",
    "              \n",
    "                \n",
    "                \n",
    "\n",
    "                for idx, ROI in enumerate(ROI_list):\n",
    "                    match_index = 0\n",
    "                    match_IoU = 0\n",
    "                    for index, compROI in enumerate(current_dataframe[(-1, -1, \"ROI\")]):\n",
    "                        #print (\"Index is \", index)\n",
    "                        #print (current_dataframe[\"ROI\"])\n",
    "                        current_dataframe.head(5)\n",
    "                        IoU = calc_overlap(ROI, compROI)\n",
    "                        if (IoU > max(ROI_match_threshold, match_IoU)):\n",
    "                            match_index = index\n",
    "                            match_IoU = IoU\n",
    "                    \n",
    "                    if match_IoU:\n",
    "                        row_index = match_index #modify the current value\n",
    "                        #change the ROI in the comparison row??\n",
    "                        \n",
    "                    else:\n",
    "                        #append a new column\n",
    "                        row_index = len(current_dataframe.index)\n",
    "                        new_row = pd.DataFrame({(-1, -1, \"ROI\"): [ROI],\n",
    "                                                (-1, -1, \"Image\"): filename,\n",
    "                                                (-1, -1, \"Index\"): row_index})\n",
    "                        current_dataframe = current_dataframe.append(new_row, ignore_index = True, sort=False)\n",
    "\n",
    "\n",
    "                    #Use the ROI to append useful information to the dataframe    \n",
    "                    x_corner = ROI.x\n",
    "                    y_corner = ROI.y\n",
    "                    x_len = ROI.x_length\n",
    "                    y_len = ROI.y_length\n",
    "                    \n",
    "                    ROI_data = {}\n",
    "                    \n",
    "                    data_inputs = {}\n",
    "                    #data_inputs[image_string] = current_Image\n",
    "                    #data_inputs[image_ROI_string] = ROI\n",
    "                    \n",
    "                    \n",
    "\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if image_type == \"Anisotropy\":\n",
    "                        \n",
    "                        image_types = ['Para', 'Perp', 'AniPixel']\n",
    "                        subRegion = {}\n",
    "                        subRegionAvg = {}\n",
    "                        \n",
    "                        #subRegion['Thresh'] = thresholded_image[y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                        #subRegion[types] = np.multiply(subRegion[types], ROI.data)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        for types in image_types:\n",
    "                            subRegion[types] = Images[types][y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                            subRegion[types] = np.multiply(subRegion[types], ROI.data)\n",
    "                            data_inputs[types] = np.mean(subRegion[types][subRegion['Para']!=0])\n",
    "\n",
    "                            \n",
    "                                \n",
    "                        para_value = data_inputs['Para']\n",
    "                        perp_value = data_inputs['Perp']\n",
    "                        data_inputs['AniAvg'] = (para_value - perp_value)/(para_value + 2*perp_value)\n",
    "                        \n",
    "                        #print (para_value, perp_value, data_inputs['AniAvg'])\n",
    "                        \n",
    "                        for types in data_inputs:\n",
    "                            current_dataframe.at[row_index, (t, channel, types)] = data_inputs[types]\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                        \n",
    "                        #Export ROIs for training...\n",
    "                        if segmentation_outputs == True:\n",
    "                            \n",
    "                            subRegion['Open'] = Images['Open'][y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                            ROI_image = np.dstack([subRegion[\"Open\"].copy(), subRegion[\"Para\"].copy(), subRegion[\"Perp\"].copy()])\n",
    "                            ROI_image = ((ROI_image/np.amax(ROI_image))*255).astype('uint8')\n",
    "                            seg_save_path = f\"{segmentation_path}{os.sep}{filename}\".replace(suffix, f\"{channel}-{idx}.jpg\")\n",
    "                            imageio.imwrite(seg_save_path, ROI_image)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "\n",
    "\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    elif image_type == \"Intensity\":\n",
    "                        int_extract = Images['Intensity'][y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                        int_extract = np.multiply(int_extract, ROI.data)\n",
    "                        int_value = np.mean(int_extract[int_extract!=0])\n",
    "                        \n",
    "                        current_dataframe.at[row_index, (t, channel, intensity_string)] = int_value\n",
    "                        \n",
    "                        \n",
    "                    if debug_mode == True:\n",
    "                        #write the ROI box\n",
    "                        debug_image = cv2.rectangle(debug_image,\n",
    "                                                    (x_corner,y_corner), \n",
    "                                                    (x_corner+x_len, y_corner+y_len), \n",
    "                                                    (255,0,0), 5)\n",
    "                        \n",
    "                        debug_subRegion = debug_image[y_corner:y_corner+y_len, x_corner: x_corner+x_len, 2]\n",
    "                        debug_subRegion[ROI.data!=0] = 255\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                if debug_mode == True:\n",
    "                    debug_save_path = f'{debug_path}{os.sep}{filename}'.replace(suffix, f'{channel}.jpg')\n",
    "                    imageio.imwrite(debug_save_path, debug_image)\n",
    "                        \n",
    "    \n",
    "    \n",
    "    #outside the loop, not really useful for anything\n",
    "    dataframes[-1][filename] = current_dataframe  \n",
    "    \n",
    "    #print (current_dataframe)\n",
    "\n",
    "    \n",
    "    return (dataframes)\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#image_Analysis(Parameters = Parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_maxima (data, neighborhood_size = 4, threshold = 700, region_size = 5, min_maxima_value = 500):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    \n",
    "    image = a 2D numpy matrix containing your data\n",
    "    neighborhood_size = the area used to find the maximum filter (should be larger than your largest object)\n",
    "    threshold = the minimum difference between your maximum and the lower value \n",
    "        in the neighbourhood (the background if the neighborhood size is large enough)\n",
    "        \n",
    "    region_size = the region that you should look at when calculating the average intensity for that maxima\n",
    "    min_maxima_value = the threshold value that determines whether to keep that maxima or not\n",
    "    \n",
    "    \n",
    "    \n",
    "    output:\n",
    "    The x and y coordinates of the maxima in the image (empty list if there are none...)\n",
    "    \"\"\"    \n",
    "\n",
    "    #find the maxima value within a specific neighborhood size    \n",
    "    data_max = filters.maximum_filter(data, neighborhood_size)\n",
    "    \n",
    "    #set the maxima as \"true\" for the pooint where this maxima is true\n",
    "    maxima = (data == data_max)\n",
    "    \n",
    "    #find the minima for comparison\n",
    "    data_min = filters.minimum_filter(data, neighborhood_size)\n",
    "    diff = ((data_max - data_min) > threshold)\n",
    "    \n",
    "    #Remove all points that are below the minimum threshold\n",
    "    maxima[diff == 0] = 0\n",
    "\n",
    "\n",
    "    \n",
    "    #May not be necessary...\n",
    "    labeled, num_objects = ndimage.label(maxima)\n",
    "    slices = ndimage.find_objects(labeled)\n",
    "    \n",
    "    \n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    #print (slices)\n",
    "    x, y = [], []\n",
    "    for dy,dx in slices:\n",
    "        x_center = (dx.start + dx.stop - 1)//2\n",
    "        y_center = (dy.start + dy.stop - 1)//2    \n",
    "        \n",
    "        reg_mean = np.mean(data[y_center-region_size:y_center + region_size,\n",
    "                                x_center-region_size:x_center+region_size])\n",
    "        if reg_mean > min_maxima_value:\n",
    "\n",
    "            x.append(int(x_center))\n",
    "            y.append(int(y_center))\n",
    "\n",
    "    #plt.imshow(data)\n",
    "    #plt.savefig('/tmp/data.png', bbox_inches = 'tight')\n",
    "\n",
    "    #plt.autoscale(False)\n",
    "    #plt.plot(x,y, 'ro')\n",
    "    #plt.savefig('/tmp/result.png', bbox_inches = 'tight')\n",
    "\n",
    "    #print (x, y)\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ROIs (image, Parameters, avg_radius = 4, thresh_tolerance = 0.5, threshold = 0):\n",
    "    \"\"\"\n",
    "    This function is responsible for finding ROIs within a cell using local maxima\n",
    "    and acts as an alternative to the machine learning approach.  It can produce\n",
    "    good results, but some of the parameters must be optimized for each experiment\n",
    "    \n",
    "    \n",
    "    In particular, you need to us\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #variables for local maxima\n",
    "    \n",
    "    max_neighborhood_size = Parameters.max_neighborhood_size\n",
    "    max_threshold= Parameters.max_threshold\n",
    "    avg_radius = Parameters.local_max_avg_radius\n",
    "    thresh_tolerance = Parameters.thresh_tolerance\n",
    "    IoU_match_thresh = Parameters.IoU_match_thresh\n",
    "    channel_thresholds = Parameters.channel_thresholds\n",
    "    \n",
    "\n",
    "\n",
    "    #Find the x,y points of the local maxima\n",
    "    seed = np.zeros(image.shape)\n",
    "    x, y = find_local_maxima (image, \n",
    "                              neighborhood_size=max_neighborhood_size, \n",
    "                              threshold=max_threshold, min_maxima_value = threshold)\n",
    "\n",
    "    overall_image = np.zeros(image.shape)\n",
    "\n",
    "\n",
    "    \n",
    "    ROI_List = []\n",
    "\n",
    "    for (x_val, y_val) in (zip(x,y)):\n",
    "        #Doesn't take care of the fact that y_val or x_val might be close to the edge (less than the tolerance)\n",
    "\n",
    "\n",
    "        average_value = np.mean(image[y_val- avg_radius: y_val + avg_radius,\n",
    "                                      x_val- avg_radius: x_val + avg_radius])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if average_value:\n",
    "            seed = np.zeros(image.shape)\n",
    "            seed[y_val, x_val] = 1\n",
    "            _ , mask = cv2.threshold(image,\n",
    "                                     average_value * (1-thresh_tolerance),\n",
    "                                     average_value*(1+thresh_tolerance),\n",
    "                                     cv2.THRESH_BINARY )\n",
    "\n",
    "            \n",
    "            roi_image = ndimage.binary_propagation(seed, mask = mask)\n",
    "\n",
    "\n",
    "            i, j = np.where(roi_image)\n",
    "            x_corner = min(i)\n",
    "            y_corner = min(j)\n",
    "            roi_subimage = roi_image[min(i): max(i),\n",
    "                                     min(j): max(j)]\n",
    "\n",
    "            current_ROI = ROIs(x = min(j), y = min(i), confidence = None, classification = None, data = roi_subimage)\n",
    "\n",
    "            \n",
    "            #print (current_ROI)\n",
    "            \n",
    "            if not ROI_List:\n",
    "                #print (current_ROI)\n",
    "                ROI_List.append(current_ROI)\n",
    "            \n",
    "            else:           \n",
    "                for compROI in ROI_List:\n",
    "                    IoU_match = 0\n",
    "                    IoU = calc_overlap(current_ROI, compROI)\n",
    "                    if IoU>IoU_match_thresh:\n",
    "                        IoU_match = 1\n",
    "                        #print (\"Already added a similar ROI\")\n",
    "                        break\n",
    "\n",
    "                if not IoU_match:\n",
    "                    #print (current_ROI)\n",
    "                    ROI_List.append(current_ROI)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #for testing purposes\n",
    "            overall_image = np.add(overall_image, np.multiply(image, roi_image))\n",
    "\n",
    "        #print (x_val, y_val, average_value, np.sum(roi_image), np.sum(mask), roi_subimage.shape)\n",
    "        #print (x_corner, y_corner, min(j), max(j),min(i), max(i), roi_subimage.shape)\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    #print (f\"Numer of ROIS is {len(ROI_List)}\")\n",
    "    plt.imshow(overall_image)\n",
    "    \n",
    "    \n",
    "    return (ROI_List)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  create_summary_columns(df):\n",
    "    \n",
    "    dataframe = df.copy()\n",
    "    \n",
    "    #precolumns are the columns like ROI that aren't important for the export\n",
    "    precolumns = 3\n",
    "    \n",
    "    summary_dataframe = pd.DataFrame([])\n",
    "    \n",
    "    timepoints = max(dataframe[precolumns:].columns, key = lambda x: x[0])[0]\n",
    "    print (timepoints)\n",
    "    \n",
    "    \n",
    "    channels = max(dataframe[precolumns:].columns, key = lambda x:x[1])[1]\n",
    "    print (channels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    statistics = {\"Mean\": np.mean, \n",
    "                  \"Stdev\": np.std,\n",
    "                  \"Count\": len, \"StdErr\": lambda x: np.std(x)/np.sqrt(len(x))}\n",
    "    \n",
    "    \n",
    "    \n",
    "    for t in range (timepoints+1):\n",
    "        \n",
    "        series = pd.Series([t], index = [(\" \",\" \",\"Time\")])\n",
    "        \n",
    "        for func in statistics:\n",
    "            new_series = dataframe.loc[0:, pd.IndexSlice[t,:,:]].apply(statistics[func])\n",
    "            new_series.index = [(func, i[1], i[2]) for i in new_series.index]\n",
    "            series = series.append(new_series)\n",
    "        \n",
    "        \n",
    "        columns = series.index\n",
    "        \n",
    "        #print (series)\n",
    "        summary_dataframe = summary_dataframe.append(series, ignore_index = True, sort = False)\n",
    "        \n",
    "    \n",
    "    \n",
    "    summary_dataframe.columns = pd.MultiIndex.from_tuples(summary_dataframe.columns, names = ['Stat', 'Channel', 'Para'])\n",
    "    \n",
    "\n",
    "    \n",
    "    #print (df.columns)\n",
    "    #print (summary_dataframe)\n",
    "    return summary_dataframe\n",
    "\n",
    "\n",
    "#create_summary_columns(sub_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell_comparisons(df, Parameters):\n",
    "    dataframe = df.copy()\n",
    "    \n",
    "    image_type_array = Parameters.image_type_array\n",
    "    \n",
    "    #image_type_bool = [image_type_array[i] == \"Anisotropy\" for i in range(len(image_type_array))]\n",
    "    \n",
    "    relative_values = False\n",
    "    AniChannel = \"AniAvg\"\n",
    "    IntChannel = \"Intensity\"\n",
    "    \n",
    "    #print (dataframe)\n",
    "    \n",
    "    statistics = {\"Mean\": np.mean, \n",
    "                  \"Stdev\": np.std,\n",
    "                  \"Count\": len, \"StdErr\": lambda x: np.std(x)/np.sqrt(len(x))}\n",
    "    \n",
    "    \n",
    "    cell_cell_comparisons = {}\n",
    "    print ()\n",
    "    \n",
    "    for channel, image_type in enumerate(image_type_array):\n",
    "        #print (channel, image_type)\n",
    "        if image_type == \"Anisotropy\" or image_type == \"Intensity\":\n",
    "            \n",
    "            if image_type == \"Anisotropy\":\n",
    "                channel_name = AniChannel\n",
    "                \n",
    "            elif image_type == \"Intensity\":\n",
    "                channel_name = IntChannel\n",
    "                \n",
    "            \n",
    "            \n",
    "            channel_subarray = dataframe.loc[:, pd.IndexSlice[:, channel, channel_name]]\n",
    "            channel_subarray = channel_subarray.dropna(how = 'any')\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print (image_type, (0, channel, channel_name))\n",
    "            first_channel = channel_subarray.loc[:, (0, channel, channel_name)].copy()\n",
    "            \n",
    "            if relative_values == True:        \n",
    "                for columns in channel_subarray.columns:\n",
    "                    channel_subarray.at[:, columns] = channel_subarray.loc[:, columns]/first_channel\n",
    "                \n",
    "            for functions in statistics:\n",
    "                channel_subarray[functions] = channel_subarray.apply(statistics[functions], axis = 1)\n",
    "\n",
    "            \n",
    "            cell_cell_comparisons.update({f\"{image_type}_Channel_{channel}\": channel_subarray})\n",
    "                \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Need to find number of timepoints and then do a comparison for the rows where there is a value in every row\n",
    "    \n",
    "    #print (image_type_bool)\n",
    "    \n",
    "    \n",
    "    #\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (cell_cell_comparisons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_file(text_path):\n",
    "    \n",
    "    skip_characters = [\"'\", \"#\", \"\\n\"]\n",
    "    \n",
    "    \n",
    "    for char in ['/', '\\\\']:\n",
    "        text_path = text_path.replace(char, os.sep)\n",
    "\n",
    "    print (text_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    config_variables = {}\n",
    "    with open(text_path, 'r') as f:\n",
    "        for lines in f:\n",
    "            if lines[0] not in skip_characters:           \n",
    "                param_input = \"\".join(lines.split())\n",
    "                variable, value = param_input.split('=')\n",
    "                #print (variable, value, param_input)\n",
    "                config_variables.update({variable: value})\n",
    "\n",
    "\n",
    "    float_variables = ['numerical_aperture',\n",
    "                       'index_of_refraction',\n",
    "                       'magnification',\n",
    "                       'gFactor',\n",
    "                       'max_filter_region',\n",
    "                       'max_threshold', \n",
    "                       'conf_thresh', \n",
    "                       'nms_thresh', \n",
    "                       'thresh_tolerance', \n",
    "                       'IoU_match_thresh']\n",
    "    \n",
    "    int_variables = ['classes', \n",
    "                     'local_max_avg_radius', \n",
    "                     'max_neighborhood_size']\n",
    "    \n",
    "    binary_variables = ['debug_mode', \n",
    "                        'root_dir_same_treatment', \n",
    "                        'machine_learning_mode', \n",
    "                        'use_cuda', \n",
    "                        \"segmentation_outputs\"]\n",
    "    \n",
    "    array_variables = {'channel_thresholds': \"int\",\n",
    "                       'channel_array': 'int',\n",
    "                       'image_type_array': 'str', \n",
    "                       'network_size':'int', \n",
    "                       'labels': 'str'}\n",
    "    \n",
    "    path_variables = ['weights_path']\n",
    "    \n",
    "    #Don't need this for anthing\n",
    "    string_variables = ['suffix']\n",
    "    \n",
    "    \n",
    "    for variables in config_variables:\n",
    "    \n",
    "    \n",
    "        #Convert Floats\n",
    "        if variables in float_variables:\n",
    "            config_variables[variables] = float(config_variables[variables])\n",
    "            \n",
    "        elif variables in int_variables:\n",
    "            config_variables[variables] = int(config_variables[variables])\n",
    "\n",
    "        #Convert Binary Variables\n",
    "        elif variables in binary_variables:\n",
    "            config_variables[variables] = (config_variables[variables].lower() == \"true\")\n",
    "\n",
    "        #Convert to arrays with the appropriate variable type\n",
    "        elif variables in array_variables:\n",
    "            var_type = array_variables[variables]\n",
    "            for c in ['[', ']', \"'\", '\"']:\n",
    "                config_variables[variables] = config_variables[variables].replace(c,\"\")\n",
    "            config_variables[variables] = config_variables[variables].split(',')\n",
    "            if var_type.lower() == \"int\":\n",
    "                config_variables[variables] = [int(x) for x in config_variables[variables]]\n",
    "                \n",
    "        elif variables in path_variables:\n",
    "            for char in ['/', '\\\\']:\n",
    "                config_variables[variables] = config_variables[variables].replace(char, os.sep)\n",
    "                \n",
    "        elif variables in string_variables:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            print (f'unknown variables found: {variables}')\n",
    "    \n",
    "    return config_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Detect Cells using Machine Learning\"\"\"\n",
    "\n",
    "\n",
    "def post_transform(boxes, scale, pad):\n",
    "    for box in boxes:\n",
    "        box.x_top_left -= pad[0]\n",
    "        box.y_top_left -= pad[1]\n",
    "\n",
    "        box.x_top_left *= scale\n",
    "        box.y_top_left *= scale\n",
    "        box.width *= scale\n",
    "        box.height *= scale\n",
    "    return boxes\n",
    "\n",
    "def output_ROIs (detections, im_h, im_w, segmentation = None):\n",
    "    ROI_list = []\n",
    "    for det in detections:\n",
    "\n",
    "        #Note, the pixels are rounded down, but it shouldn't matter since the segmentation network will\n",
    "        #do the pixel by pixel segmentation\n",
    "        x = int(det.x_top_left)\n",
    "        y = int(det.y_top_left)\n",
    "        height = int(det.height)\n",
    "        width = int(det.width)\n",
    "        \n",
    "        \n",
    "        #Ensure that the ROIs do not go over the edge of the image.  Alternatively, don't use ROIs that go over the edge...\n",
    "        if x<0:\n",
    "            width = width+x\n",
    "            x=0\n",
    "        if y<0:\n",
    "            height = height+y\n",
    "            y=0\n",
    "        height = min((im_h - y), height)\n",
    "        width = min((im_w - x), width)\n",
    "        \n",
    "        print (\"x\", int(det.x_top_left),\n",
    "               \"y\", int(det.y_top_left), \n",
    "               det.class_label, \n",
    "               det.confidence,\n",
    "               \"w\", det.width,\n",
    "               \"h\", det.height,\n",
    "              \"new_H\", height, \"new_W\", width )\n",
    "        \n",
    "        \n",
    "        #There are some boundary cases where the entire object will be detected off the screen\n",
    "        if (height >0) and (width >0):\n",
    "            fake_data = np.ones((height,width))\n",
    "\n",
    "\n",
    "            roi = ROIs(x = x,\n",
    "                       y = y, \n",
    "                       classification = det.class_label, \n",
    "                       confidence = det.confidence, \n",
    "                       data = fake_data)  #Use the data as ones for now... replace with segmentation later\n",
    "\n",
    "\n",
    "            ROI_list.append(roi)\n",
    "        \n",
    "    return (ROI_list)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def detect_ROIs(Parameters, image, debug_path = None):\n",
    "    \n",
    "    #Import the relevant parameters:\n",
    "    network_size = Parameters.network_size\n",
    "    network = Parameters.network\n",
    "    net_w, net_h = Parameters.network_size\n",
    "    device = Parameters.device\n",
    "    log = Parameters.log\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    save_check = True\n",
    "    show_check = False\n",
    "    show_label = True\n",
    "    use_cuda = True\n",
    "    img = image.copy()\n",
    "    \n",
    "    #Maybe this should already be set.. \n",
    "    network.training = False\n",
    "    \n",
    "    im_h, im_w = image.shape[:2]\n",
    "\n",
    "       \n",
    "    device = torch.device('cpu')\n",
    "    if use_cuda:\n",
    "        if torch.cuda.is_available():\n",
    "            log.debug('CUDA enabled')\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            log.error('CUDA not available')\n",
    "\n",
    "            \n",
    "    #print (\"Image Shape:\", img.shape)        \n",
    "    \n",
    "\n",
    "    #The control of the input should happen before this function...\n",
    "    #If only one slice, pad to 3 using the anisotropy ratios\n",
    "    #if img.shape[2] == 1:\n",
    "    #    print (\"There is only channel... extending\")\n",
    "    #    img = np.dstack([img, img*0.5, img*0.4])    \n",
    "    \n",
    "    \n",
    "    #Prep the image for the neural network\n",
    "    #print (\"Pre conversion\",img.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    img = img/np.amax(img)\n",
    "    img = img*255\n",
    "    img = img.astype('uint8')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Transform the image and prep it for the \n",
    "    img_tf = ln.data.transform.Letterbox.apply(img, dimension = network_size)\n",
    "    img_tf = tf.ToTensor()(img_tf)\n",
    "    img_tf.unsqueeze_(0)\n",
    "    img_tf = img_tf.to(device)\n",
    "\n",
    "\n",
    "    # Run the image through the neural net\n",
    "    with torch.no_grad():\n",
    "        output = network(img_tf)\n",
    "        \n",
    "    if im_w == net_w and im_h == net_h:\n",
    "        scale = 1\n",
    "    elif im_w / net_w >= im_h / net_h:\n",
    "        scale = im_w/net_w\n",
    "    else:\n",
    "        scale = im_h/net_h\n",
    "        \n",
    "    pad = int((net_w - im_w/scale) / 2), int((net_h - im_h/scale) / 2)\n",
    "\n",
    "    \n",
    "    #Convert the boxes into ROIs\n",
    "    converted_boxes = []\n",
    "    for b in output:\n",
    "        converted_boxes.append(post_transform(b, scale, pad))\n",
    "    \n",
    "    output = converted_boxes\n",
    "    \n",
    "    \n",
    "    image_markup = bbb.draw_boxes(img, output[0], color = (255,0,0), show_labels=show_label)\n",
    "    if Parameters.debug_mode == True:\n",
    "        if show_check:\n",
    "            cv2.imshow('image', image_markup)\n",
    "            cv2.waitKey(1000)\n",
    "            cv2.destroyAllWindows()\n",
    "        #print (output[0])\n",
    "        if save_check and debug_path:\n",
    "            cv2.imwrite(debug_path, image_markup)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Add the segmentation algorithm here when it is ready...\n",
    "    \n",
    "    \n",
    "    ROI_list = output_ROIs(output[0], im_h, im_w)\n",
    "   \n",
    "    #ROI_list = [ROIs(x=0, y=1000, data = np.ones((100,500)))]\n",
    "        \n",
    "    return ROI_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Start Here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Home\n",
    "data_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Documents{os.sep}Baseline\"\n",
    "data_path = r\"C:\\Users\\William\\Documents\\2018-08-14 Glucose Dose Response - Copy\\Cyto+Nuc\"\n",
    "#data_path = r\"D:\\[] ML Dataset\\OneDrive_1_1-22-2019\\More Confluent\"\n",
    "text_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Dropbox{os.sep}Python Analysis{os.sep}config.txt\"\n",
    "\n",
    "#text_path = r\"C:\\Users\\Rocheleau Analysis\\Dropbox\\Python Analysis\\config.txt\"\n",
    "#data_path = r\"D:\\Tester\\2019-01-18 ER Stress TC Experiment 4\"\n",
    "\n",
    "\n",
    "\n",
    "data_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline3\"\n",
    "text_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline3{os.sep}config.txt\"\n",
    "\n",
    "\n",
    "config_variables = parse_text_file (text_path)\n",
    "\n",
    "Parameters = ImagingParameters(data_path = data_path, **config_variables)\n",
    "\n",
    "if Parameters.debug_mode == True:\n",
    "    print(\"Loaded the following variables:\")\n",
    "    for variables in config_variables:\n",
    "        print(f'{variables: <25}: {config_variables[variables]}')\n",
    "        \n",
    "    if (Parameters.machine_learning_mode == True):\n",
    "        print (\"Here is the network...\")\n",
    "        print (Parameters.network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "dataframes = []\n",
    "dfs = Parameters.iterate_through_files()\n",
    "\n",
    "for index, items in enumerate(dfs):\n",
    "    save_path = f'{data_path}{os.sep}{index}.pkl'\n",
    "    items['Total'].drop((-1, -1, \"ROI\"), axis = 1).to_pickle(save_path)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print (f\"Total Time is {end_time - start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Organize and output the dataframes to excel files\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    print (f\"Dataframe {i}\")\n",
    "    sub_dataframe = dfs[i][\"Total\"]\n",
    "    print (sub_dataframe)\n",
    "    columns = sub_dataframe.columns\n",
    "    #sub_dataframe.loc[:, pd.IndexSlice[1,0,:]].mean()\n",
    "\n",
    "    writer = pd.ExcelWriter(f\"{data_path}{os.sep}output{i}.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "    sub_dataframe.to_excel(writer, \"Raw_Data\")\n",
    "    create_summary_columns(sub_dataframe).to_excel(writer, \"Summary\")\n",
    "\n",
    "    cell_cell_comparison = create_cell_comparisons(sub_dataframe, Parameters)\n",
    "    for key in cell_cell_comparison:\n",
    "        cell_cell_comparison[key].to_excel(writer, key)\n",
    "\n",
    "    writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new = pd.concat([dfs[0][\"Total\"], dfs[1][\"Total\"]], keys = [\"A\", 'B'], axis = 1)\n",
    "#new\n",
    "\n",
    "#sorted(Parameters.directory_list)\n",
    "#Parameters.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parameter Testing \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\William\\Documents\\2018-08-14 Glucose Dose Response - Copy\\Cyto+Nuc\"\n",
    "text_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Dropbox{os.sep}Python Analysis{os.sep}config.txt\"\n",
    "\n",
    "#text_path = r\"C:\\Users\\Rocheleau Analysis\\Dropbox\\Python Analysis\\config.txt\"\n",
    "#data_path = r\"D:\\Tester\\2019-01-18 ER Stress TC Experiment 4\"\n",
    "\n",
    "\n",
    "config_variables = parse_text_file (text_path)\n",
    "\n",
    "Parameters = ImagingParameters(data_path = data_path, **config_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "\n",
    "filepath = r\"C:\\Users\\William\\Documents\\2018-08-14 Glucose Dose Response - Copy\\Cyto+Nuc\\01 - 0-1mM Glucose (4 hours)\\Baseline_1\\Baseline_1_MMStack_1-Pos_003_002.ome.tif\"\n",
    "#filepath = r\"D:\\Tester\\2019-01-18 ER Stress TC Experiment 4\\GLC 1mM\\1_3\\1_3_MMStack_2-Pos_002_001.ome.tif\"\n",
    "\n",
    "\n",
    "#text_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Dropbox{os.sep}Python Analysis{os.sep}config.txt\"\n",
    "#text_path = r\"C:\\Users\\Rocheleau Analysis\\Dropbox\\Python Analysis\\config.txt\"\n",
    "channel = 1  #the first channel is 0\n",
    "import_config = False\n",
    "\n",
    "\n",
    "\n",
    "if import_config == True:\n",
    "    config_variables = parse_text_file (text_path)\n",
    "    Parameters = ImagingParameters(data_path = data_path, **config_variables)\n",
    "\n",
    "\n",
    "\n",
    "    neighborhood_size = Parameters.max_neighborhood_size\n",
    "    threshold = Parameters.max_threshold\n",
    "    reg_threshold = Parameters.channel_thresholds[channel]    \n",
    "    \n",
    "else:\n",
    "    neighborhood_size = 80\n",
    "    threshold = 1000\n",
    "    reg_threshold = 10000\n",
    "    \n",
    "    \n",
    "    \n",
    "print (f\"\"\"Parameters are...\n",
    "       Neighborhood Size = {neighborhood_size}\n",
    "       Threshold = {threshold}\n",
    "       Region Threshold = {reg_threshold}\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "offset = 0\n",
    "for i in range(channel):\n",
    "    offset = offset + Parameters.channel_array[i]\n",
    "    \n",
    "print (\"Total offset is: \", offset)\n",
    "\n",
    "\n",
    "data = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=offset, rescale=False))\n",
    "\n",
    "data_max = filters.maximum_filter(data, neighborhood_size)\n",
    "    \n",
    "#set the maxima as \"true\" for the pooint where this maxima is true\n",
    "maxima = (data == data_max)\n",
    "\n",
    "#find the minima for comparison\n",
    "data_min = filters.minimum_filter(data, neighborhood_size)\n",
    "diff = ((data_max - data_min) > threshold)\n",
    "\n",
    "#Remove all points that are below the minimum threshold\n",
    "maxima[diff == 0] = 0\n",
    "\n",
    "\n",
    "\n",
    "#May not be necessary...\n",
    "labeled, num_objects = ndimage.label(maxima)\n",
    "slices = ndimage.find_objects(labeled)\n",
    "\n",
    "\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "#print (slices)\n",
    "x, y = [], []\n",
    "for dy,dx in slices:\n",
    "    x_center = (dx.start + dx.stop - 1)//2\n",
    "\n",
    "    y_center = (dy.start + dy.stop - 1)//2\n",
    "    \n",
    "    reg_mean = np.mean(data[y_center-5:y_center + 5, x_center-5:x_center+5])\n",
    "    print (reg_mean, x_center, y_center)\n",
    "    if reg_mean > reg_threshold:\n",
    "\n",
    "        x.append(int(x_center))\n",
    "        y.append(int(y_center))\n",
    "\n",
    "#plt.imshow(data)\n",
    "#plt.savefig('/tmp/data.png', bbox_inches = 'tight')\n",
    "\n",
    "#plt.autoscale(False)\n",
    "#plt.plot(x,y, 'ro')\n",
    "#plt.savefig('/tmp/result.png', bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.gray()  # show the filtered result in grayscale\n",
    "ax1 = fig.add_subplot(221)  # left side\n",
    "ax2 = fig.add_subplot(222)  # right side\n",
    "ax3 = fig.add_subplot(212)  # right side\n",
    "\n",
    "\n",
    "\n",
    "#result = ndimage.maximum_filter(ascent, size=20)\n",
    "ax1.imshow(data)\n",
    "ax2.imshow(data_max)\n",
    "ax3.imshow(data)\n",
    "ax3.scatter(x, y, c='b')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Cells beyond this point are not part of the main program...\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create_cell_comparisons(sub_dataframe, Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"D://Documents//Documents//0000 New Scope//Baseline3//Treat1//Baseline_1//Baseline_1_MMStack_1-Pos_000_003.ome.tif\"\n",
    "image = np.asarray(bioformats.load_image(image_path))\n",
    "image = np.dstack([image, image*0.9, image*0.8])\n",
    "print (\"Max 1\", np.amax(image))\n",
    "image = ((image/np.amax(image))*255).astype('uint8')\n",
    "print (\"Max 2\", np.amax(image))\n",
    "#print (image)\n",
    "image2 = cv2.rectangle(image, (200,0), (400, 1000), (255,0,0), 20)\n",
    "plt.imshow(image2)\n",
    "\n",
    "save_path = \"D://Documents//Documents//0000 New Scope//Baseline3//debug//Treat1//Baseline_1//Baseline_1_MMStack_1-Pos_000_003.jpg\"\n",
    "\n",
    "\n",
    "imageio.imwrite(save_path, image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (dfs[3])\n",
    "for items in dfs:\n",
    "    for keys in items:\n",
    "        print (type(items[keys]), keys)\n",
    "        #items[keys].pop(\"ROI\")\n",
    "        items[keys].to_csv(\"D:/Documents/Documents/0000 New Scope/Baseline3/test.csv\")\n",
    "\n",
    "\n",
    "\"\"\"final_dataframe = pd.DataFrame([])\n",
    "\n",
    "for filenames in dfs[-1]:\n",
    "    print (f\"current filename is: {filenames}\")\n",
    "    df_interest = dfs[-1][filenames]\n",
    "    print (type(df_interest))\n",
    "    #print (df_interest)\n",
    "    if len(final_dataframe)==0:\n",
    "        print (\"need a new dataframe\")\n",
    "        final_dataframe = df_interest\n",
    "    else:\n",
    "        print (\"Appending\")\n",
    "        final_dataframe = final_dataframe.append(df_interest, ignore_index = True, sort = False)\n",
    "\n",
    "print (final_dataframe)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.ones((5,6))\n",
    "array = np.pad(array, ((2,3), (0,1)), 'constant')\n",
    "print (array)\n",
    "print (array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([], columns=[\"Image\", \"Index\", \"ROI\"])\n",
    "df.head()\n",
    "\n",
    "imparameters = ImageParams(f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline{os.sep}Baseline_1\",\n",
    "                         \"Baseline_1_MMStack_1-Pos_002_002.ome.tif\", Parameters.channel_array, Parameters.image_type_array)\n",
    "\n",
    "df2 = pd.DataFrame({\"Image\": [imparameters, 2], \"ROI\": [3,4]})\n",
    "df3 = df.append(df2, sort=False)\n",
    "df3.head()\n",
    "\n",
    "print (df3.at[0, \"Image\"])\n",
    "\n",
    "#for index, items in enumerate(df3[\"Image\"]):\n",
    "#    print (index, items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array = []\n",
    "array.append({\"array\": 1})\n",
    "print (\"array\" in array[-1])\n",
    "array.append([2,3])\n",
    "print (array[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example full program::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline_1\"\n",
    "dir_list = find_files(path)\n",
    "iterate_through_files (dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff  = pd.DataFrame({(\"A\", \"B\"): [1,2,3], (\"A\", \"C\"): [2,5,6], (\"G\"):[1,2,3]})\n",
    "dff.at[2, (\"A\", \"B\")]= 100\n",
    "for columns in dff.columns:\n",
    "    print (columns[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1, 2, 3, 43, 6, 5])\n",
    "arr2 = np.array([True, True, True, False, False, True])\n",
    "arr4 = arr1[:4].copy()\n",
    "arr3 = np.multiply (arr1, arr2)\n",
    "print (arr3)\n",
    "print (np.mean(arr3[arr3 !=0]))\n",
    "\n",
    "print (arr4)\n",
    "arr4[2] = 100\n",
    "print (arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = \"D:/Documents/Documents/0000 New Scope/Baseline3/Treat1/Baseline_1/Baseline_1_MMStack_1-Pos_000_003.ome.tif\"\n",
    "\n",
    "import_image = np.asarray(bioformats.load_image(new_path, t=0, rescale = False)).astype('float')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_image = import_image.copy()\n",
    "\n",
    "new_image [new_image <  10000] = np.nan\n",
    "\n",
    "plt.imshow(new_image)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "\n",
    "fgmask = fgbg.apply(import_image)\n",
    "cv2.imshow('frame',fgmask)\n",
    "k = cv2.waitKey(30) & 0xff\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BF Matcher\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "bio_loc = f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_002_002.ome.tif'\n",
    "\n",
    "bio_para_import = np.asarray(bioformats.load_image(bio_loc, \n",
    "                                          c = 0, z=0, t=1, rescale=False))\n",
    "\n",
    "bio_perp_import = np.asarray(bioformats.load_image(bio_loc, \n",
    "                                          c = 0, z=0, t=2, rescale=False))\n",
    "\n",
    "bio_para = skimage.img_as_ubyte(bio_para_import)\n",
    "bio_perp = skimage.img_as_ubyte(bio_perp_import)\n",
    "\n",
    "filtered_para = cv2.bilateralFilter(bio_para, 9, 75, 75)\n",
    "\n",
    "print (type(bio_para[0,0]))\n",
    "print(cv2.imread(bio_loc, 0).shape)\n",
    "#bio_para = cv2.imread(bio_loc, 0)\n",
    "\n",
    "#bio_perp = cv2.imread(bio_loc, 0)\n",
    "\n",
    "print (type(bio_para[0,0]))\n",
    "\n",
    "b = cv2.normalize(bio_para_import, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n",
    "\n",
    "\n",
    "\n",
    "print (bio_para.shape)\n",
    "print (bio_para[:4,:4], bio_perp[:4, :4])\n",
    "print (b[:4,:4])\n",
    "print(type(b[0,0]))\n",
    "\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "kp1, des1 = orb.detectAndCompute(bio_para, None)\n",
    "kp2, des2 = orb.detectAndCompute(bio_perp, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "\n",
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "\n",
    "img3 = cv2.drawMatches(bio_para, kp1, bio_perp, kp2, matches[:10], None, flags = 2)\n",
    "cv2.imshow(\"Matches\", img3)\n",
    "#plt.imshow(bio_para)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#fig, axs = plt.subpolots(1, 1)\n",
    "#axs = plt.hist(bio_para)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "cv2.imshow(\"Para\", bio_para)\n",
    "cv2.imshow(\"Bilateral\", filtered_para)\n",
    "cv2.imshow(\"Perp\", bio_perp)\n",
    "cv2.imshow(\"Difference\", (bio_para - bio_perp)*100)\n",
    "cv2.imshow(\"Normalizes\", b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#print (bioformats.get_omexml_metadata(path=f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_001.ome.tif'))\n",
    "\n",
    "\n",
    "print (kp1, des1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,2,3,4], [5,6,7,8], 'ro')\n",
    "plt.axis([0,10,0,20])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bio_para_reshape = bio_para_import.reshape(-1, 1)\n",
    "print (bio_para_reshape.shape)\n",
    "bio_para_reshape2 = filtered_para.reshape(-1, 1)\n",
    "\n",
    "x = 100+ 15*np.random.randn(10000)\n",
    "#n, bins, patches = plt.hist(bio_para_reshape, 50)\n",
    "n, bins, patches = plt.hist(bio_para_reshape2, 50)\n",
    "print (max(bio_para_reshape2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def find_maxima (image, sigma = 9, h_value = None):\n",
    "    \n",
    "    if not h_value:\n",
    "        h_value = max(image)/1000\n",
    "              \n",
    "    \n",
    "    proc_image = cv2.GaussianBlur(img, (sigma, sigma), 0)\n",
    "    \n",
    "    local_maxima = extrema.h_maxima(proc_image, h_value)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (local_maxima)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "local_maximums = find_maxima(bio_para_import, 1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize= (15,5))\n",
    "\n",
    "ax[0].imshow(bio_para_import)\n",
    "\n",
    "ax[1].imshow(local_maximums)\n",
    "\n",
    "print (find_maxima(bio_para_import, 1, 1))\n",
    "\n",
    "x = np.arange(bio_para_import.shape[1])\n",
    "y = np.arange(bio_para_import.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "#x, y = np.meshgrid(x, y)\n",
    "#ax[2].scatter(x, y, c=local_maximums[x,y])\n",
    "#ax[2].show()\n",
    "\n",
    "plt.imshow(find_maxima(bio_para_import, 1, 50))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "xy = peak_local_max(bio_para_import, min_distance=5,threshold_abs=1200)\n",
    "plt.scatter(xy[:, 0], xy[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "y = np.arange(16)\n",
    "test_data = np.random.randint(low=0,high=65535, size=(10, 16))\n",
    "\n",
    "#scatter plot the measurements with\n",
    "# x - measurement index (0-9 in this case)\n",
    "# y - byte value index (0-15 in this case) \n",
    "# c = test_data[x,y]\n",
    "\n",
    "x, y = np.meshgrid(x,y)\n",
    "plt.scatter(x,y,c=test_data[x,y])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline_1\"\n",
    "\n",
    "print (os.listdir(data_path)[4])\n",
    "print (f'{data_path}{os.sep}{os.listdir(data_path)[4]}')\n",
    "\n",
    "img = cv2.imread(f'{data_path}{os.sep}{os.listdir(data_path)[4]}')*100\n",
    "#cv2.imshow(\"image\", (img[:,:,1]*1000))\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "cv2.circle(img, (2000,1000), 400, (255,255,255), -1)\n",
    "points = np.array([[1,1], [33,4], [100,20], [50, 400]], np.int32)\n",
    "cv2.polylines(img, [points], True, (0,255,255), 3)\n",
    "cv2.putText(img, \"Hello, world!\", (0,100), cv2.FONT_HERSHEY_COMPLEX, 4, (255, 0, 0))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "#img = np.ones((100,100,3))*1\n",
    "#img[:,:,2] = np.arange(0, 100*100, 1).resize((100,100))\n",
    "print (img[:,:,2])\n",
    "\n",
    "gg = calculate_anisotropy(image = img, Parameters = Parameters)\n",
    "\n",
    "\n",
    "print (gg.shape)\n",
    "cv2.imwrite(f'{path}{os.sep}{os.listdir(path)[7]}2.tiff', gg)\n",
    "\n",
    "#print (sum(sum(img-gg)))\n",
    "\n",
    "#cv2.imshow(\"image\", (img-gg)*1000)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Thresholding options\n",
    "Works Well\n",
    "\n",
    "from skimage.feature import peak_local_max\n",
    "xy = peak_local_max(bio_para_import, min_distance=2,threshold_abs=1500)\n",
    "plt.scatter(xy[:, 0], xy[:, 1])\n",
    "\n",
    "\n",
    "Works Better:\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fname = '/tmp/slice0000.png'\n",
    "neighborhood_size = 40\n",
    "threshold = 700\n",
    "\n",
    "\n",
    "data = bio_para_import\n",
    "#data = scipy.misc.imread(fname)\n",
    "\n",
    "data_max = filters.maximum_filter(data, neighborhood_size)\n",
    "maxima = (data == data_max)\n",
    "data_min = filters.minimum_filter(data, neighborhood_size)\n",
    "diff = ((data_max - data_min) > threshold)\n",
    "maxima[diff == 0] = 0\n",
    "\n",
    "labeled, num_objects = ndimage.label(maxima)\n",
    "slices = ndimage.find_objects(labeled)\n",
    "x, y = [], []\n",
    "for dy,dx in slices:\n",
    "    x_center = (dx.start + dx.stop - 1)/2\n",
    "    x.append(x_center)\n",
    "    y_center = (dy.start + dy.stop - 1)/2    \n",
    "    y.append(y_center)\n",
    "\n",
    "plt.imshow(data)\n",
    "#plt.savefig('/tmp/data.png', bbox_inches = 'tight')\n",
    "\n",
    "plt.autoscale(False)\n",
    "plt.plot(x,y, 'ro')\n",
    "#plt.savefig('/tmp/result.png', bbox_inches = 'tight')\n",
    "\n",
    "print (x, y)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all of the files in the current path\n",
    "print(os.path.isdir(path))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"for items in os.listdir(path):\n",
    "    #print (items, \"file:\",  os.path.isfile(f\"{path}/{items}\"), \"dir:\",  os.path.isdir(f'{path}/{items}'))\n",
    "    img = cv2.imread(f'{path}/{items}')\n",
    "    cv2.imshow('image', img*100)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Options for going up ap directory:\n",
    "\n",
    "1) split path by \"/\" __file__.rsplit(os.sep, 2)  or print(path.rsplit('/')[-3])\n",
    "2) iterate up twice os.path.dirname(os.path.dirname(path))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing the find_files function\n",
    "\"\"\"\n",
    "\n",
    "path2 = \"D:\\\\Documents\\\\Documents\\\\0000 New Scope\\\\2018-08-01 Nuclear Parameter Test\"\n",
    "#path2 = \"D:/Documents/Documents/0000 New Scope/2018-08-01 Nuclear Parameter Test/N2(600-40)/Baseline/Baseline_1\"\n",
    "dir_list = {}\n",
    "result = find_files(path2, dir_list)\n",
    "\n",
    "\n",
    "for items in result:\n",
    "    print (f'{items}, {result[items]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline_1\"\n",
    "print (data_path)\n",
    "directory_list = find_files(data_path, {})\n",
    "print (directory_list)\n",
    "iterate_through_files(directory_list)\n",
    "\n",
    "\n",
    "bio_im = np.asarray(bioformats.load_image(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_001.ome.tif', \n",
    "                                          c = 0, z=0, t=6, rescale=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "img=mpimg.imread(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_000.ome.tif')\n",
    "print (img.shape)\n",
    "\n",
    "im = io.imread(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_000.ome.tif')\n",
    "print ((im.shape))\n",
    "\n",
    "pilim = Image.open(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_000.ome.tif')\n",
    "print (pilim.n_frames)\n",
    "print (pilim)\n",
    "print (pilim.info)\n",
    "print (pilim.load())\n",
    "pilim.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
