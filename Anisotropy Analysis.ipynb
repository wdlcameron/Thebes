{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from skimage import io\n",
    "from skimage.morphology import extrema\n",
    "from skimage.measure import label\n",
    "\n",
    "import skimage\n",
    "\n",
    "import scipy\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "\n",
    "\n",
    "import imageio\n",
    "\n",
    "import javabridge \n",
    "import bioformats\n",
    "javabridge.start_vm(class_path=bioformats.JARS, max_heap_size='8G')\n",
    "\n",
    "#import net.imageJ.ImageJ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#For the YOLO Network\n",
    "import logging\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "import brambox.boxes as bbb\n",
    "import lightnet as ln\n",
    "\n",
    "\n",
    "\n",
    "#For the GUI\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\n",
    "\n",
    "#for key bindings\n",
    "from matplotlib.backend_bases import key_press_handler\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# See your current version of python/anaconda\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagingParameters():\n",
    "    def __init__(self, data_path, **kwargs):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "            #print (key, value, getattr(self, key))\n",
    "            \n",
    "            \n",
    "        \n",
    "        #Assert that the core variables are all set correctly.\n",
    "        core_variables = ['channel_array', 'channel_thresholds', 'suffix', 'machine_learning_mode']\n",
    "        print (core_variables)\n",
    "        self.assert_variables(core_variables, \"Core\")\n",
    "\n",
    "        \n",
    "      \n",
    "        \n",
    "        #Store the dataframes from each of the experiments\n",
    "        self.directory_list = self.find_files(self.data_path, {})\n",
    "        self.dataframes = []\n",
    "        #print(self.directory_list)\n",
    "        \n",
    "        \n",
    "        #List containing all of the final dataframes for convenience\n",
    "        self.experiments = []\n",
    "        \n",
    "        \n",
    "        \n",
    "                 \n",
    "        machine_learning_args = [\"\"]\n",
    "        if (self.machine_learning_mode == True):\n",
    "            \n",
    "            network_variables = ['classes', 'network_size', 'labels', 'conf_thresh', 'nms_thresh', 'use_cuda']\n",
    "            self.assert_variables(network_variables, \"Network\")              \n",
    "                 \n",
    "            self.initializeROINetwork()\n",
    "            \n",
    "        else:\n",
    "            automatic_detection_variables = ['max_neighborhood_size', \n",
    "                                             'max_threshold', \n",
    "                                             'local_max_avg_radius', \n",
    "                                             'thresh_tolerance', 'IoU_match_thresh']\n",
    "            self.assert_variables(automatic_detection_variables, \"Local Max Detection\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        subframes = 0\n",
    "        for items in self.channel_array:\n",
    "            subframes += items\n",
    "            \n",
    "        self.frames_per_timepoint = subframes\n",
    "        \n",
    "        \n",
    "        \n",
    "        #If you are using the anisotropy analysis, create the relevant correction factors:\n",
    "\n",
    "        \n",
    "        if \"Anisotropy\" in self.image_type_array:\n",
    "            \n",
    "            \n",
    "            #Assert that the correct variables are defined\n",
    "            ani_variables = ['numerical_aperture', 'index_of_refraction', 'magnification', 'gFactor']\n",
    "            self.assert_variables(ani_variables, \"Anisotropy\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            asin = math.asin(self.numerical_aperture/self.index_of_refraction) \n",
    "            cos = math.cos(asin)\n",
    "\n",
    "            kA = (2.0 - 3.0 * cos + cos * cos * cos) / (6.0 * (1.0 - cos))\n",
    "            kB = (1.0 - 3.0 * cos + 3.0 * cos * cos - cos * cos * cos) / (24.0 * (1.0 - cos))\n",
    "            kC = (5.0 - 3.0 * cos - cos * cos - cos * cos * cos) / (8.0 * (1.0 - cos))\n",
    "\n",
    "\n",
    "            self.kA = kA\n",
    "            self.kB = kB\n",
    "            self.kC = kC\n",
    "\n",
    "            print (kA, kB, kC)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    def assert_variables(self, variables, identifier = \"\"):\n",
    "            for attribute in variables:\n",
    "                assert hasattr(self, attribute), f\"Error: {identifier} attribute {attribute} was not set.  Check your config file\"\n",
    "\n",
    "\n",
    "    def find_files(self, path, directory_list = {}):\n",
    "        all_files = os.listdir(path)\n",
    "        #print (all_files)\n",
    "        for files in all_files:\n",
    "            #print (path, os.path.dirname(path))\n",
    "\n",
    "            #When you find the appropriate file, add the directory to the dictionary for processing\n",
    "            if os.path.isfile(f'{path}{os.sep}{files}'):\n",
    "                #print (\"Found a file\")\n",
    "                if files.endswith(self.suffix):\n",
    "                    #print (f\"Ends with ome.tif ({files})\")\n",
    "                    prev_directory = os.path.dirname(path)\n",
    "                    current_directory = path.replace(prev_directory, \"\")\n",
    "                    if prev_directory in directory_list:\n",
    "                        directory_list[prev_directory][current_directory] = None\n",
    "\n",
    "                    else:\n",
    "                        directory_list[prev_directory] = {current_directory : None}\n",
    "\n",
    "\n",
    "\n",
    "            elif os.path.isdir(f'{path}{os.sep}{files}'):\n",
    "                directory_list = self.find_files(f'{path}{os.sep}{files}', directory_list)\n",
    "                #print (\"Found a directory\")\n",
    "\n",
    "\n",
    "        return (directory_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def iterate_through_files(self):\n",
    "        \"\"\"\n",
    "        The purpose of this function is to iterate through all of the files in the directory list and then\n",
    "        send them to the relevant analysis program\n",
    "        \"\"\" \n",
    "        \n",
    "        dataframes = self.dataframes\n",
    "        suffix = self.suffix\n",
    "        directory_list = self.directory_list\n",
    "        debug_mode = self.debug_mode\n",
    "        machine_learning_mode = self.machine_learning_mode\n",
    "\n",
    "\n",
    "        if debug_mode == True:\n",
    "            #Start a new dataframe each time\n",
    "            dataframes = []\n",
    "\n",
    "\n",
    "\n",
    "        #knowing the previous directory we looked at helps to determine whether we should append the\n",
    "            #results to a current dataframe or not.  You want to append if the data are from the same cells\n",
    "        prev_directory = \"\"\n",
    "        new_dataframe = True\n",
    "\n",
    "\n",
    "        for root_dir in directory_list:\n",
    "            #note: there will usually only be one subdirectory per root_dir\n",
    "            for directories in directory_list[root_dir]:\n",
    "                print (os.path.dirname(os.path.dirname(directories)))\n",
    "                if os.path.dirname(os.path.dirname(prev_directory)) == os.path.dirname(os.path.dirname(directories)):\n",
    "                    print (\"From the same core directory\")\n",
    "                    new_dataframe = False\n",
    "                else:\n",
    "                    print (\"Not from the same core directory\")\n",
    "                    #if they do not share the same root directory, you need to create a new dataframe\n",
    "                    new_dataframe = True\n",
    "                    dataframes.append({})\n",
    "\n",
    "\n",
    "                file_list = os.listdir(f'{root_dir}{directories}')\n",
    "\n",
    "\n",
    "                for files in file_list:\n",
    "                    if files.endswith(suffix):\n",
    "\n",
    "                        #store all the relevant information about the image in a new class                    \n",
    "                        current_Image = ImageClass(f'{root_dir}{directories}',\n",
    "                                                  files, Parameters.channel_array,\n",
    "                                                  Parameters.image_type_array, Parameters.channel_thresholds)\n",
    "\n",
    "                        #Analyze the image\n",
    "                        \n",
    "                        dataframes = image_Analysis(current_Image=current_Image, \n",
    "                                                         Parameters = Parameters, \n",
    "                                                         dataframes = dataframes)\n",
    "\n",
    "\n",
    "\n",
    "                prev_directory = directories\n",
    "\n",
    "\n",
    "        #consolidate the dataframes\n",
    "        dataframes = self.consolidate_dataframes(dataframes)\n",
    "\n",
    "        self.dataframes = dataframes\n",
    "        return (dataframes)\n",
    "\n",
    "            \n",
    "            \n",
    "    def consolidate_dataframes(self, dataframes):\n",
    "\n",
    "        \"\"\"\n",
    "        Combine the dataframes from each image into one consolidated dataframe\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        #dataframes = self.dataframes\n",
    "       \n",
    "        for index, _  in enumerate(dataframes):   \n",
    "            final_dataframe = pd.DataFrame([])\n",
    "            for filenames in dataframes[index]:\n",
    "                #print (f\"current filename is: {filenames}\")\n",
    "                df_interest = dataframes[index][filenames]\n",
    "                #print (type(df_interest))\n",
    "                #print (df_interest)\n",
    "                if len(final_dataframe)==0:\n",
    "                    #print (\"need a new dataframe\")\n",
    "                    final_dataframe = df_interest\n",
    "                else:\n",
    "                    #print (\"Appending\")\n",
    "                    final_dataframe = final_dataframe.append(df_interest, ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "            dataframes[index] = {\"Total\": final_dataframe}\n",
    "            self.experiments = self.experiments.append(final_dataframe)\n",
    "            #print (final_dataframe)\n",
    "\n",
    "\n",
    "        self.dataframes = dataframes\n",
    "        \n",
    "\n",
    "        return (dataframes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def initializeROINetwork(self):\n",
    "        #These will eventually be in a configuration file\n",
    "        self.log = logging.getLogger('lightnet.detect')\n",
    "        \n",
    "        \n",
    "        #self.classes = 20\n",
    "        #NETWORK_SIZE = (416, 416)\n",
    "        #self.network_size = [1482, 2535]  #Easier if a multiple of 13 or 26\n",
    "        #self.labels = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "        #          'bus', 'car', 'cat', 'chair', 'cow',\n",
    "        #          'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "        #          'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "        #self.conf_thresh = .20\n",
    "        #self.nms_thresh = .4\n",
    "        #self.use_cuda = True\n",
    "        \n",
    "\n",
    "        #Use the GPU if available and wanted\n",
    "        self.device = torch.device('cpu')\n",
    "        if self.use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                self.log.debug('CUDA enabled')\n",
    "                self.device = torch.device('cuda')\n",
    "            else:\n",
    "                self.log.error('CUDA not available')\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.network = ln.models.Yolo(self.classes,\n",
    "                                      conf_thresh = self.conf_thresh,\n",
    "                                      nms_thresh = self.nms_thresh,)\n",
    "    \n",
    "        self.network.postprocess.append(ln.data.transform.TensorToBrambox(self.network_size, self.labels))\n",
    "        self.network.load(self.weights_path)\n",
    "    \n",
    "        self.network = self.network.to(self.device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def create_pd_dataframe():\n",
    "    \n",
    "    dataframe = pd.DataFrame(columns=[(-1, -1,  \"Image\"), (-1,-1,\"Index\"), (-1, -1, \"ROI\")])\n",
    "    #dataframe = pd.DataFrame(columns=[\"Image\", \"Index\", \"ROI\"])\n",
    "        \n",
    "    \n",
    "    return (dataframe)\n",
    "\n",
    "#Should be a subclass of the imageing parameters\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClass():\n",
    "    def __init__(self, directory, filename, channel_array, image_type_array, channel_thresholds):\n",
    "        self.directory = directory \n",
    "        self.filename = filename\n",
    "        self.file_path = (f'{directory}{os.sep}{filename}')\n",
    "\n",
    "        \n",
    "        \n",
    "        self.dir_name = directory.replace(os.path.dirname(directory), \"\")\n",
    "        self.upper_dir_name = os.path.dirname(directory).replace (os.path.dirname(os.path.dirname(directory)), \"\")[1:]\n",
    "        \n",
    "        self.ROI_list = []\n",
    "        \n",
    "        \n",
    "        image = Image.open(self.file_path)\n",
    "        self.total_frames = image.n_frames\n",
    "        self.width = image.width\n",
    "        self.length = image.height\n",
    "        \n",
    "        self.channel_array = channel_array\n",
    "        self.image_type_array = image_type_array\n",
    "        \n",
    "        self.channel_thresholds = channel_thresholds\n",
    "        \n",
    "        assert (len(channel_array) == len(image_type_array)), \"Anisotropy and Channel arrays are not of equal length\"\n",
    "              \n",
    "        self.channel_offset = np.zeros(len(channel_array))\n",
    "        \n",
    "        images_per_timepoint = 0\n",
    "        for index, items in enumerate(channel_array):\n",
    "            #print (index, items, images_per_timepoint)\n",
    "            self.channel_offset[index] = images_per_timepoint\n",
    "            images_per_timepoint += items\n",
    "        \n",
    "        self.images_per_timepoint = images_per_timepoint\n",
    "        self.timepoints = self.total_frames // images_per_timepoint\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROIs():\n",
    "    def __init__(self, x, y, data, classification=None, confidence=None):\n",
    "        \"\"\"\n",
    "            ______x_______\n",
    "            |            |\n",
    "           y|            |\n",
    "            |            |\n",
    "            |____________|\n",
    "        \n",
    "        \n",
    "        Note: this standard was adopted as it conforms to both bramboxes and CV2 drawing formats.\n",
    "        For numpy arrays, axis 0 is Y and axis 1 is X.  Therefore indexing should be\n",
    "        np.array[y1:y1, x1:x2] when dealing with the images as numpy arrays\n",
    "        \n",
    "        \"\"\"       \n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.data = data\n",
    "        self.classification = classification\n",
    "        self.confidence = confidence\n",
    "        \n",
    "        y_length, x_length = data.shape\n",
    "        \n",
    "        self.x_length = x_length\n",
    "        self.y_length = y_length\n",
    "        \n",
    "    \n",
    "#Should make this a subfunction of the ROI class\n",
    "\n",
    "\n",
    "\n",
    "def calc_overlap(ROI1, ROI2, threshold = 0.8):\n",
    "    \"\"\"\n",
    "    Calculate the IoU for two ROIs\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    x1, y1, x1Len, y1Len = ROI1.x, ROI1.y,  ROI1.x_length, ROI1.y_length\n",
    "    x2, y2, x2Len, y2Len = ROI2.x, ROI2.y,  ROI2.x_length, ROI2.y_length\n",
    "    \n",
    "    \n",
    "    box1_Area = (x1Len * y1Len)\n",
    "    box2_Area = (x2Len * y2Len)\n",
    "    #print (\"b1 Area\", box1_Area, \"b2 Area\", box2_Area)\n",
    "    \n",
    "    \n",
    "    inter_Area = max(0, (min(x1+x1Len, x2+x2Len)-max(x1, x2)))*max(0, (min(y1+y1Len, y2+y2Len) - max(y1, y2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (box1_Area or box2_Area):\n",
    "        IoU = inter_Area / (box1_Area + box2_Area - inter_Area + 0.001)\n",
    "    else:\n",
    "        IoU = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (IoU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anisotropy(image, Parameters):\n",
    "    \"\"\"\n",
    "    Parameters contains:\n",
    "        NA - Numerical Aperture\n",
    "        index_of_refraction - Index of Refraction for the immersion media\n",
    "        mag - Magnification\n",
    "        gFactor - G-Factor for the detector\n",
    "        \n",
    "        kA - Correctional Factors for high NA\n",
    "        kB - Correctional Factors for high NA\n",
    "        kC - Correctional Factors for high NA\n",
    "        \n",
    "        \n",
    "    image.shape[-1] should be equal to 3 with channels: Open, Parallel, Perpendicular\n",
    "    \"\"\"\n",
    "    \n",
    "    #image.shape[-1] should be equal to 3 with channels: Open, Parallel, Perpendicular \n",
    "    assert image.shape[2] == 3, f\"Anisotropy image was expecting 3 channels, but got: {image.shape[2]}\"\n",
    "    \n",
    "    \n",
    "    Ka = Parameters.kA\n",
    "    Kb = Parameters.kB\n",
    "    Kc = Parameters.kC\n",
    "    \n",
    "    \n",
    "    G = Parameters.gFactor\n",
    "    \n",
    "    \n",
    "    anisotropy_image = np.zeros((image.shape))\n",
    "\n",
    "    Para = image[:,:,1]\n",
    "    Perp = image[:,:,2]\n",
    "\n",
    "    Ix = ((Kb * Para - Kc * Perp*G)/(Ka*Kb + Kb**2 -Ka*Kc - Kc**2))\n",
    "    Iy = ((((Ka + Kb) * Perp*G) - (Ka+Kc)*Para)/(Ka*Kb+Kb**2-Ka*Kc-Kc**2))\n",
    "    \n",
    "    anisotropy_image[:,:,0] = Iy\n",
    "    anisotropy_image[:,:,1] = Ix\n",
    "    anisotropy_image[:,:,2] = 0\n",
    "    \n",
    "    numerator = np.add(Iy, np.multiply(Ix, -2*G))\n",
    "    denominator = np.add(Iy, np.multiply(Ix, 2*G))\n",
    "       \n",
    "        \n",
    "    anisotropy_image[:,:,-1] = np.divide (numerator, denominator, where=denominator!=0)\n",
    "    #anisotropy_image[:,:,2] = np.divide((np.add(Iy, np.multiply(Ix, -2*G))),(np.add(Iy, np.multiply(Ix, 2*G)))) \n",
    "    \n",
    "    return (anisotropy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_Analysis(current_Image, Parameters, dataframes = []):\n",
    "    \"\"\"\n",
    "    Analyze the current file.  Whether you are using machine learning or an algorithm, much of the process is the same\n",
    "    \n",
    "    current_Image:\n",
    "        directory\n",
    "        filename\n",
    "        file_path\n",
    "        timepoints\n",
    "        total_frames\n",
    "        width\n",
    "        length\n",
    "        channel_array\n",
    "        channel_offset\n",
    "        image_type_array\n",
    "        images_per_timepoint\n",
    "        \n",
    "        dir_name\n",
    "        upper_dir_name\n",
    "        \n",
    "    \n",
    "    prev_images is a dictionary of all of the most current values from the previous images\n",
    "        If a cell is found in the first image but not the second, it will still show up in the prev_images for the third image \n",
    "    \n",
    "    \n",
    "    dataframes is a list of all the dataframes associated with the analysis.\n",
    "        different groups of data should have different dataframes (aka, data for a different graph)\n",
    "        \n",
    "        Dataframes is a list of dictionaries, each containing a dataframe for each image that it is analyzing.\n",
    "        Once the analysis is complete, the dictionary will be replaced with a single entry dictionary\n",
    "        {\"Total\": pd.DataFrame}\n",
    "    \n",
    "       \n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    #g_factor = Parameters.g_factor    \n",
    "\n",
    "        \n",
    "    #Import the relevant parameters from the ImagingParameters Class   \n",
    "    root_dir = Parameters.data_path\n",
    "    suffix = Parameters.suffix\n",
    "    debug_mode = Parameters.debug_mode\n",
    "    machine_learning_mode = Parameters.machine_learning_mode\n",
    "    \n",
    "    #Import the relevant parameters from the ImageClass Class    \n",
    "    directory = current_Image.directory\n",
    "    total_frames = current_Image.total_frames\n",
    "    timepoints = current_Image.timepoints\n",
    "    filepath = current_Image.file_path\n",
    "    filename = current_Image.filename\n",
    "    channel_offset = current_Image.channel_offset\n",
    "    image_type_array = current_Image.image_type_array\n",
    "    images_per_timepoint = current_Image.images_per_timepoint\n",
    "    upper_dir_name = current_Image.upper_dir_name\n",
    "    channel_thresholds = current_Image.channel_thresholds\n",
    "    \n",
    "    \n",
    "    \n",
    "    general_strings = ['Image', 'ROI']\n",
    "    anisotropy_strings = ['Para', 'Perp', 'AniPixel', 'AniAvg']\n",
    "    intensity_strings = ['Intensity']\n",
    "    \n",
    "    \n",
    "    para_intensity_str = f'Para'\n",
    "    perp_intensity_str = f'Perp'\n",
    "    anipix_intensity_str = f'AniPixel'\n",
    "    aniavg_intensity_str = f'AniAvg'\n",
    "\n",
    "    intensity_string = \"Intensity\"\n",
    "    \n",
    "    image_string = \"Image\"\n",
    "    image_ROI_string = \"ROI\"\n",
    "    \n",
    "\n",
    "        \n",
    "    if filename not in dataframes[-1]:\n",
    "        new_dataframe = create_pd_dataframe()\n",
    "        dataframes[-1].update({filename: new_dataframe})\n",
    "    \n",
    "    \n",
    "    current_dataframe = dataframes[-1][filename]\n",
    "    \n",
    "    \n",
    "    all_columns = current_dataframe.columns\n",
    "    \n",
    "    master_column_offset = 0\n",
    "    if len(all_columns)>3:\n",
    "        master_column_offset = max(all_columns[3:], key = lambda x: x[0])[0] + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(f'root_dir: {Parameters.data_path}')\n",
    "    #print (f'directory: {current_Image.directory}')\n",
    "    #print (f'filepath: {current_Image.file_path}')\n",
    "    #print (f'filename: {current_Image.filename}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ROI_match_threshold = 0.4\n",
    "    \n",
    "    \n",
    "    print (f'current image is :{current_Image.filename} in {upper_dir_name} and it has {timepoints} timepoints and length df: {len(dataframes)}')\n",
    "    for time in range(timepoints):\n",
    "        \n",
    "        #for string in general_strings:\n",
    "        #    current_dataframe[(t, channel, string)] = np.nan\n",
    "        \n",
    "        for channel, (image_type, offset) in enumerate(zip(image_type_array, channel_offset)):\n",
    "            #print (f\"Current time is: {t}, anisotropy value is {anisotropy} and offset is {offset}\")\n",
    "            total_offset = time * images_per_timepoint + offset\n",
    "            t = time + master_column_offset\n",
    "            \n",
    "            if image_type == \"Anisotropy\" or image_type == \"Intensity\":\n",
    "            \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Open the image\n",
    "                \n",
    "                Images = {}\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                if image_type == \"Anisotropy\":\n",
    "                    Images['Open'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 0, rescale=False))\n",
    "                    Images['Para'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 1, rescale=False))\n",
    "                    Images['Perp'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 2, rescale=False))\n",
    "\n",
    "                    raw_image = np.dstack((Images['Open'], Images['Para'], Images['Perp']))\n",
    "                    \n",
    "                    anisotropy_image = calculate_anisotropy(raw_image, Parameters)\n",
    "                    \n",
    "                    Images['AniPixel'] = anisotropy_image[:,:,2].copy()\n",
    "                                       \n",
    "                    image_for_ROIs = Images['Open']\n",
    "                    \n",
    "                    for string in anisotropy_strings:\n",
    "                            current_dataframe[(t, channel, string)] = np.nan\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                elif image_type == \"Intensity\":\n",
    "                    Images['Intensity'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 0, rescale=False))\n",
    "                    image_for_ROIs = Images['Intensity']\n",
    "                    \n",
    "                    for string in intensity_strings:\n",
    "                        current_dataframe[(t, channel, string)] = np.nan\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                #Preprocessing of the image\n",
    "                \n",
    "                \n",
    "                thresholded_image = image_for_ROIs.copy()\n",
    "                #if we change to floats, this should be np.nan, which doesn't exist for ints!\n",
    "                thresholded_image[thresholded_image < channel_thresholds[channel]] = 0\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Find ROIs and iterate through them\n",
    "                \n",
    "                if machine_learning_mode == True:\n",
    "                    if image_type == \"Anisotropy\":\n",
    "                        ROI_list = detect_ROIs(Parameters, raw_image)\n",
    "                    elif image_type == \"Intensity\":\n",
    "                        ROI_list = detect_ROIs(Parameters, np.dstack([image_for_ROIs, \n",
    "                                                                      image_for_ROIs*0.5, \n",
    "                                                                      image_for_ROIs*0.4]))\n",
    "                \n",
    "                else:\n",
    "                    ROI_list = find_ROIs(image_for_ROIs, Parameters) #for readability.  Can insert into the for loop  \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #Debug Mode: Output an image with all the ROIs\n",
    "                if debug_mode == True:\n",
    "                    debug_path = directory.replace(root_dir, f'{root_dir}{os.sep}debug')\n",
    "                    if not os.path.isdir(debug_path):\n",
    "                        os.makedirs(debug_path)\n",
    "                        \n",
    "                    debug_image = image_for_ROIs.copy()\n",
    "                    debug_image = np.dstack([debug_image, debug_image*0.9, debug_image*0.8])\n",
    "                    debug_image = ((debug_image/np.amax(debug_image))*255).astype('uint8')\n",
    "                    \n",
    "                \n",
    "                #Output the ROIs as seperate images\n",
    "                segmentation_outputs = False\n",
    "                if segmentation_outputs == True:\n",
    "                    segmentation_path = directory.replace(root_dir, f'{root_dir}{os.sep}segmentation')\n",
    "                    if not os.path.isdir(segmentation_path):\n",
    "                        os.makedirs(segmentation_path)\n",
    "\n",
    "              \n",
    "                \n",
    "                \n",
    "\n",
    "                for ROI in ROI_list:\n",
    "                    match_index = 0\n",
    "                    match_IoU = 0\n",
    "                    for index, compROI in enumerate(current_dataframe[(-1, -1, \"ROI\")]):\n",
    "                        #print (\"Index is \", index)\n",
    "                        #print (current_dataframe[\"ROI\"])\n",
    "                        current_dataframe.head(5)\n",
    "                        IoU = calc_overlap(ROI, compROI)\n",
    "                        if (IoU > max(ROI_match_threshold, match_IoU)):\n",
    "                            match_index = index\n",
    "                            match_IoU = IoU\n",
    "                    \n",
    "                    if match_IoU:\n",
    "                        row_index = match_index #modify the current value\n",
    "                        #change the ROI in the comparison row??\n",
    "                        \n",
    "                    else:\n",
    "                        #append a new column\n",
    "                        row_index = len(current_dataframe.index)\n",
    "                        new_row = pd.DataFrame({(-1, -1, \"ROI\"): [ROI],\n",
    "                                                (-1, -1, \"Image\"): filename,\n",
    "                                                (-1, -1, \"Index\"): row_index})\n",
    "                        current_dataframe = current_dataframe.append(new_row, ignore_index = True, sort=False)\n",
    "\n",
    "\n",
    "                    #Use the ROI to append useful information to the dataframe    \n",
    "                    x_corner = ROI.x\n",
    "                    y_corner = ROI.y\n",
    "                    x_len = ROI.x_length\n",
    "                    y_len = ROI.y_length\n",
    "                    \n",
    "                    ROI_data = {}\n",
    "                    \n",
    "                    data_inputs = {}\n",
    "                    #data_inputs[image_string] = current_Image\n",
    "                    #data_inputs[image_ROI_string] = ROI\n",
    "                    \n",
    "                    \n",
    "                    if debug_mode == True:\n",
    "                        #print (\"coordinates\", x_corner, y_corner, x_len, y_len)\n",
    "                        #print(\"stats:\", (x_corner),(y_corner), (x_corner+x_len), (y_corner+y_len))\n",
    "                              \n",
    "                        \n",
    "                        debug_image = cv2.rectangle(debug_image,\n",
    "                                                    (x_corner,y_corner), \n",
    "                                                    (x_corner+x_len, y_corner+y_len), \n",
    "                                                    (255,0,0), 20)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if image_type == \"Anisotropy\":\n",
    "                        \n",
    "                        image_types = ['Para', 'Perp', 'AniPixel']\n",
    "                        subRegion = {}\n",
    "                        subRegionAvg = {}\n",
    "                        \n",
    "                        #subRegion['Thresh'] = thresholded_image[y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                        #subRegion[types] = np.multiply(subRegion[types], ROI.data)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        for types in image_types:\n",
    "                            subRegion[types] = Images[types][y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                            subRegion[types] = np.multiply(subRegion[types], ROI.data)\n",
    "                            data_inputs[types] = np.mean(subRegion[types][subRegion['Para']!=0])\n",
    "\n",
    "                            \n",
    "                                \n",
    "                        para_value = data_inputs['Para']\n",
    "                        perp_value = data_inputs['Perp']\n",
    "                        data_inputs['AniAvg'] = (para_value - perp_value)/(para_value + 2*perp_value)\n",
    "                        \n",
    "                        #print (para_value, perp_value, data_inputs['AniAvg'])\n",
    "                        \n",
    "                        for types in data_inputs:\n",
    "                            current_dataframe.at[row_index, (t, channel, types)] = data_inputs[types]\n",
    "\n",
    "\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    elif image_type == \"Intensity\":\n",
    "                        int_extract = Images['Intensity'][y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                        int_extract = np.multiply(int_extract, ROI.data)\n",
    "                        int_value = np.mean(int_extract[int_extract!=0])\n",
    "                        \n",
    "                        current_dataframe.at[row_index, (t, channel, intensity_string)] = int_value\n",
    "                        \n",
    "                if debug_mode == True:\n",
    "                    debug_save_path = f'{debug_path}{os.sep}{filename}'.replace(suffix, f'{channel}.jpg')\n",
    "                    imageio.imwrite(debug_save_path, debug_image)\n",
    "                        \n",
    "    \n",
    "    \n",
    "    #outside the loop, not really useful for anything\n",
    "    dataframes[-1][filename] = current_dataframe  \n",
    "    \n",
    "    #print (current_dataframe)\n",
    "\n",
    "    \n",
    "    return (dataframes)\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#image_Analysis(Parameters = Parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_maxima (data, neighborhood_size = 4, threshold = 700):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    \n",
    "    image = a 2D numpy matrix containing your data\n",
    "    neighborhood_size = the area used to find the maximum filter (should be larger than your largest object)\n",
    "    threshold = the minimum difference between your maximum and the lower value \n",
    "        in the neighbourhood (the background if the neighborhood size is large enough)\n",
    "    \n",
    "    \n",
    "    \n",
    "    output:\n",
    "    The x and y coordinates of the maxima in the image (empty list if there are none...)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    #find the maxima value within a specific neighborhood size    \n",
    "    data_max = filters.maximum_filter(data, neighborhood_size)\n",
    "    \n",
    "    #set the maxima as \"true\" for the pooint where this maxima is true\n",
    "    maxima = (data == data_max)\n",
    "    \n",
    "    #find the minima for comparison\n",
    "    data_min = filters.minimum_filter(data, neighborhood_size)\n",
    "    diff = ((data_max - data_min) > threshold)\n",
    "    \n",
    "    #Remove all points that are below the minimum threshold\n",
    "    maxima[diff == 0] = 0\n",
    "\n",
    "\n",
    "    \n",
    "    #May not be necessary...\n",
    "    labeled, num_objects = ndimage.label(maxima)\n",
    "    slices = ndimage.find_objects(labeled)\n",
    "    \n",
    "    \n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    #print (slices)\n",
    "    x, y = [], []\n",
    "    for dy,dx in slices:\n",
    "        x_center = (dx.start + dx.stop - 1)//2\n",
    "        x.append(int(x_center))\n",
    "        y_center = (dy.start + dy.stop - 1)//2    \n",
    "        y.append(int(y_center))\n",
    "\n",
    "    #plt.imshow(data)\n",
    "    #plt.savefig('/tmp/data.png', bbox_inches = 'tight')\n",
    "\n",
    "    #plt.autoscale(False)\n",
    "    #plt.plot(x,y, 'ro')\n",
    "    #plt.savefig('/tmp/result.png', bbox_inches = 'tight')\n",
    "\n",
    "    #print (x, y)\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ROIs (image, Parameters, avg_radius = 4, thresh_tolerance = 0.5):\n",
    "    \"\"\"\n",
    "    This function is responsible for finding ROIs within a cell using local maxima\n",
    "    and acts as an alternative to the machine learning approach.  It can produce\n",
    "    good results, but some of the parameters must be optimized for each experiment\n",
    "    \n",
    "    \n",
    "    In particular, you need to us\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #variables for local maxima\n",
    "    \n",
    "    max_neighborhood_size = Parameters.max_neighborhood_size\n",
    "    max_threshold= Parameters.max_threshold\n",
    "    avg_radius = Parameters.local_max_avg_radius\n",
    "    thresh_tolerance = Parameters.thresh_tolerance\n",
    "    IoU_match_thresh = Parameters.IoU_match_thresh\n",
    "    \n",
    "\n",
    "\n",
    "    #Find the x,y points of the local maxima\n",
    "    seed = np.zeros(image.shape)\n",
    "    x, y = find_local_maxima (image, \n",
    "                              neighborhood_size=max_neighborhood_size, \n",
    "                              threshold=max_threshold)\n",
    "\n",
    "    overall_image = np.zeros(image.shape)\n",
    "\n",
    "\n",
    "    \n",
    "    ROI_List = []\n",
    "\n",
    "    for (x_val, y_val) in (zip(x,y)):\n",
    "        #Doesn't take care of the fact that y_val or x_val might be close to the edge (less than the tolerance)\n",
    "\n",
    "\n",
    "        average_value = np.mean(image[y_val- avg_radius: y_val + avg_radius,\n",
    "                                      x_val- avg_radius: x_val + avg_radius])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if average_value:\n",
    "            seed = np.zeros(image.shape)\n",
    "            seed[y_val, x_val] = 1\n",
    "            _ , mask = cv2.threshold(image,\n",
    "                                     average_value * (1-thresh_tolerance),\n",
    "                                     average_value*(1+thresh_tolerance),\n",
    "                                     cv2.THRESH_BINARY )\n",
    "\n",
    "            \n",
    "            roi_image = ndimage.binary_propagation(seed, mask = mask)\n",
    "\n",
    "\n",
    "            i, j = np.where(roi_image)\n",
    "            x_corner = min(i)\n",
    "            y_corner = min(j)\n",
    "            roi_subimage = roi_image[min(i): max(i),\n",
    "                                     min(j): max(j)]\n",
    "\n",
    "            current_ROI = ROIs(x = min(j), y = min(i), confidence = None, classification = None, data = roi_subimage)\n",
    "\n",
    "            \n",
    "            #print (current_ROI)\n",
    "            \n",
    "            if not ROI_List:\n",
    "                #print (current_ROI)\n",
    "                ROI_List.append(current_ROI)\n",
    "            \n",
    "            else:           \n",
    "                for compROI in ROI_List:\n",
    "                    IoU_match = 0\n",
    "                    IoU = calc_overlap(current_ROI, compROI)\n",
    "                    if IoU>IoU_match_thresh:\n",
    "                        IoU_match = 1\n",
    "                        #print (\"Already added a similar ROI\")\n",
    "                        break\n",
    "\n",
    "                if not IoU_match:\n",
    "                    #print (current_ROI)\n",
    "                    ROI_List.append(current_ROI)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #for testing purposes\n",
    "            overall_image = np.add(overall_image, np.multiply(image, roi_image))\n",
    "\n",
    "        #print (x_val, y_val, average_value, np.sum(roi_image), np.sum(mask), roi_subimage.shape)\n",
    "        #print (x_corner, y_corner, min(j), max(j),min(i), max(i), roi_subimage.shape)\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    #print (f\"Numer of ROIS is {len(ROI_List)}\")\n",
    "    plt.imshow(overall_image)\n",
    "    \n",
    "    \n",
    "    return (ROI_List)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  create_summary_columns(df):\n",
    "    \n",
    "    dataframe = df.copy()\n",
    "    \n",
    "    #precolumns are the columns like ROI that aren't important for the export\n",
    "    precolumns = 3\n",
    "    \n",
    "    summary_dataframe = pd.DataFrame([])\n",
    "    \n",
    "    timepoints = max(dataframe[precolumns:].columns, key = lambda x: x[0])[0]\n",
    "    print (timepoints)\n",
    "    \n",
    "    \n",
    "    channels = max(dataframe[precolumns:].columns, key = lambda x:x[1])[1]\n",
    "    print (channels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    statistics = {\"Mean\": np.mean, \n",
    "                  \"Stdev\": np.std,\n",
    "                  \"Count\": len, \"StdErr\": lambda x: np.std(x)/np.sqrt(len(x))}\n",
    "    \n",
    "    \n",
    "    \n",
    "    for t in range (timepoints+1):\n",
    "        \n",
    "        series = pd.Series([t], index = [(\" \",\" \",\"Time\")])\n",
    "        \n",
    "        for func in statistics:\n",
    "            new_series = dataframe.loc[0:, pd.IndexSlice[t,:,:]].apply(statistics[func])\n",
    "            new_series.index = [(func, i[1], i[2]) for i in new_series.index]\n",
    "            series = series.append(new_series)\n",
    "        \n",
    "        \n",
    "        columns = series.index\n",
    "        \n",
    "        #print (series)\n",
    "        summary_dataframe = summary_dataframe.append(series, ignore_index = True, sort = False)\n",
    "        \n",
    "    \n",
    "    \n",
    "    summary_dataframe.columns = pd.MultiIndex.from_tuples(summary_dataframe.columns, names = ['Stat', 'Channel', 'Para'])\n",
    "    \n",
    "\n",
    "    \n",
    "    #print (df.columns)\n",
    "    #print (summary_dataframe)\n",
    "    return summary_dataframe\n",
    "\n",
    "\n",
    "#create_summary_columns(sub_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell_comparisons(df, Parameters):\n",
    "    dataframe = df.copy()\n",
    "    \n",
    "    image_type_array = Parameters.image_type_array\n",
    "    \n",
    "    #image_type_bool = [image_type_array[i] == \"Anisotropy\" for i in range(len(image_type_array))]\n",
    "    \n",
    "    relative_values = False\n",
    "    AniChannel = \"AniAvg\"\n",
    "    IntChannel = \"Intensity\"\n",
    "    \n",
    "    #print (dataframe)\n",
    "    \n",
    "    statistics = {\"Mean\": np.mean, \n",
    "                  \"Stdev\": np.std,\n",
    "                  \"Count\": len, \"StdErr\": lambda x: np.std(x)/np.sqrt(len(x))}\n",
    "    \n",
    "    \n",
    "    cell_cell_comparisons = {}\n",
    "    print ()\n",
    "    \n",
    "    for channel, image_type in enumerate(image_type_array):\n",
    "        #print (channel, image_type)\n",
    "        if image_type == \"Anisotropy\" or image_type == \"Intensity\":\n",
    "            \n",
    "            if image_type == \"Anisotropy\":\n",
    "                channel_name = AniChannel\n",
    "                \n",
    "            elif image_type == \"Intensity\":\n",
    "                channel_name = IntChannel\n",
    "                \n",
    "            \n",
    "            \n",
    "            channel_subarray = dataframe.loc[:, pd.IndexSlice[:, channel, channel_name]]\n",
    "            channel_subarray = channel_subarray.dropna(how = 'any')\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print (image_type, (0, channel, channel_name))\n",
    "            first_channel = channel_subarray.loc[:, (0, channel, channel_name)].copy()\n",
    "            \n",
    "            if relative_values == True:        \n",
    "                for columns in channel_subarray.columns:\n",
    "                    channel_subarray.at[:, columns] = channel_subarray.loc[:, columns]/first_channel\n",
    "                \n",
    "            for functions in statistics:\n",
    "                channel_subarray[functions] = channel_subarray.apply(statistics[functions], axis = 1)\n",
    "\n",
    "            \n",
    "            cell_cell_comparisons.update({f\"{image_type}_Channel_{channel}\": channel_subarray})\n",
    "                \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Need to find number of timepoints and then do a comparison for the rows where there is a value in every row\n",
    "    \n",
    "    #print (image_type_bool)\n",
    "    \n",
    "    \n",
    "    #\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (cell_cell_comparisons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_file(text_path):\n",
    "    \n",
    "    skip_characters = [\"'\", \"#\", \"\\n\"]\n",
    "    \n",
    "    \n",
    "    for char in ['/', '\\\\']:\n",
    "        text_path = text_path.replace(char, os.sep)\n",
    "\n",
    "    print (text_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    config_variables = {}\n",
    "    with open(text_path, 'r') as f:\n",
    "        for lines in f:\n",
    "            if lines[0] not in skip_characters:           \n",
    "                param_input = \"\".join(lines.split())\n",
    "                variable, value = param_input.split('=')\n",
    "                #print (variable, value, param_input)\n",
    "                config_variables.update({variable: value})\n",
    "\n",
    "\n",
    "    float_variables = ['numerical_aperture',\n",
    "                       'index_of_refraction',\n",
    "                       'magnification',\n",
    "                       'gFactor',\n",
    "                       'max_filter_region',\n",
    "                       'max_threshold', \n",
    "                       'conf_thresh', \n",
    "                       'nms_thresh', \n",
    "                       'thresh_tolerance', \n",
    "                       'IoU_match_thresh']\n",
    "    \n",
    "    int_variables = ['classes', \n",
    "                     'local_max_avg_radius', \n",
    "                     'max_neighborhood_size']\n",
    "    \n",
    "    binary_variables = ['debug_mode', \n",
    "                        'root_dir_same_treatment', \n",
    "                        'machine_learning_mode', \n",
    "                        'use_cuda']\n",
    "    \n",
    "    array_variables = {'channel_thresholds': \"int\",\n",
    "                       'channel_array': 'int',\n",
    "                       'image_type_array': 'str', \n",
    "                       'network_size':'int', \n",
    "                       'labels': 'str'}\n",
    "    \n",
    "    path_variables = ['weights_path']\n",
    "    \n",
    "    #Don't need this for anthing\n",
    "    string_variables = ['suffix']\n",
    "    \n",
    "    \n",
    "    for variables in config_variables:\n",
    "    \n",
    "    \n",
    "        #Convert Floats\n",
    "        if variables in float_variables:\n",
    "            config_variables[variables] = float(config_variables[variables])\n",
    "            \n",
    "        elif variables in int_variables:\n",
    "            config_variables[variables] = int(config_variables[variables])\n",
    "\n",
    "        #Convert Binary Variables\n",
    "        elif variables in binary_variables:\n",
    "            config_variables[variables] = (config_variables[variables].lower() == \"true\")\n",
    "\n",
    "        #Convert to arrays with the appropriate variable type\n",
    "        elif variables in array_variables:\n",
    "            var_type = array_variables[variables]\n",
    "            for c in ['[', ']', \"'\", '\"']:\n",
    "                config_variables[variables] = config_variables[variables].replace(c,\"\")\n",
    "            config_variables[variables] = config_variables[variables].split(',')\n",
    "            if var_type.lower() == \"int\":\n",
    "                config_variables[variables] = [int(x) for x in config_variables[variables]]\n",
    "                \n",
    "        elif variables in path_variables:\n",
    "            for char in ['/', '\\\\']:\n",
    "                config_variables[variables] = config_variables[variables].replace(char, os.sep)\n",
    "                \n",
    "        elif variables in string_variables:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            print (f'unknown variables found: {variables}')\n",
    "    \n",
    "    return config_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Detect Cells using Machine Learning\"\"\"\n",
    "\n",
    "\n",
    "def post_transform(boxes, scale, pad):\n",
    "    for box in boxes:\n",
    "        box.x_top_left -= pad[0]\n",
    "        box.y_top_left -= pad[1]\n",
    "\n",
    "        box.x_top_left *= scale\n",
    "        box.y_top_left *= scale\n",
    "        box.width *= scale\n",
    "        box.height *= scale\n",
    "    return boxes\n",
    "\n",
    "def output_ROIs (detections, im_h, im_w, segmentation = None):\n",
    "    ROI_list = []\n",
    "    for det in detections:\n",
    "\n",
    "        #Note, the pixels are rounded down, but it shouldn't matter since the segmentation network will\n",
    "        #do the pixel by pixel segmentation\n",
    "        x = int(det.x_top_left)\n",
    "        y = int(det.y_top_left)\n",
    "        height = int(det.height)\n",
    "        width = int(det.width)\n",
    "        \n",
    "        \n",
    "        #Ensure that the ROIs do not go over the edge of the image.  Alternatively, don't use ROIs that go over the edge...\n",
    "        if x<0:\n",
    "            width = width+x\n",
    "            x=0\n",
    "        if y<0:\n",
    "            height = height+y\n",
    "            y=0\n",
    "        height = min((im_h - y), height)\n",
    "        width = min((im_w - x), width)\n",
    "        \n",
    "        print (\"x\", int(det.x_top_left),\n",
    "               \"y\", int(det.y_top_left), \n",
    "               det.class_label, \n",
    "               det.confidence,\n",
    "               \"w\", det.width,\n",
    "               \"h\", det.height,\n",
    "              \"new_H\", height, \"new_W\", width )\n",
    "        \n",
    "        \n",
    "        fake_data = np.ones((height,width))\n",
    "        \n",
    "        \n",
    "        roi = ROIs(x = x,\n",
    "                   y = y, \n",
    "                   classification = det.class_label, \n",
    "                   confidence = det.confidence, \n",
    "                   data = fake_data)  #Use the data as ones for now... replace with segmentation later\n",
    "        \n",
    "        \n",
    "        ROI_list.append(roi)\n",
    "        \n",
    "    return (ROI_list)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def detect_ROIs(Parameters, image):\n",
    "    \n",
    "    #Import the relevant parameters:\n",
    "    network_size = Parameters.network_size\n",
    "    network = Parameters.network\n",
    "    net_w, net_h = Parameters.network_size\n",
    "    device = Parameters.device\n",
    "    log = Parameters.log\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    save_check = False\n",
    "    show_label = True\n",
    "    use_cuda = True\n",
    "    img = image.copy()\n",
    "    \n",
    "    #Maybe this should already be set.. \n",
    "    network.training = False\n",
    "    \n",
    "    im_h, im_w = image.shape[:2]\n",
    "\n",
    "       \n",
    "    device = torch.device('cpu')\n",
    "    if use_cuda:\n",
    "        if torch.cuda.is_available():\n",
    "            log.debug('CUDA enabled')\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            log.error('CUDA not available')\n",
    "\n",
    "            \n",
    "    #print (\"Image Shape:\", img.shape)        \n",
    "    \n",
    "\n",
    "    #The control of the input should happen before this function...\n",
    "    #If only one slice, pad to 3 using the anisotropy ratios\n",
    "    #if img.shape[2] == 1:\n",
    "    #    print (\"There is only channel... extending\")\n",
    "    #    img = np.dstack([img, img*0.5, img*0.4])    \n",
    "    \n",
    "    \n",
    "    #Prep the image for the neural network\n",
    "    #print (\"Pre conversion\",img.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    img = img/np.amax(img)\n",
    "    img = img*255\n",
    "    img = img.astype('uint8')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Transform the image and prep it for the \n",
    "    img_tf = ln.data.transform.Letterbox.apply(img, dimension = network_size)\n",
    "    img_tf = tf.ToTensor()(img_tf)\n",
    "    img_tf.unsqueeze_(0)\n",
    "    img_tf = img_tf.to(device)\n",
    "\n",
    "\n",
    "    # Run the image through the neural net\n",
    "    with torch.no_grad():\n",
    "        output = network(img_tf)\n",
    "        \n",
    "    if im_w == net_w and im_h == net_h:\n",
    "        scale = 1\n",
    "    elif im_w / net_w >= im_h / net_h:\n",
    "        scale = im_w/net_w\n",
    "    else:\n",
    "        scale = im_h/net_h\n",
    "        \n",
    "    pad = int((net_w - im_w/scale) / 2), int((net_h - im_h/scale) / 2)\n",
    "\n",
    "    \n",
    "    #Convert the boxes into ROIs\n",
    "    converted_boxes = []\n",
    "    for b in output:\n",
    "        converted_boxes.append(post_transform(b, scale, pad))\n",
    "    \n",
    "    output = converted_boxes\n",
    "    \n",
    "    \n",
    "    image_markup = bbb.draw_boxes(img, output[0], color = (255,0,0), show_labels=show_label)\n",
    "    if save_check:\n",
    "        cv2.imwrite('detections.png', image)\n",
    "    elif Parameters.debug_mode == True:\n",
    "        cv2.imshow('image', image_markup)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "        print (output[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Add the segmentation algorithm here when it is ready...\n",
    "    \n",
    "    \n",
    "    ROI_list = output_ROIs(output[0], im_h, im_w)\n",
    "   \n",
    "    #ROI_list = [ROIs(x=0, y=1000, data = np.ones((100,500)))]\n",
    "        \n",
    "    return ROI_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    fig = Figure(figsize=(5, 5), dpi=100)\\n\\n    canvas = FigureCanvasTkAgg(fig, master=root)\\n    canvas.get_tk_widget().grid(row=1,column=4,columnspan=3,rowspan=20)\\n    # here: plot suff to your fig\\n    canvas.draw()\\n\\n    ###############    TOOLBAR    ###############\\n    toolbarFrame = Frame(master=root)\\n    toolbarFrame.grid(row=22,column=4)\\n    toolbar = NavigationToolbar2TkAgg(canvas, toolbarFrame)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"    fig = Figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, master=root)\n",
    "    canvas.get_tk_widget().grid(row=1,column=4,columnspan=3,rowspan=20)\n",
    "    # here: plot suff to your fig\n",
    "    canvas.draw()\n",
    "\n",
    "    ###############    TOOLBAR    ###############\n",
    "    toolbarFrame = Frame(master=root)\n",
    "    toolbarFrame.grid(row=22,column=4)\n",
    "    toolbar = NavigationToolbar2TkAgg(canvas, toolbarFrame)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nStart Here\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Start Here\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\William\\Dropbox\\Python Analysis\\config.txt\n",
      "unknown variables found: same_cells\n",
      "['channel_array', 'channel_thresholds', 'suffix', 'machine_learning_mode']\n",
      "0.23898418155398782 0.014831490153302157 0.7461843282927101\n",
      "Loaded the following variables:\n",
      "channel_array            : [3, 3, 1]\n",
      "image_type_array         : ['Anisotropy', 'Intensity', 'Brightfield']\n",
      "channel_thresholds       : [500, 500, 500]\n",
      "same_cells               : True\n",
      "root_dir_same_treatment  : True\n",
      "suffix                   : ome.tif\n",
      "machine_learning_mode    : False\n",
      "debug_mode               : True\n",
      "numerical_aperture       : 1.4\n",
      "index_of_refraction      : 1.53\n",
      "magnification            : 63.0\n",
      "gFactor                  : 1.0\n",
      "max_neighborhood_size    : 40\n",
      "max_threshold            : 800.0\n",
      "local_max_avg_radius     : 4\n",
      "thresh_tolerance         : 0.5\n",
      "IoU_match_thresh         : 0.8\n",
      "weights_path             : C:\\Users\\William\\Desktop\\Lightnet\\examples\\yolo-voc\\backup\\final.pt\n",
      "classes                  : 20\n",
      "network_size             : [1482, 2535]\n",
      "labels                   : ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
      "conf_thresh              : 0.2\n",
      "nms_thresh               : 0.4\n",
      "use_cuda                 : True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Work\n",
    "data_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline3\"\n",
    "text_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline3{os.sep}config.txt\"\n",
    "\n",
    "#Home\n",
    "data_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Documents{os.sep}Baseline\"\n",
    "text_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Dropbox{os.sep}Python Analysis{os.sep}config.txt\"\n",
    "\n",
    "config_variables = parse_text_file (text_path)\n",
    "\n",
    "Parameters = ImagingParameters(data_path = data_path, **config_variables)\n",
    "\n",
    "if Parameters.debug_mode == True:\n",
    "    print(\"Loaded the following variables:\")\n",
    "    for variables in config_variables:\n",
    "        print(f'{variables: <25}: {config_variables[variables]}')\n",
    "        \n",
    "    if (Parameters.machine_learning_mode == True):\n",
    "        print (\"Here is the network...\")\n",
    "        print (Parameters.network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\n",
      "Not from the same core directory\n",
      "current image is :Baseline_1_MMStack_1-Pos_000_003.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "current image is :Baseline_1_MMStack_1-Pos_001_000.ome.tif in Baseline and it has 2 timepoints and length df: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current image is :Baseline_1_MMStack_1-Pos_003_000.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "current image is :Baseline_1_MMStack_1-Pos_003_002.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "\\\n",
      "From the same core directory\n",
      "current image is :Baseline_1_MMStack_1-Pos_000_003.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "current image is :Baseline_1_MMStack_1-Pos_001_000.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "current image is :Baseline_1_MMStack_1-Pos_003_000.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "current image is :Baseline_1_MMStack_1-Pos_003_002.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "Total Time is 86.26682043075562\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAADnCAYAAAAaX/GuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3X+M5Pdd3/Hn6zu7s3t3zuE7JzbHncFOOShuoGCuttvQKOLAsV2UcyVSmf7IKVg6VU0oNEXgNJWCQKqgP0iJRCMd2I1TRTGRCYpVGRLHBEVUtfE5JI4dY3wxqb3Y5ELubJ9vfbs73++7f3w/35nvd3b2x+3szu7Ovh7SV/Odz3xm5jvfnf2+5/NbEYGZmVkl2+wDMDOzrcWBwczMGhwYzMyswYHBzMwaHBjMzKzBgcHMzBpGHhgk3SLpGUmnJd016vc3M7PlaZTjGCS1gL8EfhKYAR4DfiYivjaygzAzs2WNusRwA3A6Ip6LiHngPuDYiI/BzMyWMerAcBB4oXZ/JqWZmdkWMTHi99OAtEZdlqQTwAmAFq0f3c3eURzX6mjRzhKi71OZmY3Oec79bUS8aa3PH3VgmAGurt0/BLxYzxARJ4GTAHu1P27U0dEd3TI0MUEUgbIUFJQKW1ktSBQBUQAQnc6Ij9DMrPT5uP//DfP8UVclPQYclnStpDZwB/DAiI9hKNHpELUAQBG9zUHBzMbASEsMEdGR9D7gs0ALuCcinhrlMaxJ1hp8sY+iLDlUAaEIKPIRH5yZ2foadVUSEfEg8OCo33co/Rf7IocsnbooXEIws7Hikc9rVAUDBwUzGzcjLzGMhawFOCiY2XhyYFgLtyOY2RhzVZKZmTU4MJiZWYMDg20vUtnGo5VGn5vZWrmNwbY+9Y02r/ZFb6DhCGcJNht3Dgw12Z49kGVIIiIgzylmZzf7sAyaQWFgeuHgYLZOHBiS1t695bxH6UIjAIlszx6KCxc29dh2NGnpoNDIl0G4t5jZetjxgSHbswe1WmVQaKW66+4vz9aK86jaBuprR1CmctqRQaoqJTMb2o5vfO4GhUb9tVIjp5qzp9ro9LUrVLPaKlNvhttG/h3/VTZbNzv6vynbvbvcqc+WCqlhM+vt2+jV/gaDAsHg4OAgbrYedvZVryoVtMopLsoA0RckougFENsUS1YfLcroxmez9bCzA8NSalNpl/f9S3Skljjfy7YvuI3BbN3s6MBQXLhQlhKgV2qQFl9ksh19mkav75d/vX0BBgQIV/eZrasd/x8V9aqjqt46UpVSEb7obJZacK4CQRTR2O8qclcjma2jHX/VK86fJ/IC8rwMBHm6IOV589Y2lbupmo3Ojg8MUAaHbs+kKHrBIIruCGgbsdWUAFxSMNsQaw4Mkq6W9AVJT0t6StLPp/T9kh6S9Gy63ZfSJekjkk5LekLS9ev1IdZD/uqrxEKnt+UFsdChOH/e02JslqXWvXBjs9mGGqbE0AH+fUT8AHAT8F5J1wF3AQ9HxGHg4XQf4FbgcNpOAB8d4r03RHHhQm87f95TYWwFRa/01r2t2oDMbEOsOTBExEsR8aW0fx54GjgIHAPuTdnuBW5P+8eAj0fpEeBySQfWfOS2c1RVRq46MhuJdWljkHQN8CPAo8BVEfESlMEDuDJlOwi8UHvaTErrf60Tkk5JOrXA3HocnpmZXYKhA4Oky4DfB34hIl5dLuuAtEU//yLiZEQciYgjk0wNe3hmZnaJhgoMkiYpg8InIuLTKfmbVRVRuj2T0meAq2tPPwS8OMz7m5nZ+humV5KAu4GnI+I3aw89ABxP+8eBz9TS3516J90EvFJVOZmZ2dYxzHoMbwX+FfBVSV9Oaf8B+HXgU5LuBJ4H3pUeexC4DTgNzALvGeK9zcxsg6w5METEnzK43QDg6ID8Abx3re9nZmaj4ZHPZmbW4MBgZmYNDgxmZtbgwGBmZg0ODGZm1uDAYGZmDQ4MZmbW4MBgZmYNDgxmZtbgwGBmZg0ODGZm1uDAYGZmDQ4MZmbW4MBgZmYNDgxmZtbgwGBmZg0ODGZm1jB0YJDUkvTnkv53un+tpEclPSvp9yS1U/pUun86PX7NsO9tZmbrbz1KDD8PPF27/xvAhyPiMHAOuDOl3wmci4jvBT6c8pmZ2RYzVGCQdAj4J8DvpvsCfhy4P2W5F7g97R9L90mPH035zcxsCxm2xPDfgV8CinT/CuDliOik+zPAwbR/EHgBID3+SspvZmZbyJoDg6SfAs5ExOP15AFZYxWP1V/3hKRTkk4tMLfWwzMzszWaGOK5bwXeKek2YBrYS1mCuFzSRCoVHAJeTPlngKuBGUkTwHcAZ/tfNCJOAicB9mr/osBhZmYba80lhoj4QEQciohrgDuAP46IfwF8AfjplO048Jm0/0C6T3r8jyPCF34zsy1mI8Yx/DLwfkmnKdsQ7k7pdwNXpPT3A3dtwHubmdmQhqlK6oqIPwH+JO0/B9wwIM9F4F3r8X5mZrZx1iUw2M6hiQlQraAZZYe06HSWeIaZbTcODLZqmmxDJrJd043gUMzOImXEwvwmHp2ZrRcHBlsVTbbJ9l4GUio1lL2Po5OTveEyiKB49TWIwqUHs23Ok+jZijTZJtuzCyYm0NQUTExAlkHVqSwCiiC7bA+0WmXJwsy2LZcYbGWZyqAwMQETLchTu0IEFDnkOcXrF8usu3dTzM5u5tGa2ZBcYrBlabJNtnt3r/qoCGhlUBQD8xevXeg+z8y2J5cYbHVarTIgQLfEQFFWJVWlhYbM8yOabVcuMdjKWlmvtADdhmegl1aX2hs04d8dZtuRA4OtLALyvNyXao3Og6uTyFIQkb9eZtuR/3NtZVWpoCigk0MEUWtjyHZN9/K6Csls23NZ31ZUzM6StSdRq5USirIEUbU1KCPbvbvcjwJarbIReqkShZltaS4x2LJiYb4sMXQ6ZTCoSgupOqmYnS1LCdVW643kgW5m25MDg60sCopXXyPm53ttDal6Kds1XaZJqf2hKEsLVT4z23YcGLab6gKctXr3N1j1y7947QKxsFAGhaqEAL1G5giK869BES4tmG1jbmPYLiRQhjIRRfTq75VBbPyv82qCvKIKCqRRzq9fbHRZ9UR6ZtufA8NWVS8J9HX7LINDVq6iXeS9vBHN7qQbIBbmu1NvdxuYPbOq2VhxYNgK+quDIsota6Elun9WJYdqEFkUUQaKEfQEcjWR2XhzYNhMqXqo+tXdTW6li35/UOjW5RfprmoPpSqm5d7LS2yb2SoM1fgs6XJJ90v6C0lPS/qHkvZLekjSs+l2X8orSR+RdFrSE5KuX5+PsI2lC71aZcmg2qo0qk1ZeVs1+CrrbQNeUxMTZeN01VBdlUj6b83MBhi2V9JvAX8UEX8X+PvA08BdwMMRcRh4ON0HuBU4nLYTwEeHfO/tqb9XUTe9drGvggAgCbWyMni0Wt37jR5BVYCpBZZl398lBzNbxpoDg6S9wNuAuwEiYj4iXgaOAfembPcCt6f9Y8DHo/QIcLmkA2s+8u0s9S5qXMhTaUCtLF38W6jdhslJ1G6jaj2EyUnIsmaAqEoRA94HcCAws0syTInhzcC3gP8p6c8l/a6kPcBVEfESQLq9MuU/CLxQe/5MSmuQdELSKUmnFpgb4vC2GNV+4S96rBcMyMoSQxUIymAwAe1JmExp7ckyQKRSBLBoTEE36CjrtWWAg4SZrWiYxucJ4Hrg5yLiUUm/Ra/aaJBBdRyLrlIRcRI4CbBX+8fjKlYFhawFUZQX80Zjc1aWAiYmygt8q1X2SGpl5TKa1ToIRUBRrqms+jQVUKa3Ws0xBd1psrPauAdXJZnZ8oYJDDPATEQ8mu7fTxkYvinpQES8lKqKztTyX117/iHgxSHef9spq41qbQvVr/zql//kRLmEZpbBVJuYaBHTUykvKE/dWOcX0NwCMS+YT71U60Gi7z2jnu6gYGYrWHNgiIi/kfSCpO+PiGeAo8DX0nYc+PV0+5n0lAeA90m6D7gReKWqctoR6lVIVXWPVJYUWi1oT6LJyTIg7Joi2hPkl02RT7fIpzPyqYwQtM/nTL48R+vCPLpQVhPFwkK3OBbkUJQlhHoPp27pYQSjpM1sext2HMPPAZ+Q1AaeA95D2W7xKUl3As8D70p5HwRuA04DsymvpS6p3aCwZxf5njZzb5pm7jta/M3bCi676jW+a++rzOUTfOPZq/juB6dpT2RMRKBqMFyel68DRNFpVB8tO77BzKzPUIEhIr4MHBnw0NEBeQN47zDvty31jxnojl1IjcytrGxYbk8Se3Yx/6Y9XDjQ5pu3zvOfbryfO95wrvn8t8CbL/tZDn16il2dglZeoE5O5DmiU06JXa2g1s/rI5jZKnh21Y02aBnMbhfVFByyjJieorN3mtnvbDP/z8/y3E/cszgoADOd1/jYP76HmR/P6LyhTUyXQaWav6jqykrfqGgzs9XylBgbTUuMMUiD1ZBgeorisinm97V59Z+d58kf/dTAl7rv/D4+/a2jfP3cFbzlh7/BK5//bibbE8REarzOhKSyq1dacznyvBcYRjDJnpltfw4Mo1a/SGdCE+WFvZie5OL+Fp/+0ZPAnkVP+z8XC/701e/j+Vf38fIrezj37TdwcFIUExlZasQma0GWl/t533xKUXS7y5qZLceBYQQaVTnVegZVSaLVgokW+VSLM/8Avm9ycVAA+Nz5H+TpV67i2y9fRvHaJNnFjGKC5uiQ+vv0tTM0eiatodRQDqyrLds5X06z7ZlWzcaPA8NGi1g8U2qRehJFAUXqOZRBTA3+Nf/IxZxnXruKsxd2k8+3yC5m7HtK5JNRDhFc5YW+u47DJZQaugGhqvqqAk6rRbz++qpfx8y2Dzc+b7S0DnJXFM1f9gB5QWuh4E2P9E2slzz2+pv59sU9vD43ScyX4xnOXRdMvVqgvPbaed7sjVR738jzssRQ5KsuLWS7d6Ndu8rgkOZlirwg0vOz3bvJdu9e1WuZ2fbhwLDRqnEGMLAROjo5WuiQvd5h6pWCtz95+6I8s0WbIqqeTOVr6co5JmZzsvm8W+pYJL1fpIboS9Gdqyl1qwWIhU75XnkOedlFtprXyczGhwPDiESe9xbkSXMeUf2C7+S0Xptj6uUFZj9xgH/5jbc3nvtje57hwO5XuWLvBfZdeZ7vue4lDvx+m4kLC2i+g+YXynmTOp3yfQYFiiIvt1XQxATatas3a2ueE3nRDHJAzM1BnjfaHsxs+3NgGJX6L/ZUlRTVL+/5eXRxnsmzr7P7Wx2e+Z0f4D+e+cFu9rdOZ/zSd/0Rtx/6Cq/NTjF39wHar3TIXl+AhQ500oU7VSNFRGrHKNY06lntdtmeUFsXoh5sqobn3hM8TsJsnLgOYKMtNY4ByobpvEB5Xk6MN5sxfaaFil187sM/xh+884e4fM/rLOQtvn3uMvb9yTTf+bc5U+fmaL023y0tRKcDRV4GhCHHKJQD5dStPlr0WSIWlxCiXHvaPZTMxoMDw0aLKCeuy1qpd1IBtMqAUOWZXyDSmgyZxHSnoHVxmt137yafvoypgEMLQbawwOT5hXICvYsLaG4eqmqkhU6v3n/RMRRrG9hWf06WlaUG9cZhqN0uSzuuSjIbKw4MI9Ttslqr8lF1uzBf9jwtCrTQoT23kEY1Z71f6nN5+fjF+bIBeG6eWFgg5hfK9RjqvZLqPaG0+i6q0emgqTTVdzVSernPVOU1s7HhwDAK/es7VxfpIiMoL/aRZ6gIosih00ELHTTR6q0RXdXxd8rHy/UXUg+hhYXF71kPBlFcemkhClD6erRaKM+JrFowKJUcMjdRmY0jB4aNJjUHt/W3NxRBZGmxnbwcY6Aiygt/1T5RH8Vc5N2GZYroVh1F3jdWovv6a1h/oWr7UBpzkVaQU57aMWoBoRr05tmXzMaHA8MoLTeWoCoRRDQusuouC1r1ZOqNlq5WbItYYlDbGtdhKGZny0boXbsa4xjIhKqXb/XmXYqqAdzMxoIDw0argkF1279WQnXBTxd3pbYCVYPKoCw5dGozo1bTaFTdUiv9QSGajcWXIjod4vz5ckzD1FRvOm8og0K3pJIv7r5qZtuaA8NGqtoW6iWF6kJeb4iuVTVVVULlEp2BWlmzRND/Ot0nDigpVO0MQ3Rhjao9I6lPphfz8y4pmI2hoVoPJf07SU9JelLSJyVNS7pW0qOSnpX0e2nZTyRNpfun0+PXrMcH2OqWXCSnfmEvorf1Pd4duNa/RdFsXKbarfVKuoR5kVYrOh2K2VmK2VkHBbMxtebAIOkg8G+BIxHxFqAF3AH8BvDhiDgMnAPuTE+5EzgXEd8LfDjl29mq0kJ9G6TRu6gXEKI2urnaytdd/4BgZjvHsP0NJ4BdkiaA3cBLwI8D96fH7wWqWeGOpfukx49KO3QuhUFjCvpLDH1BoBEM0m2jNNKf38xsjdYcGCLir4H/CjxPGRBeAR4HXo6Iqo5hBjiY9g8CL6TndlL+K9b6/mOhf2Gd+n5tZtR676JyTYVecOhOzldNh+GSgpkNaZiqpH2UpYBrge+iXI/y1gFZqyvVoNLBoquYpBOSTkk6tcDcWg9va+n/Fd/fGF1t9Qbp6C3NWZUMFlcX9bq4mpmtl2Gqkn4C+KuI+FZELACfBv4RcHmqWgI4BLyY9meAqwHS498BnO1/0Yg4GRFHIuLIJNt8uoX+BXr69XdbrQWE5svUSwZFb9CaSwhmtgGGCQzPAzdJ2p3aCo4CXwO+APx0ynMc+EzafyDdJz3+xzGwH+aYWmmhnO64g6zRntAYpOZAYGYjMEwbw6OUjchfAr6aXusk8MvA+yWdpmxDuDs95W7gipT+fuCuIY5722h0H13dExY/z72MzGyEtJV/tO/V/rhRRzf7MIayaNnL/plOl5j5tDtyeQv/fbYLTba77TeSuiPGY8Ejtm08fT7ufzwijqz1+Z4ec4MtWh9hFSWHqJb8dFAYmibbqFVO51FNM1JN/KdJryNhNoinxNhokWZKzVqDR0H3BYpqhlUbnqamUhCoL6uaZootCmiJGDBjudlO5xLDqBR5Oe9Q3ypri8ckOCisqyzrrWlRH09ZBQiXGswWcYlh1NKFvz7PkAcrb4zGwPoq4BaFFxgyW4H/Q2wsNUoC9VKYg4LZivxfYmOr2+OuvxrJzJblwGBjKRbme1VJgwJEURDhLqtmgzgw2NiK2mp3tcTe/hqXPjUbd258tvFVBLT6Sg2ppOABbmZLc4nBxlYszBN50eseXJUeHBTMluUSg421bgBI02LE3JhM5W62gRwYbEdwCcFs9VyVZGZmDQ4MZmbW4MBgZmYNDgxmZtbgwGBmZg0ODGZm1rBiYJB0j6Qzkp6spe2X9JCkZ9PtvpQuSR+RdFrSE5Kurz3neMr/rKTjG/NxzMxsWKspMXwMuKUv7S7g4Yg4DDyc7gPcChxO2wngo1AGEuBDwI3ADcCHqmBiZmZby4qBISK+CJztSz4G3Jv27wVur6V/PEqPAJdLOgC8A3goIs5GxDngIRYHGzMz2wLW2sZwVUS8BJBur0zpB4EXavlmUtpS6YtIOiHplKRTC3j6AjOzUVvvxudBq6HEMumLEyNORsSRiDgyydS6HpyZma1srYHhm6mKiHR7JqXPAFfX8h0CXlwm3czMtpi1BoYHgKpn0XHgM7X0d6feSTcBr6Sqps8CN0valxqdb05pZma2xaw4u6qkTwJvB94oaYayd9GvA5+SdCfwPPCulP1B4DbgNDALvAcgIs5K+jXgsZTvVyOiv0HbzMy2AEVs3eUN92p/3Kijm30YZmbbyufj/scj4shan++Rz2Zm1uDAYGZmDQ4MZmbW4MBgZmYNDgxmZtbgwGBmZg0ODGZm1uDAYGZmDQ4MZmbW4MBgZmYNDgxmZtbgwGBmZg0ODGa2NWStcrNNt+K022ZmG8aBYEtyicHMNkctKChT79Ylh03nEoOZjV5fUFC7jSSIQEBxca7MU+Sbd4w7mAODmW2KKiCUdwRZqsAoCrLpqTI42KZYsSpJ0j2Szkh6spb2XyT9haQnJP2BpMtrj31A0mlJz0h6Ry39lpR2WtJd6/9RzGxbSKUFtdtlQGi1UKuFpHJrtUDqVSvZyK2mjeFjwC19aQ8Bb4mIHwL+EvgAgKTrgDuAv5ee8z8ktSS1gN8GbgWuA34m5TWzHahqUyDLyiqkyYne1mqhyQk0NdXLZyO1YmCIiC8CZ/vSPhcRnXT3EeBQ2j8G3BcRcxHxV8Bp4Ia0nY6I5yJiHrgv5TWznUrpot9qNdMygbIyaExMuNSwCdajV9LPAn+Y9g8CL9Qem0lpS6Wb2U4VkW6LXpCo0jKh9mRZenCpYeSGCgySPgh0gE9USQOyxTLpg17zhKRTkk4t4MYns7GV2hQAyFNwKJqXBbVavQZqG5k190qSdBz4KeBoRBXmmQGurmU7BLyY9pdKb4iIk8BJgL3aPzB4mNkYUVaWGjoFFEF0yn971aua3HV1pNZUYpB0C/DLwDsjYrb20APAHZKmJF0LHAb+DHgMOCzpWkltygbqB4Y7dDPb1iKICMhzIi/SlkNREK+/TnQ6RKcDRbHZR7rjrFhikPRJ4O3AGyXNAB+i7IU0BTyUovojEfGvI+IpSZ8CvkZZxfTeiMjT67wP+CzQAu6JiKc24POY2TYQRaCirD6KLCsv/hHE/HwvT9pXu40yEY4PI6NeLdDWs1f740Yd3ezDMLP1lrV6A9zSiOf6gLYyEERvqox2m2J2dqlXsz6fj/sfj4gja32+50oys9ErcqJolhCUqRsIoq8Rup7PNp4Dg5ltmiii10WVxQFhpXTbGA4MtjOkGTs16a6PW0bqZRTz82XX1akpsvZkt+RQVTVFEe6RNGKeRM/GnqamkETVnpZNT1NcvLjJR2VAWaVEC+bm0NQUTE6iycnysTwv2x0cFEbOgcHGVhUQgHJ6hVq3x2x6mogg5jyIctMVOVH0VRc5GGwqVyXZWOoGhaycc6fbFz7rfeWVqi9siyjy3mabyoHBxo6mpsqpm7OsHDUrweRkLyhUwYIUHNzuYNbgwGBjpVtSqLaiKIMENGfxLIpaoPAkbWZ1Dgw2VlRfCSzdNgZx1tocPNWC2WAODDY2NNluBoU0zcKiAFAPDma2iP8zbHxUVUJaZdVQUbhnktkADgw2vrJscZCoLTi/lecJM9tMDgw23gZVF9WnYHBpwWwRD3Cz8VIUZe+jeq+jKr227yqkZaTZTpetknNpa6y5xGDjo3+itaJoBoRqURgHhaVple00q23HsW3JJQYbG7EwD9kUGvRrNgUIz5G0jP6LfbXkZv/tUvldihgbDgw2diLPe3Mk0RvH4FLCGigbfAssWlKtHigcJLY1BwYbKzE3hybbRNZMsxUMKi2s+Jy+PP2lCQeHbWvFv76keySdkfTkgMd+UVJIemO6L0kfkXRa0hOSrq/lPS7p2bQdX9+PYdYTC/PE3Fx3s0u0mqCwmudV05LYtrOab8DHgFv6EyVdDfwk8Hwt+VbgcNpOAB9NefcDHwJuBG4APiRp3zAHbmYbpL+K6FIoW3tgsS1jxb9gRHwRODvgoQ8DvwTUy4vHgI9H6RHgckkHgHcAD0XE2Yg4BzzEgGBjZmOiHhxcath21hTaJb0T+OuI+ErfQweBF2r3Z1LaUumDXvuEpFOSTi3gagCzTbHaUsNy+Vxy2LYuufFZ0m7gg8DNgx4ekBbLpC9OjDgJnATYq/1uvTIbhaqhuNGzKF30+3siDWp0HhQEhqmSsk21lpD+d4Brga9I+gZwCPiSpO+kLAlcXct7CHhxmXQz20oiFvcmavQ2ygZ0U80W56un27ZzyX+5iPhqRFwZEddExDWUF/3rI+JvgAeAd6feSTcBr0TES8BngZsl7UuNzjenNDPbivoDRLkoc/M+9AJF/2P1NHdb3XZW0131k8D/Bb5f0oykO5fJ/iDwHHAa+B3g3wBExFng14DH0varKc3MtrJBAaK+319KWHTfQWE70laeeniv9seNOrrZh2FmldX0MNrC15Sd4vNx/+MRcWStz/fIZzNbPV/0dwS3DpmZWYMDg5mZNTgwmJlZgwODmZk1bOleSZK+BVwA/nazj2ULeCM+D+DzUPF5KPk89NTPxfdExJvW+kJbOjAASDo1TLerceHzUPJ5KPk8lHweetbzXLgqyczMGhwYzMysYTsEhpObfQBbhM9Dyeeh5PNQ8nnoWbdzseXbGMzMbLS2Q4nBzMxGaMsGBkm3SHpG0mlJd2328Ww0Sd+Q9FVJX5Z0KqXtl/SQpGfT7b6ULkkfSefmCUnXb+7RD0fSPZLOSHqylnbJn13S8ZT/WUnHN+OzDGOJ8/Arkv46fS++LOm22mMfSOfhGUnvqKVv6/8dSVdL+oKkpyU9JennU/qO+k4scx42/jsREVtuA1rA14E3A23gK8B1m31cG/yZvwG8sS/tPwN3pf27gN9I+7cBf0i5Mt5NwKObffxDfva3AdcDT671swP7Kad83w/sS/v7NvuzrcN5+BXgFwfkvS79X0xRLpz19fR/s+3/d4ADlGu8ALwB+Mv0eXfUd2KZ87Dh34mtWmK4ATgdEc9FxDxwH3Bsk49pMxwD7k379wK319I/HqVHgMslHdiMA1wPEfFFoH99jkv97O8AHoqIsxFxDngIuGXjj379LHEelnIMuC8i5iLiryjXQLmBMfjfiYiXIuJLaf888DTlGvE76juxzHlYyrp9J7ZqYDgIvFC7P8PyJ2QcBPA5SY9LOpHSropyBTzS7ZUpfSecn0v97ON8Tt6XqkjuqapP2CHnQdI1wI8Aj7KDvxN95wE2+DuxVQPDoNVAxr371Fsj4nrgVuC9kt62TN6deH4qS332cT0nH6VcZ/2HgZeA/5bSx/48SLoM+H3gFyLi1eWyDkgbm3Mx4Dxs+HdiqwaGGeDq2v1DwIubdCwjEREvptszwB9QFv++WVURpdszKftOOD+X+tnH8pxExDcjIo+IgnK53BvSQ2N9HiRNUl4MPxERn07JO+47Meg8jOI7sVUDw2PAYUnXSmoDdwAPbPIxbRhJeyS9odoHbgaepPzMVU+K48Bn0v4DwLtTb4ybgFeqIvYYudRaJmy+AAAA9ElEQVTP/lngZkn7UtH65pS2rfW1Hf1Tyu8FlOfhDklTkq4FDgN/xhj870gScDfwdET8Zu2hHfWdWOo8jOQ7sdkt78u0yN9G2Qr/deCDm308G/xZ30zZU+ArwFPV5wWuAB4Gnk23+1O6gN9O5+arwJHN/gxDfv5PUhaJFyh/3dy5ls8O/Cxlg9tp4D2b/bnW6Tz8r/Q5n0j/zAdq+T+YzsMzwK219G39vwP8GGVVxxPAl9N22077TixzHjb8O+GRz2Zm1rBVq5LMzGyTODCYmVmDA4OZmTU4MJiZWYMDg5mZNTgwmJlZgwODmZk1ODCYmVnD/wf32nLl7mK9hwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#work\n",
    "#path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline3\"\n",
    "\n",
    "#home\n",
    "#path = f\"C:{os.sep}Users{os.sep}William{os.sep}Documents{os.sep}Baseline\"\n",
    "\n",
    "#analysis\n",
    "#path = f\"D:{os.sep}William{os.sep}2018-12-04 Test data from 08-3\"\n",
    "\n",
    "\n",
    "dataframes = []\n",
    "dfs = Parameters.iterate_through_files()\n",
    "\n",
    "\n",
    "for index, items in enumerate(dfs):\n",
    "    save_path = f'{data_path}{os.sep}{index}.pkl'\n",
    "    items['Total'].to_pickle(save_path)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print (f\"Total Time is {end_time - start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           -1               0            \\\n",
      "                                           -1               0             \n",
      "                                        Image Index    AniAvg  AniPixel   \n",
      "0    Baseline_1_MMStack_1-Pos_000_003.ome.tif     0  0.045401 -0.252169   \n",
      "1    Baseline_1_MMStack_1-Pos_000_003.ome.tif     1  0.048111 -0.247700   \n",
      "2    Baseline_1_MMStack_1-Pos_000_003.ome.tif     2  0.090796 -0.172933   \n",
      "3    Baseline_1_MMStack_1-Pos_000_003.ome.tif     3  0.070787 -0.206576   \n",
      "4    Baseline_1_MMStack_1-Pos_000_003.ome.tif     4  0.084017 -0.184636   \n",
      "5    Baseline_1_MMStack_1-Pos_000_003.ome.tif     5  0.071149 -0.208027   \n",
      "6    Baseline_1_MMStack_1-Pos_000_003.ome.tif     6  0.077978 -0.195796   \n",
      "7    Baseline_1_MMStack_1-Pos_000_003.ome.tif     7  0.061670 -0.242206   \n",
      "8    Baseline_1_MMStack_1-Pos_000_003.ome.tif     8  0.068974 -0.210574   \n",
      "9    Baseline_1_MMStack_1-Pos_000_003.ome.tif     9  0.084969 -0.183823   \n",
      "10   Baseline_1_MMStack_1-Pos_000_003.ome.tif    10  0.080539 -0.191052   \n",
      "11   Baseline_1_MMStack_1-Pos_000_003.ome.tif    11  0.067801 -0.215595   \n",
      "12   Baseline_1_MMStack_1-Pos_000_003.ome.tif    12  0.098546 -0.160280   \n",
      "13   Baseline_1_MMStack_1-Pos_000_003.ome.tif    13       NaN       NaN   \n",
      "14   Baseline_1_MMStack_1-Pos_000_003.ome.tif    14       NaN       NaN   \n",
      "15   Baseline_1_MMStack_1-Pos_000_003.ome.tif    15       NaN       NaN   \n",
      "16   Baseline_1_MMStack_1-Pos_000_003.ome.tif    16       NaN       NaN   \n",
      "17   Baseline_1_MMStack_1-Pos_000_003.ome.tif    17       NaN       NaN   \n",
      "18   Baseline_1_MMStack_1-Pos_000_003.ome.tif    18       NaN       NaN   \n",
      "19   Baseline_1_MMStack_1-Pos_000_003.ome.tif    19       NaN       NaN   \n",
      "20   Baseline_1_MMStack_1-Pos_000_003.ome.tif    20       NaN       NaN   \n",
      "21   Baseline_1_MMStack_1-Pos_000_003.ome.tif    21       NaN       NaN   \n",
      "22   Baseline_1_MMStack_1-Pos_000_003.ome.tif    22       NaN       NaN   \n",
      "23   Baseline_1_MMStack_1-Pos_000_003.ome.tif    23       NaN       NaN   \n",
      "24   Baseline_1_MMStack_1-Pos_001_000.ome.tif     0       NaN       NaN   \n",
      "25   Baseline_1_MMStack_1-Pos_001_000.ome.tif     1  0.059460 -0.227838   \n",
      "26   Baseline_1_MMStack_1-Pos_001_000.ome.tif     2  0.076005 -0.198678   \n",
      "27   Baseline_1_MMStack_1-Pos_001_000.ome.tif     3  0.035558 -0.269564   \n",
      "28   Baseline_1_MMStack_1-Pos_001_000.ome.tif     4  0.084871 -0.182411   \n",
      "29   Baseline_1_MMStack_1-Pos_001_000.ome.tif     5  0.034743 -0.271767   \n",
      "..                                        ...   ...       ...       ...   \n",
      "104  Baseline_1_MMStack_1-Pos_003_002.ome.tif     4  0.067232 -0.214968   \n",
      "105  Baseline_1_MMStack_1-Pos_003_002.ome.tif     5  0.026229 -0.287429   \n",
      "106  Baseline_1_MMStack_1-Pos_003_002.ome.tif     6  0.069043 -0.211151   \n",
      "107  Baseline_1_MMStack_1-Pos_003_002.ome.tif     7  0.041935 -0.295068   \n",
      "108  Baseline_1_MMStack_1-Pos_003_002.ome.tif     8  0.065483 -0.217687   \n",
      "109  Baseline_1_MMStack_1-Pos_003_002.ome.tif     9  0.067811 -0.263383   \n",
      "110  Baseline_1_MMStack_1-Pos_003_002.ome.tif    10  0.088157 -0.179569   \n",
      "111  Baseline_1_MMStack_1-Pos_003_002.ome.tif    11  0.044579 -0.254155   \n",
      "112  Baseline_1_MMStack_1-Pos_003_002.ome.tif    12  0.039971 -0.263630   \n",
      "113  Baseline_1_MMStack_1-Pos_003_002.ome.tif    13  0.090187 -0.174375   \n",
      "114  Baseline_1_MMStack_1-Pos_003_002.ome.tif    14  0.038979 -0.264280   \n",
      "115  Baseline_1_MMStack_1-Pos_003_002.ome.tif    15       NaN       NaN   \n",
      "116  Baseline_1_MMStack_1-Pos_003_002.ome.tif    16       NaN       NaN   \n",
      "117  Baseline_1_MMStack_1-Pos_003_002.ome.tif    17       NaN       NaN   \n",
      "118  Baseline_1_MMStack_1-Pos_003_002.ome.tif    18       NaN       NaN   \n",
      "119  Baseline_1_MMStack_1-Pos_003_002.ome.tif    19       NaN       NaN   \n",
      "120  Baseline_1_MMStack_1-Pos_003_002.ome.tif    20       NaN       NaN   \n",
      "121  Baseline_1_MMStack_1-Pos_003_002.ome.tif    21       NaN       NaN   \n",
      "122  Baseline_1_MMStack_1-Pos_003_002.ome.tif    22       NaN       NaN   \n",
      "123  Baseline_1_MMStack_1-Pos_003_002.ome.tif    23       NaN       NaN   \n",
      "124  Baseline_1_MMStack_1-Pos_003_002.ome.tif    24       NaN       NaN   \n",
      "125  Baseline_1_MMStack_1-Pos_003_002.ome.tif    25       NaN       NaN   \n",
      "126  Baseline_1_MMStack_1-Pos_003_002.ome.tif    26       NaN       NaN   \n",
      "127  Baseline_1_MMStack_1-Pos_003_002.ome.tif    27       NaN       NaN   \n",
      "128  Baseline_1_MMStack_1-Pos_003_002.ome.tif    28       NaN       NaN   \n",
      "129  Baseline_1_MMStack_1-Pos_003_002.ome.tif    29       NaN       NaN   \n",
      "130  Baseline_1_MMStack_1-Pos_003_002.ome.tif    30       NaN       NaN   \n",
      "131  Baseline_1_MMStack_1-Pos_003_002.ome.tif    31       NaN       NaN   \n",
      "132  Baseline_1_MMStack_1-Pos_003_002.ome.tif    32       NaN       NaN   \n",
      "133  Baseline_1_MMStack_1-Pos_003_002.ome.tif    33       NaN       NaN   \n",
      "\n",
      "                                                      1            \\\n",
      "                                            1         0             \n",
      "             Para          Perp     Intensity    AniAvg  AniPixel   \n",
      "0      684.856122    599.342192           NaN       NaN       NaN   \n",
      "1      705.314195    612.450289           NaN       NaN       NaN   \n",
      "2     7734.550298   5951.528942           NaN  0.091868 -0.170857   \n",
      "3     4624.441841   3764.183230           NaN       NaN       NaN   \n",
      "4     6330.695059   4964.585882           NaN  0.088916 -0.178489   \n",
      "5      955.799357    777.200286   2643.944633  0.060088 -0.227243   \n",
      "6     1208.319752    963.788895           NaN       NaN       NaN   \n",
      "7     1311.577412   1095.565611           NaN  0.045449 -0.274328   \n",
      "8     1248.243434   1021.264210           NaN       NaN       NaN   \n",
      "9    17938.466764  14030.038816           NaN  0.090940 -0.173105   \n",
      "10   12620.290712   9994.031579           NaN  0.084244 -0.184060   \n",
      "11     787.128512    646.142836           NaN  0.066673 -0.215959   \n",
      "12   10910.181818   8215.756474           NaN  0.108366 -0.143190   \n",
      "13            NaN           NaN   1795.467156       NaN       NaN   \n",
      "14            NaN           NaN   2545.361181       NaN       NaN   \n",
      "15            NaN           NaN   2226.000000       NaN       NaN   \n",
      "16            NaN           NaN   1835.510955       NaN       NaN   \n",
      "17            NaN           NaN    855.038780       NaN       NaN   \n",
      "18            NaN           NaN   1168.267397       NaN       NaN   \n",
      "19            NaN           NaN           NaN  0.074599 -0.203661   \n",
      "20            NaN           NaN           NaN  0.067346 -0.226823   \n",
      "21            NaN           NaN           NaN  0.049856 -0.244983   \n",
      "22            NaN           NaN           NaN       NaN       NaN   \n",
      "23            NaN           NaN           NaN       NaN       NaN   \n",
      "24            NaN           NaN           NaN       NaN       NaN   \n",
      "25     916.724351    770.578080   6833.432440  0.050724 -0.243412   \n",
      "26    1732.362889   1389.481367           NaN  0.074001 -0.202726   \n",
      "27     562.491438    506.471426           NaN  0.039508 -0.262531   \n",
      "28     788.666667    617.000000           NaN       NaN       NaN   \n",
      "29     567.063867    511.799795           NaN       NaN       NaN   \n",
      "..            ...           ...           ...       ...       ...   \n",
      "104   1331.135800   1094.472626           NaN  0.066038 -0.216549   \n",
      "105    536.468183    496.359415           NaN  0.017584 -0.303203   \n",
      "106   1159.670252    948.613984           NaN  0.062384 -0.222922   \n",
      "107    784.917111    693.812590           NaN  0.052054 -0.292680   \n",
      "108    883.849824    730.325328           NaN  0.072522 -0.205711   \n",
      "109   2369.989611   1945.435194           NaN  0.067071 -0.279577   \n",
      "110  26458.486429  20509.820212   2339.431305  0.089648 -0.176858   \n",
      "111   1038.805291    911.250467           NaN  0.047508 -0.248745   \n",
      "112    658.428921    585.318831           NaN  0.041818 -0.260048   \n",
      "113   2744.777399   2115.628013           NaN  0.093687 -0.168327   \n",
      "114    770.478277    686.896414           NaN  0.047790 -0.248589   \n",
      "115           NaN           NaN   3425.675028       NaN       NaN   \n",
      "116           NaN           NaN   2537.980616       NaN       NaN   \n",
      "117           NaN           NaN   3206.129515       NaN       NaN   \n",
      "118           NaN           NaN   1018.780863       NaN       NaN   \n",
      "119           NaN           NaN   6679.933113       NaN       NaN   \n",
      "120           NaN           NaN  57388.458213       NaN       NaN   \n",
      "121           NaN           NaN   3865.236659       NaN       NaN   \n",
      "122           NaN           NaN           NaN       NaN       NaN   \n",
      "123           NaN           NaN   3640.937519       NaN       NaN   \n",
      "124           NaN           NaN   2587.712975       NaN       NaN   \n",
      "125           NaN           NaN   1559.481792       NaN       NaN   \n",
      "126           NaN           NaN           NaN       NaN       NaN   \n",
      "127           NaN           NaN           NaN  0.051021 -0.242969   \n",
      "128           NaN           NaN           NaN       NaN       NaN   \n",
      "129           NaN           NaN           NaN       NaN       NaN   \n",
      "130           NaN           NaN           NaN       NaN       NaN   \n",
      "131           NaN           NaN           NaN       NaN       NaN   \n",
      "132           NaN           NaN           NaN       NaN       NaN   \n",
      "133           NaN           NaN           NaN       NaN       NaN   \n",
      "\n",
      "                       ...              2                          \\\n",
      "                       ...              0                           \n",
      "             Para      ...         AniAvg  AniPixel          Para   \n",
      "0             NaN      ...       0.045401 -0.252169    684.856122   \n",
      "1             NaN      ...       0.048111 -0.247700    705.314195   \n",
      "2     6767.883175      ...       0.090796 -0.172933   7734.550298   \n",
      "3             NaN      ...       0.070787 -0.206576   4624.441841   \n",
      "4     3212.369220      ...       0.084017 -0.184636   6330.695059   \n",
      "5      816.604886      ...       0.071149 -0.208027    955.799357   \n",
      "6             NaN      ...       0.077978 -0.195796   1208.319752   \n",
      "7      967.901806      ...       0.061670 -0.242206   1311.577412   \n",
      "8             NaN      ...       0.068974 -0.210574   1248.243434   \n",
      "9    12488.033584      ...       0.084969 -0.183823  17938.466764   \n",
      "10    9652.178446      ...       0.080539 -0.191052  12620.290712   \n",
      "11     908.074092      ...       0.067801 -0.215595    787.128512   \n",
      "12    8371.467955      ...       0.098546 -0.160280  10910.181818   \n",
      "13            NaN      ...            NaN       NaN           NaN   \n",
      "14            NaN      ...            NaN       NaN           NaN   \n",
      "15            NaN      ...            NaN       NaN           NaN   \n",
      "16            NaN      ...            NaN       NaN           NaN   \n",
      "17            NaN      ...            NaN       NaN           NaN   \n",
      "18            NaN      ...            NaN       NaN           NaN   \n",
      "19    2090.556053      ...            NaN       NaN           NaN   \n",
      "20    1584.268532      ...            NaN       NaN           NaN   \n",
      "21     845.981983      ...            NaN       NaN           NaN   \n",
      "22            NaN      ...            NaN       NaN           NaN   \n",
      "23            NaN      ...            NaN       NaN           NaN   \n",
      "24            NaN      ...            NaN       NaN           NaN   \n",
      "25     777.749367      ...       0.059460 -0.227838    916.724351   \n",
      "26    1504.582350      ...       0.076005 -0.198678   1732.362889   \n",
      "27     575.572094      ...       0.035558 -0.269564    562.491438   \n",
      "28            NaN      ...       0.084871 -0.182411    788.666667   \n",
      "29            NaN      ...       0.034743 -0.271767    567.063867   \n",
      "..            ...      ...            ...       ...           ...   \n",
      "104   1425.196984      ...       0.067232 -0.214968   1331.135800   \n",
      "105    525.390901      ...       0.026229 -0.287429    536.468183   \n",
      "106   1162.300839      ...       0.069043 -0.211151   1159.670252   \n",
      "107   1200.834270      ...       0.041935 -0.295068    784.917111   \n",
      "108   1012.356427      ...       0.065483 -0.217687    883.849824   \n",
      "109   2644.012231      ...       0.067811 -0.263383   2369.989611   \n",
      "110  29651.894576      ...       0.088157 -0.179569  26458.486429   \n",
      "111   1082.185029      ...       0.044579 -0.254155   1038.805291   \n",
      "112    679.066224      ...       0.039971 -0.263630    658.428921   \n",
      "113   3132.608454      ...       0.090187 -0.174375   2744.777399   \n",
      "114    832.946644      ...       0.038979 -0.264280    770.478277   \n",
      "115           NaN      ...            NaN       NaN           NaN   \n",
      "116           NaN      ...            NaN       NaN           NaN   \n",
      "117           NaN      ...            NaN       NaN           NaN   \n",
      "118           NaN      ...            NaN       NaN           NaN   \n",
      "119           NaN      ...            NaN       NaN           NaN   \n",
      "120           NaN      ...            NaN       NaN           NaN   \n",
      "121           NaN      ...            NaN       NaN           NaN   \n",
      "122           NaN      ...            NaN       NaN           NaN   \n",
      "123           NaN      ...            NaN       NaN           NaN   \n",
      "124           NaN      ...            NaN       NaN           NaN   \n",
      "125           NaN      ...            NaN       NaN           NaN   \n",
      "126           NaN      ...            NaN       NaN           NaN   \n",
      "127    616.570936      ...            NaN       NaN           NaN   \n",
      "128           NaN      ...            NaN       NaN           NaN   \n",
      "129           NaN      ...            NaN       NaN           NaN   \n",
      "130           NaN      ...            NaN       NaN           NaN   \n",
      "131           NaN      ...            NaN       NaN           NaN   \n",
      "132           NaN      ...            NaN       NaN           NaN   \n",
      "133           NaN      ...            NaN       NaN           NaN   \n",
      "\n",
      "                                        3                          \\\n",
      "                              1         0                           \n",
      "             Perp     Intensity    AniAvg  AniPixel          Para   \n",
      "0      599.342192           NaN       NaN       NaN           NaN   \n",
      "1      612.450289           NaN       NaN       NaN           NaN   \n",
      "2     5951.528942           NaN  0.091868 -0.170857   6767.883175   \n",
      "3     3764.183230           NaN       NaN       NaN           NaN   \n",
      "4     4964.585882           NaN  0.088916 -0.178489   3212.369220   \n",
      "5      777.200286   2643.944633  0.060088 -0.227243    816.604886   \n",
      "6      963.788895           NaN       NaN       NaN           NaN   \n",
      "7     1095.565611           NaN  0.045449 -0.274328    967.901806   \n",
      "8     1021.264210           NaN       NaN       NaN           NaN   \n",
      "9    14030.038816           NaN  0.090940 -0.173105  12488.033584   \n",
      "10    9994.031579           NaN  0.084244 -0.184060   9652.178446   \n",
      "11     646.142836           NaN  0.066673 -0.215959    908.074092   \n",
      "12    8215.756474           NaN  0.108366 -0.143190   8371.467955   \n",
      "13            NaN   1795.467156       NaN       NaN           NaN   \n",
      "14            NaN   2545.361181       NaN       NaN           NaN   \n",
      "15            NaN   2226.000000       NaN       NaN           NaN   \n",
      "16            NaN   1835.510955       NaN       NaN           NaN   \n",
      "17            NaN    855.038780       NaN       NaN           NaN   \n",
      "18            NaN   1168.267397       NaN       NaN           NaN   \n",
      "19            NaN           NaN  0.074599 -0.203661   2090.556053   \n",
      "20            NaN           NaN  0.067346 -0.226823   1584.268532   \n",
      "21            NaN           NaN  0.049856 -0.244983    845.981983   \n",
      "22            NaN           NaN       NaN       NaN           NaN   \n",
      "23            NaN           NaN       NaN       NaN           NaN   \n",
      "24            NaN           NaN       NaN       NaN           NaN   \n",
      "25     770.578080   6833.432440  0.050724 -0.243412    777.749367   \n",
      "26    1389.481367           NaN  0.074001 -0.202726   1504.582350   \n",
      "27     506.471426           NaN  0.039508 -0.262531    575.572094   \n",
      "28     617.000000           NaN       NaN       NaN           NaN   \n",
      "29     511.799795           NaN       NaN       NaN           NaN   \n",
      "..            ...           ...       ...       ...           ...   \n",
      "104   1094.472626           NaN  0.066038 -0.216549   1425.196984   \n",
      "105    496.359415           NaN  0.017584 -0.303203    525.390901   \n",
      "106    948.613984           NaN  0.062384 -0.222922   1162.300839   \n",
      "107    693.812590           NaN  0.052054 -0.292680   1200.834270   \n",
      "108    730.325328           NaN  0.072522 -0.205711   1012.356427   \n",
      "109   1945.435194           NaN  0.067071 -0.279577   2644.012231   \n",
      "110  20509.820212   2339.431305  0.089648 -0.176858  29651.894576   \n",
      "111    911.250467           NaN  0.047508 -0.248745   1082.185029   \n",
      "112    585.318831           NaN  0.041818 -0.260048    679.066224   \n",
      "113   2115.628013           NaN  0.093687 -0.168327   3132.608454   \n",
      "114    686.896414           NaN  0.047790 -0.248589    832.946644   \n",
      "115           NaN   3425.675028       NaN       NaN           NaN   \n",
      "116           NaN   2537.980616       NaN       NaN           NaN   \n",
      "117           NaN   3206.129515       NaN       NaN           NaN   \n",
      "118           NaN   1018.780863       NaN       NaN           NaN   \n",
      "119           NaN   6679.933113       NaN       NaN           NaN   \n",
      "120           NaN  57388.458213       NaN       NaN           NaN   \n",
      "121           NaN   3865.236659       NaN       NaN           NaN   \n",
      "122           NaN           NaN       NaN       NaN           NaN   \n",
      "123           NaN   3640.937519       NaN       NaN           NaN   \n",
      "124           NaN   2587.712975       NaN       NaN           NaN   \n",
      "125           NaN   1559.481792       NaN       NaN           NaN   \n",
      "126           NaN           NaN       NaN       NaN           NaN   \n",
      "127           NaN           NaN  0.051021 -0.242969    616.570936   \n",
      "128           NaN           NaN       NaN       NaN           NaN   \n",
      "129           NaN           NaN       NaN       NaN           NaN   \n",
      "130           NaN           NaN       NaN       NaN           NaN   \n",
      "131           NaN           NaN       NaN       NaN           NaN   \n",
      "132           NaN           NaN       NaN       NaN           NaN   \n",
      "133           NaN           NaN       NaN       NaN           NaN   \n",
      "\n",
      "                                 \n",
      "                              1  \n",
      "             Perp     Intensity  \n",
      "0             NaN           NaN  \n",
      "1             NaN           NaN  \n",
      "2     5192.147581           NaN  \n",
      "3             NaN           NaN  \n",
      "4     2484.849091           NaN  \n",
      "5      685.193811   2477.587157  \n",
      "6             NaN           NaN  \n",
      "7      846.928155           NaN  \n",
      "8             NaN           NaN  \n",
      "9     9605.343350           NaN  \n",
      "10    7564.509754           NaN  \n",
      "11     747.812247           NaN  \n",
      "12    6134.696105           NaN  \n",
      "13            NaN   1323.015827  \n",
      "14            NaN   1951.577207  \n",
      "15            NaN           NaN  \n",
      "16            NaN           NaN  \n",
      "17            NaN           NaN  \n",
      "18            NaN   1049.567620  \n",
      "19    1683.437363           NaN  \n",
      "20    1302.179857           NaN  \n",
      "21     730.922540           NaN  \n",
      "22            NaN    678.261951  \n",
      "23            NaN   1215.044621  \n",
      "24            NaN           NaN  \n",
      "25     670.298588   5639.354122  \n",
      "26    1213.624464           NaN  \n",
      "27     512.348532           NaN  \n",
      "28            NaN           NaN  \n",
      "29            NaN           NaN  \n",
      "..            ...           ...  \n",
      "104   1175.785264           NaN  \n",
      "105    498.617012           NaN  \n",
      "106    968.904115           NaN  \n",
      "107   1030.990607           NaN  \n",
      "108    820.001769           NaN  \n",
      "109   2174.925338           NaN  \n",
      "110  22889.631015   2553.649004  \n",
      "111    941.330415           NaN  \n",
      "112    600.450083           NaN  \n",
      "113   2391.092015           NaN  \n",
      "114    723.944731           NaN  \n",
      "115           NaN   3023.386587  \n",
      "116           NaN   1879.457156  \n",
      "117           NaN           NaN  \n",
      "118           NaN           NaN  \n",
      "119           NaN   5111.722182  \n",
      "120           NaN  53834.890933  \n",
      "121           NaN   3783.174273  \n",
      "122           NaN           NaN  \n",
      "123           NaN   3021.957295  \n",
      "124           NaN   2848.620811  \n",
      "125           NaN   1466.307573  \n",
      "126           NaN           NaN  \n",
      "127    530.934443           NaN  \n",
      "128           NaN   8342.728831  \n",
      "129           NaN           NaN  \n",
      "130           NaN           NaN  \n",
      "131           NaN           NaN  \n",
      "132           NaN           NaN  \n",
      "133           NaN           NaN  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134 rows x 22 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Organize and output the dataframes to excel files\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sub_dataframe = dfs[0][\"Total\"]\n",
    "columns = sub_dataframe.columns\n",
    "sub_dataframe.loc[:, pd.IndexSlice[1,0,:]].mean()\n",
    "\n",
    "#work\n",
    "writer = pd.ExcelWriter(f\"{data_path}{os.sep}test.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "#home\n",
    "#writer = pd.ExcelWriter(\"C:{os.sep}Users{os.sep}William{os.sep}Documents{os.sep}Baseline{os.sep}test.xlsx\", engine='xlsxwriter')\n",
    "#print (sub_dataframe)\n",
    "\n",
    "sub_dataframe.to_excel(writer, \"Raw_Data\")\n",
    "create_summary_columns(sub_dataframe).to_excel(writer, \"Summary\")\n",
    "\n",
    "cell_cell_comparison = create_cell_comparisons(sub_dataframe, Parameters)\n",
    "for key in cell_cell_comparison:\n",
    "    cell_cell_comparison[key].to_excel(writer, key)\n",
    "\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Cells beyond this point are not part of the main program...\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagingParameters():\n",
    "    #Note: the input to __init__ may be replaced by just the config file path\n",
    "    def __init__(self, data_path,\n",
    "                 numerical_aperture=None, \n",
    "                 index_of_refraction=None, \n",
    "                 magnification = None, \n",
    "                 gFactor = None, \n",
    "                 channel_array = [1], \n",
    "                 image_type_array = ['Intensity'], \n",
    "                 channel_thresholds = 0, \n",
    "                 timepoints = 1, \n",
    "                 same_cells = False, \n",
    "                 max_filter_region = 5,\n",
    "                 max_threshold =  600,\n",
    "                 root_dir_same_treatment = True, \n",
    "                 suffix = \"ome.tif\", \n",
    "                 machine_learning_mode = False, \n",
    "                 debug_mode = False,\n",
    "                 weights_path = \"final.pt\"):\n",
    "        \n",
    "        \n",
    "\n",
    "        #    for key, value in **kwargs.iteritems():\n",
    "        #        setattr(self, key, value)\n",
    "        \n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.numerical_aperture = numerical_aperture\n",
    "        self.index_of_refraction = index_of_refraction\n",
    "        self.magnification = magnification\n",
    "        self.gFactor = gFactor\n",
    "        self.channel_array = channel_array\n",
    "        self.image_type_array = image_type_array\n",
    "        self.max_filter_region = max_filter_region\n",
    "        self.max_threhsold = max_threshold\n",
    "        self.root_dir_same_treatment = root_dir_same_treatment\n",
    "        self.suffix = suffix\n",
    "        self.channel_thresholds = channel_thresholds\n",
    "        self.machine_learning_mode = machine_learning_mode\n",
    "        self.debug_mode = debug_mode\n",
    "        \n",
    "        \n",
    "        self.weights_path = weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create_cell_comparisons(sub_dataframe, Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"D://Documents//Documents//0000 New Scope//Baseline3//Treat1//Baseline_1//Baseline_1_MMStack_1-Pos_000_003.ome.tif\"\n",
    "image = np.asarray(bioformats.load_image(image_path))\n",
    "image = np.dstack([image, image*0.9, image*0.8])\n",
    "print (\"Max 1\", np.amax(image))\n",
    "image = ((image/np.amax(image))*255).astype('uint8')\n",
    "print (\"Max 2\", np.amax(image))\n",
    "#print (image)\n",
    "image2 = cv2.rectangle(image, (200,0), (400, 1000), (255,0,0), 20)\n",
    "plt.imshow(image2)\n",
    "\n",
    "save_path = \"D://Documents//Documents//0000 New Scope//Baseline3//debug//Treat1//Baseline_1//Baseline_1_MMStack_1-Pos_000_003.jpg\"\n",
    "\n",
    "\n",
    "imageio.imwrite(save_path, image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (dfs[3])\n",
    "for items in dfs:\n",
    "    for keys in items:\n",
    "        print (type(items[keys]), keys)\n",
    "        #items[keys].pop(\"ROI\")\n",
    "        items[keys].to_csv(\"D:/Documents/Documents/0000 New Scope/Baseline3/test.csv\")\n",
    "\n",
    "\n",
    "\"\"\"final_dataframe = pd.DataFrame([])\n",
    "\n",
    "for filenames in dfs[-1]:\n",
    "    print (f\"current filename is: {filenames}\")\n",
    "    df_interest = dfs[-1][filenames]\n",
    "    print (type(df_interest))\n",
    "    #print (df_interest)\n",
    "    if len(final_dataframe)==0:\n",
    "        print (\"need a new dataframe\")\n",
    "        final_dataframe = df_interest\n",
    "    else:\n",
    "        print (\"Appending\")\n",
    "        final_dataframe = final_dataframe.append(df_interest, ignore_index = True, sort = False)\n",
    "\n",
    "print (final_dataframe)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.ones((5,6))\n",
    "array = np.pad(array, ((2,3), (0,1)), 'constant')\n",
    "print (array)\n",
    "print (array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([], columns=[\"Image\", \"Index\", \"ROI\"])\n",
    "df.head()\n",
    "\n",
    "imparameters = ImageParams(f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline{os.sep}Baseline_1\",\n",
    "                         \"Baseline_1_MMStack_1-Pos_002_002.ome.tif\", Parameters.channel_array, Parameters.image_type_array)\n",
    "\n",
    "df2 = pd.DataFrame({\"Image\": [imparameters, 2], \"ROI\": [3,4]})\n",
    "df3 = df.append(df2, sort=False)\n",
    "df3.head()\n",
    "\n",
    "print (df3.at[0, \"Image\"])\n",
    "\n",
    "#for index, items in enumerate(df3[\"Image\"]):\n",
    "#    print (index, items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array = []\n",
    "array.append({\"array\": 1})\n",
    "print (\"array\" in array[-1])\n",
    "array.append([2,3])\n",
    "print (array[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example full program::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline_1\"\n",
    "dir_list = find_files(path)\n",
    "iterate_through_files (dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff  = pd.DataFrame({(\"A\", \"B\"): [1,2,3], (\"A\", \"C\"): [2,5,6], (\"G\"):[1,2,3]})\n",
    "dff.at[2, (\"A\", \"B\")]= 100\n",
    "for columns in dff.columns:\n",
    "    print (columns[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1, 2, 3, 43, 6, 5])\n",
    "arr2 = np.array([True, True, True, False, False, True])\n",
    "arr4 = arr1[:4].copy()\n",
    "arr3 = np.multiply (arr1, arr2)\n",
    "print (arr3)\n",
    "print (np.mean(arr3[arr3 !=0]))\n",
    "\n",
    "print (arr4)\n",
    "arr4[2] = 100\n",
    "print (arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = \"D:/Documents/Documents/0000 New Scope/Baseline3/Treat1/Baseline_1/Baseline_1_MMStack_1-Pos_000_003.ome.tif\"\n",
    "\n",
    "import_image = np.asarray(bioformats.load_image(new_path, t=0, rescale = False)).astype('float')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_image = import_image.copy()\n",
    "\n",
    "new_image [new_image <  10000] = np.nan\n",
    "\n",
    "plt.imshow(new_image)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "\n",
    "fgmask = fgbg.apply(import_image)\n",
    "cv2.imshow('frame',fgmask)\n",
    "k = cv2.waitKey(30) & 0xff\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BF Matcher\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "bio_loc = f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_002_002.ome.tif'\n",
    "\n",
    "bio_para_import = np.asarray(bioformats.load_image(bio_loc, \n",
    "                                          c = 0, z=0, t=1, rescale=False))\n",
    "\n",
    "bio_perp_import = np.asarray(bioformats.load_image(bio_loc, \n",
    "                                          c = 0, z=0, t=2, rescale=False))\n",
    "\n",
    "bio_para = skimage.img_as_ubyte(bio_para_import)\n",
    "bio_perp = skimage.img_as_ubyte(bio_perp_import)\n",
    "\n",
    "filtered_para = cv2.bilateralFilter(bio_para, 9, 75, 75)\n",
    "\n",
    "print (type(bio_para[0,0]))\n",
    "print(cv2.imread(bio_loc, 0).shape)\n",
    "#bio_para = cv2.imread(bio_loc, 0)\n",
    "\n",
    "#bio_perp = cv2.imread(bio_loc, 0)\n",
    "\n",
    "print (type(bio_para[0,0]))\n",
    "\n",
    "b = cv2.normalize(bio_para_import, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n",
    "\n",
    "\n",
    "\n",
    "print (bio_para.shape)\n",
    "print (bio_para[:4,:4], bio_perp[:4, :4])\n",
    "print (b[:4,:4])\n",
    "print(type(b[0,0]))\n",
    "\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "kp1, des1 = orb.detectAndCompute(bio_para, None)\n",
    "kp2, des2 = orb.detectAndCompute(bio_perp, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "\n",
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "\n",
    "img3 = cv2.drawMatches(bio_para, kp1, bio_perp, kp2, matches[:10], None, flags = 2)\n",
    "cv2.imshow(\"Matches\", img3)\n",
    "#plt.imshow(bio_para)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#fig, axs = plt.subpolots(1, 1)\n",
    "#axs = plt.hist(bio_para)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "cv2.imshow(\"Para\", bio_para)\n",
    "cv2.imshow(\"Bilateral\", filtered_para)\n",
    "cv2.imshow(\"Perp\", bio_perp)\n",
    "cv2.imshow(\"Difference\", (bio_para - bio_perp)*100)\n",
    "cv2.imshow(\"Normalizes\", b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#print (bioformats.get_omexml_metadata(path=f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_001.ome.tif'))\n",
    "\n",
    "\n",
    "print (kp1, des1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,2,3,4], [5,6,7,8], 'ro')\n",
    "plt.axis([0,10,0,20])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bio_para_reshape = bio_para_import.reshape(-1, 1)\n",
    "print (bio_para_reshape.shape)\n",
    "bio_para_reshape2 = filtered_para.reshape(-1, 1)\n",
    "\n",
    "x = 100+ 15*np.random.randn(10000)\n",
    "#n, bins, patches = plt.hist(bio_para_reshape, 50)\n",
    "n, bins, patches = plt.hist(bio_para_reshape2, 50)\n",
    "print (max(bio_para_reshape2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def find_maxima (image, sigma = 9, h_value = None):\n",
    "    \n",
    "    if not h_value:\n",
    "        h_value = max(image)/1000\n",
    "              \n",
    "    \n",
    "    proc_image = cv2.GaussianBlur(img, (sigma, sigma), 0)\n",
    "    \n",
    "    local_maxima = extrema.h_maxima(proc_image, h_value)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (local_maxima)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "local_maximums = find_maxima(bio_para_import, 1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize= (15,5))\n",
    "\n",
    "ax[0].imshow(bio_para_import)\n",
    "\n",
    "ax[1].imshow(local_maximums)\n",
    "\n",
    "print (find_maxima(bio_para_import, 1, 1))\n",
    "\n",
    "x = np.arange(bio_para_import.shape[1])\n",
    "y = np.arange(bio_para_import.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "#x, y = np.meshgrid(x, y)\n",
    "#ax[2].scatter(x, y, c=local_maximums[x,y])\n",
    "#ax[2].show()\n",
    "\n",
    "plt.imshow(find_maxima(bio_para_import, 1, 50))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "xy = peak_local_max(bio_para_import, min_distance=5,threshold_abs=1200)\n",
    "plt.scatter(xy[:, 0], xy[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "y = np.arange(16)\n",
    "test_data = np.random.randint(low=0,high=65535, size=(10, 16))\n",
    "\n",
    "#scatter plot the measurements with\n",
    "# x - measurement index (0-9 in this case)\n",
    "# y - byte value index (0-15 in this case) \n",
    "# c = test_data[x,y]\n",
    "\n",
    "x, y = np.meshgrid(x,y)\n",
    "plt.scatter(x,y,c=test_data[x,y])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline_1\"\n",
    "\n",
    "print (os.listdir(data_path)[4])\n",
    "print (f'{data_path}{os.sep}{os.listdir(data_path)[4]}')\n",
    "\n",
    "img = cv2.imread(f'{data_path}{os.sep}{os.listdir(data_path)[4]}')*100\n",
    "#cv2.imshow(\"image\", (img[:,:,1]*1000))\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "cv2.circle(img, (2000,1000), 400, (255,255,255), -1)\n",
    "points = np.array([[1,1], [33,4], [100,20], [50, 400]], np.int32)\n",
    "cv2.polylines(img, [points], True, (0,255,255), 3)\n",
    "cv2.putText(img, \"Hello, world!\", (0,100), cv2.FONT_HERSHEY_COMPLEX, 4, (255, 0, 0))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "#img = np.ones((100,100,3))*1\n",
    "#img[:,:,2] = np.arange(0, 100*100, 1).resize((100,100))\n",
    "print (img[:,:,2])\n",
    "\n",
    "gg = calculate_anisotropy(image = img, Parameters = Parameters)\n",
    "\n",
    "\n",
    "print (gg.shape)\n",
    "cv2.imwrite(f'{path}{os.sep}{os.listdir(path)[7]}2.tiff', gg)\n",
    "\n",
    "#print (sum(sum(img-gg)))\n",
    "\n",
    "#cv2.imshow(\"image\", (img-gg)*1000)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Thresholding options\n",
    "Works Well\n",
    "\n",
    "from skimage.feature import peak_local_max\n",
    "xy = peak_local_max(bio_para_import, min_distance=2,threshold_abs=1500)\n",
    "plt.scatter(xy[:, 0], xy[:, 1])\n",
    "\n",
    "\n",
    "Works Better:\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fname = '/tmp/slice0000.png'\n",
    "neighborhood_size = 40\n",
    "threshold = 700\n",
    "\n",
    "\n",
    "data = bio_para_import\n",
    "#data = scipy.misc.imread(fname)\n",
    "\n",
    "data_max = filters.maximum_filter(data, neighborhood_size)\n",
    "maxima = (data == data_max)\n",
    "data_min = filters.minimum_filter(data, neighborhood_size)\n",
    "diff = ((data_max - data_min) > threshold)\n",
    "maxima[diff == 0] = 0\n",
    "\n",
    "labeled, num_objects = ndimage.label(maxima)\n",
    "slices = ndimage.find_objects(labeled)\n",
    "x, y = [], []\n",
    "for dy,dx in slices:\n",
    "    x_center = (dx.start + dx.stop - 1)/2\n",
    "    x.append(x_center)\n",
    "    y_center = (dy.start + dy.stop - 1)/2    \n",
    "    y.append(y_center)\n",
    "\n",
    "plt.imshow(data)\n",
    "#plt.savefig('/tmp/data.png', bbox_inches = 'tight')\n",
    "\n",
    "plt.autoscale(False)\n",
    "plt.plot(x,y, 'ro')\n",
    "#plt.savefig('/tmp/result.png', bbox_inches = 'tight')\n",
    "\n",
    "print (x, y)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all of the files in the current path\n",
    "print(os.path.isdir(path))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"for items in os.listdir(path):\n",
    "    #print (items, \"file:\",  os.path.isfile(f\"{path}/{items}\"), \"dir:\",  os.path.isdir(f'{path}/{items}'))\n",
    "    img = cv2.imread(f'{path}/{items}')\n",
    "    cv2.imshow('image', img*100)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Options for going up ap directory:\n",
    "\n",
    "1) split path by \"/\" __file__.rsplit(os.sep, 2)  or print(path.rsplit('/')[-3])\n",
    "2) iterate up twice os.path.dirname(os.path.dirname(path))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing the find_files function\n",
    "\"\"\"\n",
    "\n",
    "path2 = \"D:\\\\Documents\\\\Documents\\\\0000 New Scope\\\\2018-08-01 Nuclear Parameter Test\"\n",
    "#path2 = \"D:/Documents/Documents/0000 New Scope/2018-08-01 Nuclear Parameter Test/N2(600-40)/Baseline/Baseline_1\"\n",
    "dir_list = {}\n",
    "result = find_files(path2, dir_list)\n",
    "\n",
    "\n",
    "for items in result:\n",
    "    print (f'{items}, {result[items]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline_1\"\n",
    "print (data_path)\n",
    "directory_list = find_files(data_path, {})\n",
    "print (directory_list)\n",
    "iterate_through_files(directory_list)\n",
    "\n",
    "\n",
    "bio_im = np.asarray(bioformats.load_image(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_001.ome.tif', \n",
    "                                          c = 0, z=0, t=6, rescale=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "img=mpimg.imread(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_000.ome.tif')\n",
    "print (img.shape)\n",
    "\n",
    "im = io.imread(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_000.ome.tif')\n",
    "print ((im.shape))\n",
    "\n",
    "pilim = Image.open(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_000.ome.tif')\n",
    "print (pilim.n_frames)\n",
    "print (pilim)\n",
    "print (pilim.info)\n",
    "print (pilim.load())\n",
    "pilim.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
