{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from skimage import io\n",
    "from skimage.morphology import extrema\n",
    "from skimage.measure import label\n",
    "\n",
    "import skimage\n",
    "\n",
    "import scipy\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "\n",
    "\n",
    "import imageio\n",
    "\n",
    "import javabridge \n",
    "import bioformats\n",
    "javabridge.start_vm(class_path=bioformats.JARS, max_heap_size='8G')\n",
    "\n",
    "#import net.imageJ.ImageJ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#For the YOLO Network\n",
    "import logging\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "import brambox.boxes as bbb\n",
    "import lightnet as ln\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# See your current version of python/anaconda\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagingParameters():\n",
    "    def __init__(self, data_path, **kwargs):\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "            #print (key, value, getattr(self, key))\n",
    "            \n",
    "            \n",
    "        \n",
    "        #Assert that the core variables are all set correctly.\n",
    "        core_variables = ['channel_array', 'channel_thresholds', 'suffix', 'machine_learning_mode']\n",
    "        print (core_variables)\n",
    "        self.assert_variables(core_variables, \"Core\")\n",
    "\n",
    "        \n",
    "      \n",
    "        \n",
    "        #Store the dataframes from each of the experiments\n",
    "        self.directory_list = self.find_files(self.data_path, {})\n",
    "        self.dataframes = []\n",
    "        #print(self.directory_list)\n",
    "        \n",
    "        \n",
    "        #List containing all of the final dataframes for convenience\n",
    "        self.experiments = []\n",
    "        \n",
    "        \n",
    "        \n",
    "                 \n",
    "        machine_learning_args = [\"\"]\n",
    "        if (self.machine_learning_mode == True):\n",
    "            \n",
    "            network_variables = ['classes', 'network_size', 'labels', 'conf_thresh', 'nms_thresh', 'use_cuda']\n",
    "            self.assert_variables(network_variables, \"Network\")              \n",
    "                 \n",
    "            self.initializeROINetwork()\n",
    "            \n",
    "            \n",
    "        \n",
    "        subframes = 0\n",
    "        for items in self.channel_array:\n",
    "            subframes += items\n",
    "            \n",
    "        self.frames_per_timepoint = subframes\n",
    "        \n",
    "        \n",
    "        \n",
    "        #If you are using the anisotropy analysis, create the relevant correction factors:\n",
    "\n",
    "        \n",
    "        if \"Anisotropy\" in self.image_type_array:\n",
    "            \n",
    "            \n",
    "            #Assert that the correct variables are defined\n",
    "            ani_variables = ['numerical_aperture', 'index_of_refraction', 'magnification', 'gFactor']\n",
    "            self.assert_variables(ani_variables, \"Anisotropy\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            asin = math.asin(self.numerical_aperture/self.index_of_refraction) \n",
    "            cos = math.cos(asin)\n",
    "\n",
    "            kA = (2.0 - 3.0 * cos + cos * cos * cos) / (6.0 * (1.0 - cos))\n",
    "            kB = (1.0 - 3.0 * cos + 3.0 * cos * cos - cos * cos * cos) / (24.0 * (1.0 - cos))\n",
    "            kC = (5.0 - 3.0 * cos - cos * cos - cos * cos * cos) / (8.0 * (1.0 - cos))\n",
    "\n",
    "\n",
    "            self.kA = kA\n",
    "            self.kB = kB\n",
    "            self.kC = kC\n",
    "\n",
    "            print (kA, kB, kC)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    def assert_variables(self, variables, identifier = \"\"):\n",
    "            for attribute in variables:\n",
    "                assert hasattr(self, attribute), f\"Error: {identifier} attribute {attribute} was not set.  Check your config file\"\n",
    "\n",
    "\n",
    "    def find_files(self, path, directory_list = {}):\n",
    "        all_files = os.listdir(path)\n",
    "        #print (all_files)\n",
    "        for files in all_files:\n",
    "            #print (path, os.path.dirname(path))\n",
    "\n",
    "            #When you find the appropriate file, add the directory to the dictionary for processing\n",
    "            if os.path.isfile(f'{path}{os.sep}{files}'):\n",
    "                #print (\"Found a file\")\n",
    "                if files.endswith(self.suffix):\n",
    "                    #print (f\"Ends with ome.tif ({files})\")\n",
    "                    prev_directory = os.path.dirname(path)\n",
    "                    current_directory = path.replace(prev_directory, \"\")\n",
    "                    if prev_directory in directory_list:\n",
    "                        directory_list[prev_directory][current_directory] = None\n",
    "\n",
    "                    else:\n",
    "                        directory_list[prev_directory] = {current_directory : None}\n",
    "\n",
    "\n",
    "\n",
    "            elif os.path.isdir(f'{path}{os.sep}{files}'):\n",
    "                directory_list = self.find_files(f'{path}{os.sep}{files}', directory_list)\n",
    "                #print (\"Found a directory\")\n",
    "\n",
    "\n",
    "        return (directory_list)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def iterate_through_files(self):\n",
    "        \"\"\"\n",
    "        The purpose of this function is to iterate through all of the files in the directory list and then\n",
    "        send them to the relevant analysis program\n",
    "        \"\"\" \n",
    "        \n",
    "        dataframes = self.dataframes\n",
    "        suffix = self.suffix\n",
    "        directory_list = self.directory_list\n",
    "        debug_mode = self.debug_mode\n",
    "        machine_learning_mode = self.machine_learning_mode\n",
    "\n",
    "\n",
    "        if debug_mode == True:\n",
    "            #Start a new dataframe each time\n",
    "            dataframes = []\n",
    "\n",
    "\n",
    "\n",
    "        #knowing the previous directory we looked at helps to determine whether we should append the\n",
    "            #results to a current dataframe or not.  You want to append if the data are from the same cells\n",
    "        prev_directory = \"\"\n",
    "        new_dataframe = True\n",
    "\n",
    "\n",
    "        for root_dir in directory_list:\n",
    "            #note: there will usually only be one subdirectory per root_dir\n",
    "            for directories in directory_list[root_dir]:\n",
    "                print (os.path.dirname(os.path.dirname(directories)))\n",
    "                if os.path.dirname(os.path.dirname(prev_directory)) == os.path.dirname(os.path.dirname(directories)):\n",
    "                    print (\"From the same core directory\")\n",
    "                    new_dataframe = False\n",
    "                else:\n",
    "                    print (\"Not from the same core directory\")\n",
    "                    #if they do not share the same root directory, you need to create a new dataframe\n",
    "                    new_dataframe = True\n",
    "                    dataframes.append({})\n",
    "\n",
    "\n",
    "                file_list = os.listdir(f'{root_dir}{directories}')\n",
    "\n",
    "\n",
    "                for files in file_list:\n",
    "                    if files.endswith(suffix):\n",
    "\n",
    "                        #store all the relevant information about the image in a new class                    \n",
    "                        current_Image = ImageClass(f'{root_dir}{directories}',\n",
    "                                                  files, Parameters.channel_array,\n",
    "                                                  Parameters.image_type_array, Parameters.channel_thresholds)\n",
    "\n",
    "                        #Analyze the image\n",
    "                        \n",
    "                        dataframes = image_Analysis(current_Image=current_Image, \n",
    "                                                    Parameters = Parameters, \n",
    "                                                    dataframes = dataframes)\n",
    "\n",
    "\n",
    "\n",
    "                prev_directory = directories\n",
    "\n",
    "\n",
    "        #consolidate the dataframes\n",
    "        dataframes = self.consolidate_dataframes()\n",
    "\n",
    "        self.dataframes = dataframes\n",
    "        return (dataframes)\n",
    "\n",
    "            \n",
    "            \n",
    "    def consolidate_dataframes(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Combine the dataframes from each image into one consolidated dataframe\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        dataframes = self.dataframes\n",
    "       \n",
    "        for index, _  in enumerate(dataframes):   \n",
    "            final_dataframe = pd.DataFrame([])\n",
    "            for filenames in dataframes[index]:\n",
    "                #print (f\"current filename is: {filenames}\")\n",
    "                df_interest = dataframes[index][filenames]\n",
    "                #print (type(df_interest))\n",
    "                #print (df_interest)\n",
    "                if len(final_dataframe)==0:\n",
    "                    #print (\"need a new dataframe\")\n",
    "                    final_dataframe = df_interest\n",
    "                else:\n",
    "                    #print (\"Appending\")\n",
    "                    final_dataframe = final_dataframe.append(df_interest, ignore_index = True, sort = False)\n",
    "\n",
    "\n",
    "            dataframes[index] = {\"Total\": final_dataframe}\n",
    "            self.experiments = self.experiments.append(final_dataframe)\n",
    "            #print (final_dataframe)\n",
    "\n",
    "\n",
    "        self.dataframes = dataframes\n",
    "        \n",
    "\n",
    "        return (dataframes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def initializeROINetwork(self):\n",
    "        #These will eventually be in a configuration file\n",
    "        self.log = logging.getLogger('lightnet.detect')\n",
    "        \n",
    "        \n",
    "        #self.classes = 20\n",
    "        #NETWORK_SIZE = (416, 416)\n",
    "        #self.network_size = [1482, 2535]  #Easier if a multiple of 13 or 26\n",
    "        #self.labels = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "        #          'bus', 'car', 'cat', 'chair', 'cow',\n",
    "        #          'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "        #          'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "        #self.conf_thresh = .20\n",
    "        #self.nms_thresh = .4\n",
    "        #self.use_cuda = True\n",
    "        \n",
    "\n",
    "        #Use the GPU if available and wanted\n",
    "        self.device = torch.device('cpu')\n",
    "        if self.use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                self.log.debug('CUDA enabled')\n",
    "                self.device = torch.device('cuda')\n",
    "            else:\n",
    "                self.log.error('CUDA not available')\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.network = ln.models.Yolo(self.classes,\n",
    "                                      conf_thresh = self.conf_thresh,\n",
    "                                      nms_thresh = self.nms_thresh,)\n",
    "    \n",
    "        self.network.postprocess.append(ln.data.transform.TensorToBrambox(self.network_size, self.labels))\n",
    "        self.network.load(self.weights_path)\n",
    "    \n",
    "        self.network = self.network.to(self.device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def create_pd_dataframe():\n",
    "    \n",
    "    dataframe = pd.DataFrame(columns=[(-1, -1,  \"Image\"), (-1,-1,\"Index\"), (-1, -1, \"ROI\")])\n",
    "    #dataframe = pd.DataFrame(columns=[\"Image\", \"Index\", \"ROI\"])\n",
    "        \n",
    "    \n",
    "    return (dataframe)\n",
    "\n",
    "#Should be a subclass of the imageing parameters\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClass():\n",
    "    def __init__(self, directory, filename, channel_array, image_type_array, channel_thresholds):\n",
    "        self.directory = directory \n",
    "        self.filename = filename\n",
    "        self.file_path = (f'{directory}{os.sep}{filename}')\n",
    "\n",
    "        \n",
    "        \n",
    "        self.dir_name = directory.replace(os.path.dirname(directory), \"\")\n",
    "        self.upper_dir_name = os.path.dirname(directory).replace (os.path.dirname(os.path.dirname(directory)), \"\")[1:]\n",
    "        \n",
    "        self.ROI_list = []\n",
    "        \n",
    "        \n",
    "        image = Image.open(self.file_path)\n",
    "        self.total_frames = image.n_frames\n",
    "        self.width = image.width\n",
    "        self.length = image.height\n",
    "        \n",
    "        self.channel_array = channel_array\n",
    "        self.image_type_array = image_type_array\n",
    "        \n",
    "        self.channel_thresholds = channel_thresholds\n",
    "        \n",
    "        assert (len(channel_array) == len(image_type_array)), \"Anisotropy and Channel arrays are not of equal length\"\n",
    "              \n",
    "        self.channel_offset = np.zeros(len(channel_array))\n",
    "        \n",
    "        images_per_timepoint = 0\n",
    "        for index, items in enumerate(channel_array):\n",
    "            #print (index, items, images_per_timepoint)\n",
    "            self.channel_offset[index] = images_per_timepoint\n",
    "            images_per_timepoint += items\n",
    "        \n",
    "        self.images_per_timepoint = images_per_timepoint\n",
    "        self.timepoints = self.total_frames // images_per_timepoint\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROIs():\n",
    "    def __init__(self, x, y, data, classification=None, confidence=None):\n",
    "        \"\"\"\n",
    "            ______x_______\n",
    "            |            |\n",
    "           y|            |\n",
    "            |            |\n",
    "            |____________|\n",
    "        \n",
    "        \n",
    "        Note: this standard was adopted as it conforms to both bramboxes and CV2 drawing formats.\n",
    "        For numpy arrays, axis 0 is Y and axis 1 is X.  Therefore indexing should be\n",
    "        np.array[y1:y1, x1:x2] when dealing with the images as numpy arrays\n",
    "        \n",
    "        \"\"\"       \n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.data = data\n",
    "        self.classification = classification\n",
    "        self.confidence = confidence\n",
    "        \n",
    "        y_length, x_length = data.shape\n",
    "        \n",
    "        self.x_length = x_length\n",
    "        self.y_length = y_length\n",
    "        \n",
    "    \n",
    "#Should make this a subfunction of the ROI class\n",
    "\n",
    "\n",
    "\n",
    "def calc_overlap(ROI1, ROI2, threshold = 0.8):\n",
    "    \"\"\"\n",
    "    Calculate the IoU for two ROIs\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    x1, y1, x1Len, y1Len = ROI1.x, ROI1.y,  ROI1.x_length, ROI1.y_length\n",
    "    x2, y2, x2Len, y2Len = ROI2.x, ROI2.y,  ROI2.x_length, ROI2.y_length\n",
    "    \n",
    "    \n",
    "    box1_Area = (x1Len * y1Len)\n",
    "    box2_Area = (x2Len * y2Len)\n",
    "    #print (\"b1 Area\", box1_Area, \"b2 Area\", box2_Area)\n",
    "    \n",
    "    \n",
    "    inter_Area = max(0, (min(x1+x1Len, x2+x2Len)-max(x1, x2)))*max(0, (min(y1+y1Len, y2+y2Len) - max(y1, y2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (box1_Area or box2_Area):\n",
    "        IoU = inter_Area / (box1_Area + box2_Area - inter_Area + 0.001)\n",
    "    else:\n",
    "        IoU = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (IoU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anisotropy(image, Parameters):\n",
    "    \"\"\"\n",
    "    Parameters contains:\n",
    "        NA - Numerical Aperture\n",
    "        index_of_refraction - Index of Refraction for the immersion media\n",
    "        mag - Magnification\n",
    "        gFactor - G-Factor for the detector\n",
    "        \n",
    "        kA - Correctional Factors for high NA\n",
    "        kB - Correctional Factors for high NA\n",
    "        kC - Correctional Factors for high NA\n",
    "        \n",
    "        \n",
    "    image.shape[-1] should be equal to 3 with channels: Open, Parallel, Perpendicular\n",
    "    \"\"\"\n",
    "    \n",
    "    #image.shape[-1] should be equal to 3 with channels: Open, Parallel, Perpendicular \n",
    "    assert image.shape[2] == 3, f\"Anisotropy image was expecting 3 channels, but got: {image.shape[2]}\"\n",
    "    \n",
    "    \n",
    "    Ka = Parameters.kA\n",
    "    Kb = Parameters.kB\n",
    "    Kc = Parameters.kC\n",
    "    \n",
    "    \n",
    "    G = Parameters.gFactor\n",
    "    \n",
    "    \n",
    "    anisotropy_image = np.zeros((image.shape))\n",
    "\n",
    "    Para = image[:,:,1]\n",
    "    Perp = image[:,:,2]\n",
    "\n",
    "    Ix = ((Kb * Para - Kc * Perp*G)/(Ka*Kb + Kb**2 -Ka*Kc - Kc**2))\n",
    "    Iy = ((((Ka + Kb) * Perp*G) - (Ka+Kc)*Para)/(Ka*Kb+Kb**2-Ka*Kc-Kc**2))\n",
    "    \n",
    "    anisotropy_image[:,:,0] = Iy\n",
    "    anisotropy_image[:,:,1] = Ix\n",
    "    anisotropy_image[:,:,2] = 0\n",
    "    \n",
    "    numerator = np.add(Iy, np.multiply(Ix, -2*G))\n",
    "    denominator = np.add(Iy, np.multiply(Ix, 2*G))\n",
    "       \n",
    "        \n",
    "    anisotropy_image[:,:,-1] = np.divide (numerator, denominator, where=denominator!=0)\n",
    "    #anisotropy_image[:,:,2] = np.divide((np.add(Iy, np.multiply(Ix, -2*G))),(np.add(Iy, np.multiply(Ix, 2*G)))) \n",
    "    \n",
    "    return (anisotropy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_Analysis(current_Image, Parameters, dataframes = []):\n",
    "    \"\"\"\n",
    "    Analyze the current file.  Whether you are using machine learning or an algorithm, much of the process is the same\n",
    "    \n",
    "    current_Image:\n",
    "        directory\n",
    "        filename\n",
    "        file_path\n",
    "        timepoints\n",
    "        total_frames\n",
    "        width\n",
    "        length\n",
    "        channel_array\n",
    "        channel_offset\n",
    "        image_type_array\n",
    "        images_per_timepoint\n",
    "        \n",
    "        dir_name\n",
    "        upper_dir_name\n",
    "        \n",
    "    \n",
    "    prev_images is a dictionary of all of the most current values from the previous images\n",
    "        If a cell is found in the first image but not the second, it will still show up in the prev_images for the third image \n",
    "    \n",
    "    \n",
    "    dataframes is a list of all the dataframes associated with the analysis.\n",
    "        different groups of data should have different dataframes (aka, data for a different graph)\n",
    "        \n",
    "        Dataframes is a list of dictionaries, each containing a dataframe for each image that it is analyzing.\n",
    "        Once the analysis is complete, the dictionary will be replaced with a single entry dictionary\n",
    "        {\"Total\": pd.DataFrame}\n",
    "    \n",
    "       \n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    #g_factor = Parameters.g_factor    \n",
    "\n",
    "        \n",
    "    #Import the relevant parameters from the ImagingParameters Class   \n",
    "    root_dir = Parameters.data_path\n",
    "    suffix = Parameters.suffix\n",
    "    debug_mode = Parameters.debug_mode\n",
    "    machine_learning_mode = Parameters.machine_learning_mode\n",
    "    \n",
    "    #Import the relevant parameters from the ImageClass Class    \n",
    "    directory = current_Image.directory\n",
    "    total_frames = current_Image.total_frames\n",
    "    timepoints = current_Image.timepoints\n",
    "    filepath = current_Image.file_path\n",
    "    filename = current_Image.filename\n",
    "    channel_offset = current_Image.channel_offset\n",
    "    image_type_array = current_Image.image_type_array\n",
    "    images_per_timepoint = current_Image.images_per_timepoint\n",
    "    upper_dir_name = current_Image.upper_dir_name\n",
    "    channel_thresholds = current_Image.channel_thresholds\n",
    "    \n",
    "    \n",
    "    #strings for the panda dataframe\n",
    "    pre_string = \"\"\n",
    "\n",
    "    \n",
    "    general_strings = ['Image', 'ROI']\n",
    "    anisotropy_strings = ['Para', 'Perp', 'AniPixel', 'AniAvg']\n",
    "    intensity_strings = ['Intensity']\n",
    "    \n",
    "    \n",
    "    para_intensity_str = f'Para'\n",
    "    perp_intensity_str = f'Perp'\n",
    "    anipix_intensity_str = f'AniPixel'\n",
    "    aniavg_intensity_str = f'AniAvg'\n",
    "\n",
    "    intensity_string = \"Intensity\"\n",
    "    \n",
    "    image_string = \"Image\"\n",
    "    image_ROI_string = \"ROI\"\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    if filename not in dataframes[-1]:\n",
    "        new_dataframe = create_pd_dataframe()\n",
    "        dataframes[-1].update({filename: new_dataframe})\n",
    "    \n",
    "    \n",
    "    current_dataframe = dataframes[-1][filename]\n",
    "    \n",
    "    \n",
    "    all_columns = current_dataframe.columns\n",
    "    \n",
    "    master_column_offset = 0\n",
    "    if len(all_columns)>3:\n",
    "        master_column_offset = max(all_columns[3:], key = lambda x: x[0])[0] + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(f'root_dir: {Parameters.data_path}')\n",
    "    #print (f'directory: {current_Image.directory}')\n",
    "    #print (f'filepath: {current_Image.file_path}')\n",
    "    #print (f'filename: {current_Image.filename}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ROI_match_threshold = 0.4\n",
    "    \n",
    "    \n",
    "    print (f'current image is :{current_Image.filename} in {upper_dir_name} and it has {timepoints} timepoints and length df: {len(dataframes)}')\n",
    "    for time in range(timepoints):\n",
    "        \n",
    "        #for string in general_strings:\n",
    "        #    current_dataframe[(t, channel, string)] = np.nan\n",
    "        \n",
    "        for channel, (image_type, offset) in enumerate(zip(image_type_array, channel_offset)):\n",
    "            #print (f\"Current time is: {t}, anisotropy value is {anisotropy} and offset is {offset}\")\n",
    "            total_offset = time * images_per_timepoint + offset\n",
    "            t = time + master_column_offset\n",
    "            \n",
    "            if image_type == \"Anisotropy\" or image_type == \"Intensity\":\n",
    "            \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Open the image\n",
    "                \n",
    "                Images = {}\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                if image_type == \"Anisotropy\":\n",
    "                    Images['Open'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 0, rescale=False))\n",
    "                    Images['Para'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 1, rescale=False))\n",
    "                    Images['Perp'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 2, rescale=False))\n",
    "\n",
    "                    raw_image = np.dstack((Images['Open'], Images['Para'], Images['Perp']))\n",
    "                    \n",
    "                    anisotropy_image = calculate_anisotropy(raw_image, Parameters)\n",
    "                    \n",
    "                    Images['AniPixel'] = anisotropy_image[:,:,2].copy()\n",
    "                                       \n",
    "                    image_for_ROIs = Images['Open']\n",
    "                    \n",
    "                    for string in anisotropy_strings:\n",
    "                            current_dataframe[(t, channel, string)] = np.nan\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                elif image_type == \"Intensity\":\n",
    "                    Images['Intensity'] = np.asarray(bioformats.load_image(filepath, c = 0, z=0, t=total_offset + 0, rescale=False))\n",
    "                    image_for_ROIs = Images['Intensity']\n",
    "                    \n",
    "                    for string in intensity_strings:\n",
    "                        current_dataframe[(t, channel, string)] = np.nan\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                #Preprocessing of the image\n",
    "                \n",
    "                \n",
    "                thresholded_image = image_for_ROIs.copy()\n",
    "                #if we change to floats, this should be np.nan, which doesn't exist for ints!\n",
    "                thresholded_image[thresholded_image < channel_thresholds[channel]] = 0\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Find ROIs and iterate through them\n",
    "                \n",
    "                if machine_learning_mode == True:\n",
    "                    if image_type == \"Anisotropy\":\n",
    "                        ROI_list = detect_ROIs(Parameters, raw_image)\n",
    "                    elif image_type == \"Intensity\":\n",
    "                        ROI_list = detect_ROIs(Parameters, np.dstack([image_for_ROIs, \n",
    "                                                                      image_for_ROIs*0.5, \n",
    "                                                                      image_for_ROIs*0.4]))\n",
    "                \n",
    "                else:\n",
    "                    ROI_list = find_ROIs(image_for_ROIs) #for readability.  Can insert into the for loop  \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #Debug Mode: Output an image with all the ROIs\n",
    "                if debug_mode == True:\n",
    "                    debug_path = directory.replace(root_dir, f'{root_dir}{os.sep}debug')\n",
    "                    if not os.path.isdir(debug_path):\n",
    "                        os.makedirs(debug_path)\n",
    "                        \n",
    "                    debug_image = image_for_ROIs.copy()\n",
    "                    debug_image = np.dstack([debug_image, debug_image*0.9, debug_image*0.8])\n",
    "                    debug_image = ((debug_image/np.amax(debug_image))*255).astype('uint8')\n",
    "                    \n",
    "                \n",
    "                #Output the ROIs as seperate images\n",
    "                segmentation_outputs = False\n",
    "                if segmentation_outputs == True:\n",
    "                    segmentation_path = directory.replace(root_dir, f'{root_dir}{os.sep}segmentation')\n",
    "                    if not os.path.isdir(segmentation_path):\n",
    "                        os.makedirs(segmentation_path)\n",
    "\n",
    "              \n",
    "                \n",
    "                \n",
    "\n",
    "                for ROI in ROI_list:\n",
    "                    match_index = 0\n",
    "                    match_IoU = 0\n",
    "                    for index, compROI in enumerate(current_dataframe[(-1, -1, \"ROI\")]):\n",
    "                        #print (\"Index is \", index)\n",
    "                        #print (current_dataframe[\"ROI\"])\n",
    "                        current_dataframe.head(5)\n",
    "                        IoU = calc_overlap(ROI, compROI)\n",
    "                        if (IoU > max(ROI_match_threshold, match_IoU)):\n",
    "                            match_index = index\n",
    "                            match_IoU = IoU\n",
    "                    \n",
    "                    if match_IoU:\n",
    "                        row_index = match_index #modify the current value\n",
    "                        #change the ROI in the comparison row??\n",
    "                        \n",
    "                    else:\n",
    "                        #append a new column\n",
    "                        row_index = len(current_dataframe.index)\n",
    "                        new_row = pd.DataFrame({(-1, -1, \"ROI\"): [ROI],\n",
    "                                                (-1, -1, \"Image\"): filename,\n",
    "                                                (-1, -1, \"Index\"): row_index})\n",
    "                        current_dataframe = current_dataframe.append(new_row, ignore_index = True, sort=False)\n",
    "\n",
    "\n",
    "                    #Use the ROI to append useful information to the dataframe    \n",
    "                    x_corner = ROI.x\n",
    "                    y_corner = ROI.y\n",
    "                    x_len = ROI.x_length\n",
    "                    y_len = ROI.y_length\n",
    "                    \n",
    "                    ROI_data = {}\n",
    "                    \n",
    "                    data_inputs = {}\n",
    "                    #data_inputs[image_string] = current_Image\n",
    "                    #data_inputs[image_ROI_string] = ROI\n",
    "                    \n",
    "                    \n",
    "                    if debug_mode == True:\n",
    "                        #print (\"coordinates\", x_corner, y_corner, x_len, y_len)\n",
    "                        #print(\"stats:\", (x_corner),(y_corner), (x_corner+x_len), (y_corner+y_len))\n",
    "                              \n",
    "                        \n",
    "                        debug_image = cv2.rectangle(debug_image,\n",
    "                                                    (x_corner,y_corner), \n",
    "                                                    (x_corner+x_len, y_corner+y_len), \n",
    "                                                    (255,0,0), 20)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if image_type == \"Anisotropy\":\n",
    "                        \n",
    "                        image_types = ['Para', 'Perp', 'AniPixel']\n",
    "                        subRegion = {}\n",
    "                        subRegionAvg = {}\n",
    "                        \n",
    "                        #subRegion['Thresh'] = thresholded_image[y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                        #subRegion[types] = np.multiply(subRegion[types], ROI.data)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        for types in image_types:\n",
    "                            subRegion[types] = Images[types][y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                            subRegion[types] = np.multiply(subRegion[types], ROI.data)\n",
    "                            data_inputs[types] = np.mean(subRegion[types][subRegion['Para']!=0])\n",
    "\n",
    "                            \n",
    "                                \n",
    "                        para_value = data_inputs['Para']\n",
    "                        perp_value = data_inputs['Perp']\n",
    "                        data_inputs['AniAvg'] = (para_value - perp_value)/(para_value + 2*perp_value)\n",
    "                        \n",
    "                        #print (para_value, perp_value, data_inputs['AniAvg'])\n",
    "                        \n",
    "                        for types in data_inputs:\n",
    "                            current_dataframe.at[row_index, (t, channel, types)] = data_inputs[types]\n",
    "\n",
    "\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    elif image_type == \"Intensity\":\n",
    "                        int_extract = Images['Intensity'][y_corner:y_corner+y_len, x_corner: x_corner+x_len].copy()\n",
    "                        int_extract = np.multiply(int_extract, ROI.data)\n",
    "                        int_value = np.mean(int_extract[int_extract!=0])\n",
    "                        \n",
    "                        current_dataframe.at[row_index, (t, channel, intensity_string)] = int_value\n",
    "                        \n",
    "                if debug_mode == True:\n",
    "                    debug_save_path = f'{debug_path}{os.sep}{filename}'.replace(suffix, f'{channel}.jpg')\n",
    "                    imageio.imwrite(debug_save_path, debug_image)\n",
    "                        \n",
    "                        \n",
    "                \n",
    "    \n",
    "    #print (current_dataframe)\n",
    "    dataframes[-1][filename] = current_dataframe            \n",
    "    #print (dataframes[-1][filename].head(5))        \n",
    "    return (dataframes)\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#image_Analysis(Parameters = Parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_maxima (data, neighborhood_size = 4, threshold = 700):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    \n",
    "    image = a 2D numpy matrix containing your data\n",
    "    neighborhood_size = the area used to find the maximum filter (should be larger than your largest object)\n",
    "    threshold = the minimum difference between your maximum and the lower value \n",
    "        in the neighbourhood (the background if the neighborhood size is large enough)\n",
    "    \n",
    "    \n",
    "    \n",
    "    output:\n",
    "    The x and y coordinates of the maxima in the image (empty list if there are none...)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    #find the maxima value within a specific neighborhood size    \n",
    "    data_max = filters.maximum_filter(data, neighborhood_size)\n",
    "    \n",
    "    #set the maxima as \"true\" for the pooint where this maxima is true\n",
    "    maxima = (data == data_max)\n",
    "    \n",
    "    #find the minima for comparison\n",
    "    data_min = filters.minimum_filter(data, neighborhood_size)\n",
    "    diff = ((data_max - data_min) > threshold)\n",
    "    \n",
    "    #Remove all points that are below the minimum threshold\n",
    "    maxima[diff == 0] = 0\n",
    "\n",
    "\n",
    "    \n",
    "    #May not be necessary...\n",
    "    labeled, num_objects = ndimage.label(maxima)\n",
    "    slices = ndimage.find_objects(labeled)\n",
    "    \n",
    "    \n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    #print (slices)\n",
    "    x, y = [], []\n",
    "    for dy,dx in slices:\n",
    "        x_center = (dx.start + dx.stop - 1)//2\n",
    "        x.append(int(x_center))\n",
    "        y_center = (dy.start + dy.stop - 1)//2    \n",
    "        y.append(int(y_center))\n",
    "\n",
    "    #plt.imshow(data)\n",
    "    #plt.savefig('/tmp/data.png', bbox_inches = 'tight')\n",
    "\n",
    "    #plt.autoscale(False)\n",
    "    #plt.plot(x,y, 'ro')\n",
    "    #plt.savefig('/tmp/result.png', bbox_inches = 'tight')\n",
    "\n",
    "    #print (x, y)\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ROIs (image, avg_radius = 4, thresh_tolerance = 0.5):\n",
    "    test = 25\n",
    "\n",
    "    seed = np.zeros(image.shape)\n",
    "    x, y = find_local_maxima (image, 40, 800)\n",
    "\n",
    "    overall_image = np.zeros(image.shape)\n",
    "\n",
    "\n",
    "    ROI_List = []\n",
    "\n",
    "    for (x_val, y_val) in (zip(x,y)):\n",
    "        #Doesn't take care of the fact that y_val or x_val might be close to the edge (less than the tolerance)\n",
    "\n",
    "\n",
    "        average_value = np.mean(image[y_val- avg_radius: y_val + avg_radius,\n",
    "                                      x_val- avg_radius: x_val + avg_radius])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if average_value:\n",
    "            seed = np.zeros(image.shape)\n",
    "            seed[y_val, x_val] = 1\n",
    "            _ , mask = cv2.threshold(image,\n",
    "                                     average_value * (1-thresh_tolerance),\n",
    "                                     average_value*(1+thresh_tolerance),\n",
    "                                     cv2.THRESH_BINARY )\n",
    "\n",
    "            \n",
    "            roi_image = ndimage.binary_propagation(seed, mask = mask)\n",
    "\n",
    "\n",
    "            i, j = np.where(roi_image)\n",
    "            x_corner = min(i)\n",
    "            y_corner = min(j)\n",
    "            roi_subimage = roi_image[min(i): max(i),\n",
    "                                     min(j): max(j)]\n",
    "\n",
    "            current_ROI = ROIs(x = min(j), y = min(i), confidence = None, classification = None, data = roi_subimage)\n",
    "\n",
    "            \n",
    "            #print (current_ROI)\n",
    "            \n",
    "            if not ROI_List:\n",
    "                #print (current_ROI)\n",
    "                ROI_List.append(current_ROI)\n",
    "            \n",
    "            else:           \n",
    "                for compROI in ROI_List:\n",
    "                    IoU_match = 0\n",
    "                    IoU = calc_overlap(current_ROI, compROI)\n",
    "                    if IoU>0.8:\n",
    "                        IoU_match = 1\n",
    "                        #print (\"Already added a similar ROI\")\n",
    "                        break\n",
    "\n",
    "                if not IoU_match:\n",
    "                    #print (current_ROI)\n",
    "                    ROI_List.append(current_ROI)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #for testing purposes\n",
    "            overall_image = np.add(overall_image, np.multiply(image, roi_image))\n",
    "\n",
    "        #print (x_val, y_val, average_value, np.sum(roi_image), np.sum(mask), roi_subimage.shape)\n",
    "        #print (x_corner, y_corner, min(j), max(j),min(i), max(i), roi_subimage.shape)\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    #print (f\"Numer of ROIS is {len(ROI_List)}\")\n",
    "    plt.imshow(overall_image)\n",
    "    \n",
    "    \n",
    "    return (ROI_List)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  create_summary_columns(df):\n",
    "    \n",
    "    dataframe = df.copy()\n",
    "    \n",
    "    #precolumns are the columns like ROI that aren't important for the export\n",
    "    precolumns = 3\n",
    "    \n",
    "    summary_dataframe = pd.DataFrame([])\n",
    "    \n",
    "    timepoints = max(dataframe[precolumns:].columns, key = lambda x: x[0])[0]\n",
    "    print (timepoints)\n",
    "    \n",
    "    \n",
    "    channels = max(dataframe[precolumns:].columns, key = lambda x:x[1])[1]\n",
    "    print (channels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    statistics = {\"Mean\": np.mean, \n",
    "                  \"Stdev\": np.std,\n",
    "                  \"Count\": len, \"StdErr\": lambda x: np.std(x)/np.sqrt(len(x))}\n",
    "    \n",
    "    \n",
    "    \n",
    "    for t in range (timepoints+1):\n",
    "        \n",
    "        series = pd.Series([t], index = [(\" \",\" \",\"Time\")])\n",
    "        \n",
    "        for func in statistics:\n",
    "            new_series = dataframe.loc[0:, pd.IndexSlice[t,:,:]].apply(statistics[func])\n",
    "            new_series.index = [(func, i[1], i[2]) for i in new_series.index]\n",
    "            series = series.append(new_series)\n",
    "        \n",
    "        \n",
    "        columns = series.index\n",
    "        \n",
    "        #print (series)\n",
    "        summary_dataframe = summary_dataframe.append(series, ignore_index = True, sort = False)\n",
    "        \n",
    "    \n",
    "    \n",
    "    summary_dataframe.columns = pd.MultiIndex.from_tuples(summary_dataframe.columns, names = ['Stat', 'Channel', 'Para'])\n",
    "    \n",
    "\n",
    "    \n",
    "    #print (df.columns)\n",
    "    #print (summary_dataframe)\n",
    "    return summary_dataframe\n",
    "\n",
    "\n",
    "#create_summary_columns(sub_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell_comparisons(df, Parameters):\n",
    "    dataframe = df.copy()\n",
    "    \n",
    "    image_type_array = Parameters.image_type_array\n",
    "    \n",
    "    #image_type_bool = [image_type_array[i] == \"Anisotropy\" for i in range(len(image_type_array))]\n",
    "    \n",
    "    relative_values = False\n",
    "    AniChannel = \"AniAvg\"\n",
    "    IntChannel = \"Intensity\"\n",
    "    \n",
    "    #print (dataframe)\n",
    "    \n",
    "    statistics = {\"Mean\": np.mean, \n",
    "                  \"Stdev\": np.std,\n",
    "                  \"Count\": len, \"StdErr\": lambda x: np.std(x)/np.sqrt(len(x))}\n",
    "    \n",
    "    \n",
    "    cell_cell_comparisons = {}\n",
    "    print ()\n",
    "    \n",
    "    for channel, image_type in enumerate(image_type_array):\n",
    "        #print (channel, image_type)\n",
    "        if image_type == \"Anisotropy\" or image_type == \"Intensity\":\n",
    "            \n",
    "            if image_type == \"Anisotropy\":\n",
    "                channel_name = AniChannel\n",
    "                \n",
    "            elif image_type == \"Intensity\":\n",
    "                channel_name = IntChannel\n",
    "                \n",
    "            \n",
    "            \n",
    "            channel_subarray = dataframe.loc[:, pd.IndexSlice[:, channel, channel_name]]\n",
    "            channel_subarray = channel_subarray.dropna(how = 'any')\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print (image_type, (0, channel, channel_name))\n",
    "            first_channel = channel_subarray.loc[:, (0, channel, channel_name)].copy()\n",
    "            \n",
    "            if relative_values == True:        \n",
    "                for columns in channel_subarray.columns:\n",
    "                    channel_subarray.at[:, columns] = channel_subarray.loc[:, columns]/first_channel\n",
    "                \n",
    "            for functions in statistics:\n",
    "                channel_subarray[functions] = channel_subarray.apply(statistics[functions], axis = 1)\n",
    "\n",
    "            \n",
    "            cell_cell_comparisons.update({f\"{image_type}_Channel_{channel}\": channel_subarray})\n",
    "                \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Need to find number of timepoints and then do a comparison for the rows where there is a value in every row\n",
    "    \n",
    "    #print (image_type_bool)\n",
    "    \n",
    "    \n",
    "    #\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (cell_cell_comparisons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_file(text_path):\n",
    "    \n",
    "    skip_characters = [\"'\", \"#\", \"\\n\"]\n",
    "    \n",
    "    \n",
    "    for char in ['/', '\\\\']:\n",
    "        text_path = text_path.replace(char, os.sep)\n",
    "\n",
    "    print (text_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    config_variables = {}\n",
    "    with open(text_path, 'r') as f:\n",
    "        for lines in f:\n",
    "            if lines[0] not in skip_characters:           \n",
    "                param_input = \"\".join(lines.split())\n",
    "                variable, value = param_input.split('=')\n",
    "                #print (variable, value, param_input)\n",
    "                config_variables.update({variable: value})\n",
    "\n",
    "\n",
    "    float_variables = ['numerical_aperture',\n",
    "                       'index_of_refraction',\n",
    "                       'magnification',\n",
    "                       'gFactor',\n",
    "                       'max_filter_region',\n",
    "                       'max_threshold', \n",
    "                       'conf_thresh', \n",
    "                       'nms_thresh']\n",
    "    \n",
    "    int_variables = ['classes']\n",
    "    \n",
    "    binary_variables = ['debug_mode', \n",
    "                        'root_dir_same_treatment', \n",
    "                        'machine_learning_mode', \n",
    "                        'use_cuda']\n",
    "    \n",
    "    array_variables = {'channel_thresholds': \"int\",\n",
    "                       'channel_array': 'int',\n",
    "                       'image_type_array': 'str', \n",
    "                       'network_size':'int', \n",
    "                       'labels': 'str'}\n",
    "    \n",
    "    path_variables = ['weights_path']\n",
    "    \n",
    "    #Don't need this for anthing\n",
    "    string_variables = ['suffix']\n",
    "    \n",
    "    \n",
    "    for variables in config_variables:\n",
    "    \n",
    "    \n",
    "        #Convert Floats\n",
    "        if variables in float_variables:\n",
    "            config_variables[variables] = float(config_variables[variables])\n",
    "            \n",
    "        elif variables in int_variables:\n",
    "            config_variables[variables] = int(config_variables[variables])\n",
    "\n",
    "        #Convert Binary Variables\n",
    "        elif variables in binary_variables:\n",
    "            config_variables[variables] = (config_variables[variables].lower() == \"true\")\n",
    "\n",
    "        #Convert to arrays with the appropriate variable type\n",
    "        elif variables in array_variables:\n",
    "            var_type = array_variables[variables]\n",
    "            for c in ['[', ']', \"'\", '\"']:\n",
    "                config_variables[variables] = config_variables[variables].replace(c,\"\")\n",
    "            config_variables[variables] = config_variables[variables].split(',')\n",
    "            if var_type.lower() == \"int\":\n",
    "                config_variables[variables] = [int(x) for x in config_variables[variables]]\n",
    "                \n",
    "        elif variables in path_variables:\n",
    "            for char in ['/', '\\\\']:\n",
    "                config_variables[variables] = config_variables[variables].replace(char, os.sep)\n",
    "                \n",
    "        elif variables in string_variables:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            print (f'unknown variables found: {variables}')\n",
    "    \n",
    "    return config_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Detect Cells using Machine Learning\"\"\"\n",
    "\n",
    "\n",
    "def post_transform(boxes, scale, pad):\n",
    "    for box in boxes:\n",
    "        box.x_top_left -= pad[0]\n",
    "        box.y_top_left -= pad[1]\n",
    "\n",
    "        box.x_top_left *= scale\n",
    "        box.y_top_left *= scale\n",
    "        box.width *= scale\n",
    "        box.height *= scale\n",
    "    return boxes\n",
    "\n",
    "def output_ROIs (detections, im_h, im_w, segmentation = None):\n",
    "    ROI_list = []\n",
    "    for det in detections:\n",
    "\n",
    "        #Note, the pixels are rounded down, but it shouldn't matter since the segmentation network will\n",
    "        #do the pixel by pixel segmentation\n",
    "        x = int(det.x_top_left)\n",
    "        y = int(det.y_top_left)\n",
    "        height = int(det.height)\n",
    "        width = int(det.width)\n",
    "        \n",
    "        \n",
    "        #Ensure that the ROIs do not go over the edge of the image.  Alternatively, don't use ROIs that go over the edge...\n",
    "        if x<0:\n",
    "            width = width+x\n",
    "            x=0\n",
    "        if y<0:\n",
    "            height = height+y\n",
    "            y=0\n",
    "        height = min((im_h - y), height)\n",
    "        width = min((im_w - x), width)\n",
    "        \n",
    "        print (\"x\", int(det.x_top_left),\n",
    "               \"y\", int(det.y_top_left), \n",
    "               det.class_label, \n",
    "               det.confidence,\n",
    "               \"w\", det.width,\n",
    "               \"h\", det.height,\n",
    "              \"new_H\", height, \"new_W\", width )\n",
    "        \n",
    "        \n",
    "        fake_data = np.ones((height,width))\n",
    "        \n",
    "        \n",
    "        roi = ROIs(x = x,\n",
    "                   y = y, \n",
    "                   classification = det.class_label, \n",
    "                   confidence = det.confidence, \n",
    "                   data = fake_data)  #Use the data as ones for now... replace with segmentation later\n",
    "        \n",
    "        \n",
    "        ROI_list.append(roi)\n",
    "        \n",
    "    return (ROI_list)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def detect_ROIs(Parameters, image):\n",
    "    \n",
    "    #Import the relevant parameters:\n",
    "    network_size = Parameters.network_size\n",
    "    network = Parameters.network\n",
    "    net_w, net_h = Parameters.network_size\n",
    "    device = Parameters.device\n",
    "    log = Parameters.log\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    save_check = False\n",
    "    show_label = True\n",
    "    use_cuda = True\n",
    "    img = image.copy()\n",
    "    \n",
    "    #Maybe this should already be set.. \n",
    "    network.training = False\n",
    "    \n",
    "    im_h, im_w = image.shape[:2]\n",
    "\n",
    "       \n",
    "    device = torch.device('cpu')\n",
    "    if use_cuda:\n",
    "        if torch.cuda.is_available():\n",
    "            log.debug('CUDA enabled')\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            log.error('CUDA not available')\n",
    "\n",
    "            \n",
    "    #print (\"Image Shape:\", img.shape)        \n",
    "    \n",
    "\n",
    "    #The control of the input should happen before this function...\n",
    "    #If only one slice, pad to 3 using the anisotropy ratios\n",
    "    #if img.shape[2] == 1:\n",
    "    #    print (\"There is only channel... extending\")\n",
    "    #    img = np.dstack([img, img*0.5, img*0.4])    \n",
    "    \n",
    "    \n",
    "    #Prep the image for the neural network\n",
    "    #print (\"Pre conversion\",img.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    img = img/np.amax(img)\n",
    "    img = img*255\n",
    "    img = img.astype('uint8')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Transform the image and prep it for the \n",
    "    img_tf = ln.data.transform.Letterbox.apply(img, dimension = network_size)\n",
    "    img_tf = tf.ToTensor()(img_tf)\n",
    "    img_tf.unsqueeze_(0)\n",
    "    img_tf = img_tf.to(device)\n",
    "\n",
    "\n",
    "    # Run the image through the neural net\n",
    "    with torch.no_grad():\n",
    "        output = network(img_tf)\n",
    "        \n",
    "    if im_w == net_w and im_h == net_h:\n",
    "        scale = 1\n",
    "    elif im_w / net_w >= im_h / net_h:\n",
    "        scale = im_w/net_w\n",
    "    else:\n",
    "        scale = im_h/net_h\n",
    "        \n",
    "    pad = int((net_w - im_w/scale) / 2), int((net_h - im_h/scale) / 2)\n",
    "\n",
    "    \n",
    "    #Convert the boxes into ROIs\n",
    "    converted_boxes = []\n",
    "    for b in output:\n",
    "        converted_boxes.append(post_transform(b, scale, pad))\n",
    "    \n",
    "    output = converted_boxes\n",
    "    \n",
    "    \n",
    "    image_markup = bbb.draw_boxes(img, output[0], color = (255,0,0), show_labels=show_label)\n",
    "    if save_check:\n",
    "        cv2.imwrite('detections.png', image)\n",
    "    elif Parameters.debug_mode == True:\n",
    "        cv2.imshow('image', image_markup)\n",
    "        cv2.waitKey(1000)\n",
    "        cv2.destroyAllWindows()\n",
    "        print (output[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Add the segmentation algorithm here when it is ready...\n",
    "    \n",
    "    \n",
    "    ROI_list = output_ROIs(output[0], im_h, im_w)\n",
    "   \n",
    "    #ROI_list = [ROIs(x=0, y=1000, data = np.ones((100,500)))]\n",
    "        \n",
    "    return ROI_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nStart Here\\n\\n'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Start Here\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\William\\Dropbox\\Python Analysis\\config.txt\n",
      "unknown variables found: same_cells\n",
      "['channel_array', 'channel_thresholds', 'suffix', 'machine_learning_mode']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO       Loaded weights from C:\\Users\\William\\Desktop\\Lightnet\\examples\\yolo-voc\\backup\\final.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23898418155398782 0.014831490153302157 0.7461843282927101\n",
      "Loaded the following variables:\n",
      "channel_array            : [3, 3, 1]\n",
      "image_type_array         : ['Anisotropy', 'Intensity', 'Brightfield']\n",
      "channel_thresholds       : [500, 500, 500]\n",
      "same_cells               : True\n",
      "max_threshold            : 800.0\n",
      "root_dir_same_treatment  : True\n",
      "suffix                   : ome.tif\n",
      "machine_learning_mode    : True\n",
      "debug_mode               : True\n",
      "numerical_aperture       : 1.4\n",
      "index_of_refraction      : 1.53\n",
      "magnification            : 63.0\n",
      "gFactor                  : 1.0\n",
      "max_filter_region        : 40.0\n",
      "weights_path             : C:\\Users\\William\\Desktop\\Lightnet\\examples\\yolo-voc\\backup\\final.pt\n",
      "classes                  : 20\n",
      "network_size             : [1482, 2535]\n",
      "labels                   : ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
      "conf_thresh              : 0.2\n",
      "nms_thresh               : 0.4\n",
      "use_cuda                 : True\n",
      "Here is the network...\n",
      "Yolo(\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (1_convbatch): Conv2dBatchReLU(3, 32, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (2_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3_convbatch): Conv2dBatchReLU(32, 64, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (4_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (6_convbatch): Conv2dBatchReLU(128, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (7_convbatch): Conv2dBatchReLU(64, 128, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (8_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (9_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (10_convbatch): Conv2dBatchReLU(256, 128, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (11_convbatch): Conv2dBatchReLU(128, 256, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (12_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (13_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (14_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (15_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (16_convbatch): Conv2dBatchReLU(512, 256, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (17_convbatch): Conv2dBatchReLU(256, 512, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (18_max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (19_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (20_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (21_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (22_convbatch): Conv2dBatchReLU(1024, 512, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (23_convbatch): Conv2dBatchReLU(512, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (24_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (25_convbatch): Conv2dBatchReLU(1024, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (26_convbatch): Conv2dBatchReLU(512, 64, kernel_size=1, stride=1, padding=0, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (27_reorg): Reorg(stride=2, darknet_compatible)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (28_convbatch): Conv2dBatchReLU(1280, 1024, kernel_size=3, stride=1, padding=1, LeakyReLU(negative_slope=0.1, inplace))\n",
      "      (29_conv): Conv2d(1024, 125, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (loss): RegionLoss(\n",
      "    classes=20, reduction=32, threshold=0.6, seen=1280000\n",
      "    coord_scale=1.0, object_scale=5.0, noobject_scale=1.0, class_scale=1.0\n",
      "    anchors=[1.3221, 1.7314] [3.1927, 4.0094] [5.0559, 8.0989] [9.4711, 4.8405] [11.236, 10.007] \n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Work\n",
    "data_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline3\"\n",
    "text_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline3{os.sep}config.txt\"\n",
    "\n",
    "#Home\n",
    "data_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Documents{os.sep}Baseline\"\n",
    "text_path = f\"C:{os.sep}Users{os.sep}William{os.sep}Dropbox{os.sep}Python Analysis{os.sep}config.txt\"\n",
    "\n",
    "config_variables = parse_text_file (text_path)\n",
    "\n",
    "Parameters = ImagingParameters(data_path = data_path, **config_variables)\n",
    "\n",
    "if Parameters.debug_mode == True:\n",
    "    print(\"Loaded the following variables:\")\n",
    "    for variables in config_variables:\n",
    "        print(f'{variables: <25}: {config_variables[variables]}')\n",
    "        \n",
    "    if (Parameters.machine_learning_mode == True):\n",
    "        print (\"Here is the network...\")\n",
    "        print (Parameters.network)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\n",
      "Not from the same core directory\n",
      "current image is :Baseline_1_MMStack_1-Pos_000_003.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "[Detection {class_label = cat, object_id = None, x = 1424.1996154373314, y = 398.4109812542173, w = 187.23547066754176, h = 146.70934959751392, confidence = 0.9631985425949097}, Detection {class_label = cat, object_id = None, x = 588.666003763917, y = 1102.834519441633, w = 228.42980808767715, h = 165.70254528956858, confidence = 0.9295817613601685}, Detection {class_label = cat, object_id = None, x = 767.3051369032557, y = 666.8211190536438, w = 146.93681255139805, h = 127.98357058794072, confidence = 0.883554995059967}, Detection {class_label = cat, object_id = None, x = 2018.5356649586708, y = 236.56511602774967, w = 206.0132806239984, h = 112.77046613397226, confidence = 0.8726407289505005}, Detection {class_label = cat, object_id = None, x = 1015.2972795947201, y = 1271.514528508772, w = 134.29010396898195, h = 130.236661553222, confidence = 0.8380724191665649}, Detection {class_label = cat, object_id = None, x = 521.1398817054657, y = 677.919457974865, w = 117.30703632390774, h = 117.72986910635966, confidence = 0.8093457818031311}, Detection {class_label = cat, object_id = None, x = 1625.533403445513, y = 949.7584846280365, w = 148.92993098167597, h = 154.0523113297065, confidence = 0.6504329442977905}, Detection {class_label = cat, object_id = None, x = 1775.047075320513, y = 1022.9805768176451, w = 131.4546386059801, h = 122.69022211854758, confidence = 0.3439410924911499}]\n",
      "x 1424 y 398 cat 0.9631985425949097 w 187.23547066754176 h 146.70934959751392 new_H 146 new_W 187\n",
      "x 588 y 1102 cat 0.9295817613601685 w 228.42980808767715 h 165.70254528956858 new_H 165 new_W 228\n",
      "x 767 y 666 cat 0.883554995059967 w 146.93681255139805 h 127.98357058794072 new_H 127 new_W 146\n",
      "x 2018 y 236 cat 0.8726407289505005 w 206.0132806239984 h 112.77046613397226 new_H 112 new_W 206\n",
      "x 1015 y 1271 cat 0.8380724191665649 w 134.29010396898195 h 130.236661553222 new_H 130 new_W 134\n",
      "x 521 y 677 cat 0.8093457818031311 w 117.30703632390774 h 117.72986910635966 new_H 117 new_W 117\n",
      "x 1625 y 949 cat 0.6504329442977905 w 148.92993098167597 h 154.0523113297065 new_H 154 new_W 148\n",
      "x 1775 y 1022 cat 0.3439410924911499 w 131.4546386059801 h 122.69022211854758 new_H 122 new_W 131\n",
      "[Detection {class_label = cat, object_id = None, x = 282.02884121172826, y = 626.9302752825574, w = 151.84758129454497, h = 117.31805938844256, confidence = 0.9418582916259766}, Detection {class_label = cat, object_id = None, x = 580.3934215797908, y = 306.37456113992914, w = 140.86539449962046, h = 88.36080071864984, confidence = 0.9260132908821106}, Detection {class_label = cat, object_id = None, x = 2378.7584819922404, y = 647.0121905575237, w = 151.55666088768345, h = 292.93795302747554, confidence = 0.5255148410797119}, Detection {class_label = cat, object_id = None, x = 586.4353623692646, y = 1102.4492978238868, w = 195.3753726356908, h = 157.27705875453358, confidence = 0.4462932050228119}, Detection {class_label = cat, object_id = None, x = 8.98816062113856, y = 768.1575178179825, w = 66.84103274120172, h = 176.67072875811826, confidence = 0.4396250247955322}, Detection {class_label = cat, object_id = None, x = 1239.5438411985494, y = 1289.710315452092, w = 118.40603715945514, h = 78.35543053095479, confidence = 0.30949822068214417}, Detection {class_label = cat, object_id = None, x = 4.51851943372554, y = 910.3594751602565, w = 75.26645420501751, h = 309.30656616375677, confidence = 0.22764869034290314}, Detection {class_label = cat, object_id = None, x = 1567.2211577998482, y = -3.874704790823212, w = 553.8826260174174, h = 164.84939653445514, confidence = 0.2170211523771286}]\n",
      "x 282 y 626 cat 0.9418582916259766 w 151.84758129454497 h 117.31805938844256 new_H 117 new_W 151\n",
      "x 580 y 306 cat 0.9260132908821106 w 140.86539449962046 h 88.36080071864984 new_H 88 new_W 140\n",
      "x 2378 y 647 cat 0.5255148410797119 w 151.55666088768345 h 292.93795302747554 new_H 292 new_W 150\n",
      "x 586 y 1102 cat 0.4462932050228119 w 195.3753726356908 h 157.27705875453358 new_H 157 new_W 195\n",
      "x 8 y 768 cat 0.4396250247955322 w 66.84103274120172 h 176.67072875811826 new_H 176 new_W 66\n",
      "x 1239 y 1289 cat 0.30949822068214417 w 118.40603715945514 h 78.35543053095479 new_H 78 new_W 118\n",
      "x 4 y 910 cat 0.22764869034290314 w 75.26645420501751 h 309.30656616375677 new_H 309 new_W 75\n",
      "x 1567 y -3 cat 0.2170211523771286 w 553.8826260174174 h 164.84939653445514 new_H 161 new_W 553\n",
      "[Detection {class_label = cat, object_id = None, x = 1424.055521729504, y = 398.5305040696694, w = 186.15603024049005, h = 149.20895636966515, confidence = 0.9454817175865173}, Detection {class_label = cat, object_id = None, x = 726.6383839142628, y = 653.8553923119097, w = 216.9232123371078, h = 159.51852800006327, confidence = 0.918810248374939}, Detection {class_label = cat, object_id = None, x = 988.7947610914306, y = 1273.9726588857964, w = 178.2682271898195, h = 139.7384260540549, confidence = 0.7566810250282288}, Detection {class_label = cat, object_id = None, x = 1613.0498284096661, y = 915.4202460779353, w = 161.99962851747006, h = 219.9188830418143, confidence = 0.6664296984672546}, Detection {class_label = cat, object_id = None, x = -18.377088374293606, y = 346.3052805541498, w = 183.37540690104169, h = 900.8150369538631, confidence = 0.5516310930252075}, Detection {class_label = cat, object_id = None, x = 518.4911707416077, y = 690.901426492915, w = 120.62107447574014, h = 119.5399161685012, confidence = 0.487222820520401}, Detection {class_label = cat, object_id = None, x = 2161.283595858637, y = -47.06367029352227, w = 468.54458515203277, h = 254.81087766742579, confidence = 0.323055237531662}, Detection {class_label = cat, object_id = None, x = 1.6829955066263917, y = 646.3412802589406, w = 124.65269200457575, h = 408.57234667573385, confidence = 0.2545628845691681}]\n",
      "x 1424 y 398 cat 0.9454817175865173 w 186.15603024049005 h 149.20895636966515 new_H 149 new_W 186\n",
      "x 726 y 653 cat 0.918810248374939 w 216.9232123371078 h 159.51852800006327 new_H 159 new_W 216\n",
      "x 988 y 1273 cat 0.7566810250282288 w 178.2682271898195 h 139.7384260540549 new_H 139 new_W 178\n",
      "x 1613 y 915 cat 0.6664296984672546 w 161.99962851747006 h 219.9188830418143 new_H 219 new_W 161\n",
      "x -18 y 346 cat 0.5516310930252075 w 183.37540690104169 h 900.8150369538631 new_H 900 new_W 165\n",
      "x 518 y 690 cat 0.487222820520401 w 120.62107447574014 h 119.5399161685012 new_H 119 new_W 120\n",
      "x 2161 y -47 cat 0.323055237531662 w 468.54458515203277 h 254.81087766742579 new_H 207 new_W 367\n",
      "x 1 y 646 cat 0.2545628845691681 w 124.65269200457575 h 408.57234667573385 new_H 408 new_W 124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detection {class_label = cat, object_id = None, x = 971.3632746605095, y = 1025.7558382886302, w = 199.51058354551495, h = 120.97196451822917, confidence = 0.9232482314109802}, Detection {class_label = cat, object_id = None, x = 1179.8139799995784, y = 1226.1556200447033, w = 191.714530913936, h = 138.32420721839154, confidence = 0.8162416815757751}, Detection {class_label = cat, object_id = None, x = 596.1157733953273, y = 1113.6371747427463, w = 172.67430174463354, h = 152.65655970605602, confidence = 0.7265763878822327}, Detection {class_label = cat, object_id = None, x = 252.4248462012905, y = 551.7756199392713, w = 197.3008039837424, h = 179.95230938580679, confidence = 0.68648362159729}, Detection {class_label = cat, object_id = None, x = 2261.063907515182, y = 602.0293416835358, w = 235.17574138358216, h = 148.31140301456014, confidence = 0.6821162700653076}, Detection {class_label = cat, object_id = None, x = 556.6730881252109, y = 231.9882667531208, w = 163.73274838425692, h = 155.53886333264805, confidence = 0.6661224365234375}, Detection {class_label = cat, object_id = None, x = 13.721646081098179, y = 771.9397694205466, w = 100.04111710315453, h = 179.4726303862496, confidence = 0.48243966698646545}, Detection {class_label = cat, object_id = None, x = 911.3614678221998, y = 416.0318509615385, w = 227.57323658643304, h = 210.52832525461793, confidence = 0.4803241193294525}, Detection {class_label = cat, object_id = None, x = 1050.6236636513158, y = 426.296028909413, w = 228.83150573812839, h = 178.4784332563681, confidence = 0.4751213490962982}, Detection {class_label = cat, object_id = None, x = 2017.7400261470987, y = 0.32993710990215924, w = 638.4772412175271, h = 257.257919908696, confidence = 0.3026469349861145}, Detection {class_label = cat, object_id = None, x = -1.0121632935064524, y = 247.7294631937416, w = 78.28332511294387, h = 326.61074726140777, confidence = 0.298695832490921}, Detection {class_label = cat, object_id = None, x = 19.97793797378437, y = 947.9081714954455, w = 135.5115948675776, h = 552.4903101541414, confidence = 0.276368647813797}, Detection {class_label = cat, object_id = None, x = 211.53044805899967, y = 59.26238956013833, w = 189.57970038245404, h = 125.26100379027497, confidence = 0.261031836271286}, Detection {class_label = cat, object_id = None, x = 1825.482788250675, y = 1283.4857587930162, w = 234.94510295420042, h = 159.02561351451797, confidence = 0.25370270013809204}, Detection {class_label = cat, object_id = None, x = 2334.871953019568, y = 401.00883255313767, w = 226.75375568014087, h = 237.2186392965587, confidence = 0.2502748966217041}, Detection {class_label = cat, object_id = None, x = 1263.644971427969, y = 1444.060913250675, w = 268.4190915991903, h = 33.07292218536501, confidence = 0.22758954763412476}]\n",
      "x 971 y 1025 cat 0.9232482314109802 w 199.51058354551495 h 120.97196451822917 new_H 120 new_W 199\n",
      "x 1179 y 1226 cat 0.8162416815757751 w 191.714530913936 h 138.32420721839154 new_H 138 new_W 191\n",
      "x 596 y 1113 cat 0.7265763878822327 w 172.67430174463354 h 152.65655970605602 new_H 152 new_W 172\n",
      "x 252 y 551 cat 0.68648362159729 w 197.3008039837424 h 179.95230938580679 new_H 179 new_W 197\n",
      "x 2261 y 602 cat 0.6821162700653076 w 235.17574138358216 h 148.31140301456014 new_H 148 new_W 235\n",
      "x 556 y 231 cat 0.6661224365234375 w 163.73274838425692 h 155.53886333264805 new_H 155 new_W 163\n",
      "x 13 y 771 cat 0.48243966698646545 w 100.04111710315453 h 179.4726303862496 new_H 179 new_W 100\n",
      "x 911 y 416 cat 0.4803241193294525 w 227.57323658643304 h 210.52832525461793 new_H 210 new_W 227\n",
      "x 1050 y 426 cat 0.4751213490962982 w 228.83150573812839 h 178.4784332563681 new_H 178 new_W 228\n",
      "x 2017 y 0 cat 0.3026469349861145 w 638.4772412175271 h 257.257919908696 new_H 257 new_W 511\n",
      "x -1 y 247 cat 0.298695832490921 w 78.28332511294387 h 326.61074726140777 new_H 326 new_W 77\n",
      "x 19 y 947 cat 0.276368647813797 w 135.5115948675776 h 552.4903101541414 new_H 533 new_W 135\n",
      "x 211 y 59 cat 0.261031836271286 w 189.57970038245404 h 125.26100379027497 new_H 125 new_W 189\n",
      "x 1825 y 1283 cat 0.25370270013809204 w 234.94510295420042 h 159.02561351451797 new_H 159 new_W 234\n",
      "x 2334 y 401 cat 0.2502748966217041 w 226.75375568014087 h 237.2186392965587 new_H 237 new_W 194\n",
      "x 1263 y 1444 cat 0.22758954763412476 w 268.4190915991903 h 33.07292218536501 new_H 33 new_W 268\n",
      "current image is :Baseline_1_MMStack_1-Pos_001_000.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "[Detection {class_label = cat, object_id = None, x = 1180.941846427969, y = 1017.8025735914306, w = 129.31957381810898, h = 118.77267443699394, confidence = 0.8863032460212708}, Detection {class_label = cat, object_id = None, x = 956.5790936551114, y = 270.69221148574564, w = 143.16104204226764, h = 139.89519563538505, confidence = 0.8364134430885315}, Detection {class_label = cat, object_id = None, x = 816.1695620888158, y = 637.8518287154184, w = 120.31559113001856, h = 129.45306091720437, confidence = 0.7859861254692078}, Detection {class_label = cat, object_id = None, x = 1638.9557739752026, y = 1403.9583017037787, w = 423.90119981443996, h = 90.76290477593096, confidence = 0.29279524087905884}, Detection {class_label = cat, object_id = None, x = 2.0020364408711835, y = 601.9699967316127, w = 81.91869795949836, h = 373.43602263621796, confidence = 0.2572571635246277}]\n",
      "x 1180 y 1017 cat 0.8863032460212708 w 129.31957381810898 h 118.77267443699394 new_H 118 new_W 129\n",
      "x 956 y 270 cat 0.8364134430885315 w 143.16104204226764 h 139.89519563538505 new_H 139 new_W 143\n",
      "x 816 y 637 cat 0.7859861254692078 w 120.31559113001856 h 129.45306091720437 new_H 129 new_W 120\n",
      "x 1638 y 1403 cat 0.29279524087905884 w 423.90119981443996 h 90.76290477593096 new_H 77 new_W 423\n",
      "x 2 y 601 cat 0.2572571635246277 w 81.91869795949836 h 373.43602263621796 new_H 373 new_W 81\n",
      "[Detection {class_label = cat, object_id = None, x = 244.05304342210695, y = 567.5992746288799, w = 180.08532797212382, h = 150.26104085615933, confidence = 0.9463828206062317}, Detection {class_label = cat, object_id = None, x = 677.1822791466346, y = 806.4341788967612, w = 182.20076728028005, h = 115.82899563643936, confidence = 0.9431463479995728}, Detection {class_label = cat, object_id = None, x = 525.2643038071441, y = 120.78904932101891, w = 132.76067003257845, h = 117.71150600829749, confidence = 0.9223216772079468}, Detection {class_label = cat, object_id = None, x = 843.2755771075828, y = 328.370819627193, w = 170.32973365938133, h = 166.55521251765984, confidence = 0.9010586738586426}, Detection {class_label = cat, object_id = None, x = 152.28954501544578, y = 1095.0828193530701, w = 176.50961241934465, h = 140.22155382823044, confidence = 0.8857040405273438}, Detection {class_label = cat, object_id = None, x = 1154.3805035425103, y = 1032.4772267206479, w = 133.4026106243674, h = 106.14875379554657, confidence = 0.8741595149040222}, Detection {class_label = cat, object_id = None, x = 1230.0342811656546, y = 1401.1241117366735, w = 229.73305446609314, h = 85.32490298622534, confidence = 0.790859580039978}, Detection {class_label = cat, object_id = None, x = 1379.2147883982796, y = 1381.4823902454455, w = 340.0438935849992, h = 123.65882023079033, confidence = 0.7824482917785645}, Detection {class_label = cat, object_id = None, x = 800.0680793216516, y = 629.4839822663631, w = 142.89778991781589, h = 115.8648108354947, confidence = 0.7625579833984375}, Detection {class_label = cat, object_id = None, x = 2019.7156924763833, y = 1246.6885569542849, w = 234.61646726868253, h = 190.1051895203378, confidence = 0.7139737010002136}, Detection {class_label = cat, object_id = None, x = 2.1472331058641196, y = 518.0518619264508, w = 218.61214884604843, h = 195.51276400793904, confidence = 0.6503405570983887}, Detection {class_label = cat, object_id = None, x = 1291.694727353239, y = 5.322513389844804, w = 111.0366174695302, h = 79.58759961662345, confidence = 0.6310102939605713}, Detection {class_label = cat, object_id = None, x = 2165.542272899798, y = -50.28453947368421, w = 471.57804922085865, h = 242.62038340291838, confidence = 0.4624941647052765}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 244 y 567 cat 0.9463828206062317 w 180.08532797212382 h 150.26104085615933 new_H 150 new_W 180\n",
      "x 677 y 806 cat 0.9431463479995728 w 182.20076728028005 h 115.82899563643936 new_H 115 new_W 182\n",
      "x 525 y 120 cat 0.9223216772079468 w 132.76067003257845 h 117.71150600829749 new_H 117 new_W 132\n",
      "x 843 y 328 cat 0.9010586738586426 w 170.32973365938133 h 166.55521251765984 new_H 166 new_W 170\n",
      "x 152 y 1095 cat 0.8857040405273438 w 176.50961241934465 h 140.22155382823044 new_H 140 new_W 176\n",
      "x 1154 y 1032 cat 0.8741595149040222 w 133.4026106243674 h 106.14875379554657 new_H 106 new_W 133\n",
      "x 1230 y 1401 cat 0.790859580039978 w 229.73305446609314 h 85.32490298622534 new_H 79 new_W 229\n",
      "x 1379 y 1381 cat 0.7824482917785645 w 340.0438935849992 h 123.65882023079033 new_H 99 new_W 340\n",
      "x 800 y 629 cat 0.7625579833984375 w 142.89778991781589 h 115.8648108354947 new_H 115 new_W 142\n",
      "x 2019 y 1246 cat 0.7139737010002136 w 234.61646726868253 h 190.1051895203378 new_H 190 new_W 234\n",
      "x 2 y 518 cat 0.6503405570983887 w 218.61214884604843 h 195.51276400793904 new_H 195 new_W 218\n",
      "x 1291 y 5 cat 0.6310102939605713 w 111.0366174695302 h 79.58759961662345 new_H 79 new_W 111\n",
      "x 2165 y -50 cat 0.4624941647052765 w 471.57804922085865 h 242.62038340291838 new_H 192 new_W 363\n",
      "[Detection {class_label = cat, object_id = None, x = 1165.7179922085863, y = 1009.196097967274, w = 136.44047350761218, h = 134.6351506159856, confidence = 0.9083572626113892}, Detection {class_label = cat, object_id = None, x = 826.8928825594636, y = 650.9466567560729, w = 115.71479564671897, h = 102.07208095452725, confidence = 0.6785563826560974}, Detection {class_label = cat, object_id = None, x = 938.7140767332996, y = 280.4330086032389, w = 179.31816432607962, h = 135.84171417689356, confidence = 0.46719416975975037}, Detection {class_label = cat, object_id = None, x = 1653.117770010965, y = 1387.4352094930837, w = 405.117455362791, h = 106.18942330755526, confidence = 0.364978164434433}, Detection {class_label = cat, object_id = None, x = 3.001654003313196, y = 594.2349548751687, w = 79.69544865534856, h = 382.41173838668186, confidence = 0.22335965931415558}]\n",
      "x 1165 y 1009 cat 0.9083572626113892 w 136.44047350761218 h 134.6351506159856 new_H 134 new_W 136\n",
      "x 826 y 650 cat 0.6785563826560974 w 115.71479564671897 h 102.07208095452725 new_H 102 new_W 115\n",
      "x 938 y 280 cat 0.46719416975975037 w 179.31816432607962 h 135.84171417689356 new_H 135 new_W 179\n",
      "x 1653 y 1387 cat 0.364978164434433 w 405.117455362791 h 106.18942330755526 new_H 93 new_W 405\n",
      "x 3 y 594 cat 0.22335965931415558 w 79.69544865534856 h 382.41173838668186 new_H 382 new_W 79\n",
      "[Detection {class_label = cat, object_id = None, x = 233.1966913508983, y = 557.6137056131917, w = 196.64872529599992, h = 172.61737744206522, confidence = 0.9501796364784241}, Detection {class_label = cat, object_id = None, x = 175.03341975450195, y = 1096.2967880187248, w = 156.9667991813217, h = 119.69809128816634, confidence = 0.9113819003105164}, Detection {class_label = cat, object_id = None, x = 13.933862848320471, y = 517.1789705634278, w = 176.5577260788314, h = 168.44996929297403, confidence = 0.9037507176399231}, Detection {class_label = cat, object_id = None, x = 539.3751798930922, y = 123.9252738592274, w = 113.71571669276106, h = 111.18352225402751, confidence = 0.8639844059944153}, Detection {class_label = cat, object_id = None, x = 1169.0297528677463, y = 1020.3492008265857, w = 101.27014975605707, h = 124.7555305594214, confidence = 0.8555775284767151}, Detection {class_label = cat, object_id = None, x = 679.2354062552716, y = 778.9158205760797, w = 218.33875862564315, h = 148.62371883829917, confidence = 0.8298282027244568}, Detection {class_label = cat, object_id = None, x = 798.9378182723938, y = 625.0466456857288, w = 150.94117825362687, h = 138.2844096607203, confidence = 0.8282315135002136}, Detection {class_label = cat, object_id = None, x = 1284.8589176893556, y = 5.320535224780702, w = 122.03702420583461, h = 77.46999343686741, confidence = 0.6586335897445679}, Detection {class_label = cat, object_id = None, x = 88.96280710320724, y = 912.0677768640352, w = 142.42593247880822, h = 108.25609824403256, confidence = 0.5724930167198181}, Detection {class_label = cat, object_id = None, x = 840.4383157789306, y = 311.80077202471324, w = 160.95199490237013, h = 196.5986725141806, confidence = 0.28478848934173584}, Detection {class_label = cat, object_id = None, x = 1.4621698171021003, y = 191.58289183746626, w = 77.31296357066043, h = 334.6415247949351, confidence = 0.27413323521614075}]\n",
      "x 233 y 557 cat 0.9501796364784241 w 196.64872529599992 h 172.61737744206522 new_H 172 new_W 196\n",
      "x 175 y 1096 cat 0.9113819003105164 w 156.9667991813217 h 119.69809128816634 new_H 119 new_W 156\n",
      "x 13 y 517 cat 0.9037507176399231 w 176.5577260788314 h 168.44996929297403 new_H 168 new_W 176\n",
      "x 539 y 123 cat 0.8639844059944153 w 113.71571669276106 h 111.18352225402751 new_H 111 new_W 113\n",
      "x 1169 y 1020 cat 0.8555775284767151 w 101.27014975605707 h 124.7555305594214 new_H 124 new_W 101\n",
      "x 679 y 778 cat 0.8298282027244568 w 218.33875862564315 h 148.62371883829917 new_H 148 new_W 218\n",
      "x 798 y 625 cat 0.8282315135002136 w 150.94117825362687 h 138.2844096607203 new_H 138 new_W 150\n",
      "x 1284 y 5 cat 0.6586335897445679 w 122.03702420583461 h 77.46999343686741 new_H 77 new_W 122\n",
      "x 88 y 912 cat 0.5724930167198181 w 142.42593247880822 h 108.25609824403256 new_H 108 new_W 142\n",
      "x 840 y 311 cat 0.28478848934173584 w 160.95199490237013 h 196.5986725141806 new_H 196 new_W 160\n",
      "x 1 y 191 cat 0.27413323521614075 w 77.31296357066043 h 334.6415247949351 new_H 334 new_W 77\n",
      "current image is :Baseline_1_MMStack_1-Pos_003_000.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "[Detection {class_label = cat, object_id = None, x = 1089.081483004386, y = 58.04560981781377, w = 240.75187635743507, h = 175.77731393255524, confidence = 0.9520514607429504}, Detection {class_label = cat, object_id = None, x = 1383.7221936677633, y = 958.0848937246964, w = 131.25291782641702, h = 83.52129797478598, confidence = 0.7120698094367981}, Detection {class_label = cat, object_id = None, x = 1225.1677868800607, y = 944.3262351341094, w = 144.94473526062754, h = 92.84909457105053, confidence = 0.6750535368919373}, Detection {class_label = cat, object_id = None, x = 1384.9366829031715, y = 204.131538092527, w = 119.01636615294998, h = 95.97525259164664, confidence = 0.6093252301216125}, Detection {class_label = cat, object_id = None, x = 1135.6647715291836, y = 364.35884784075574, w = 128.70569193604504, h = 98.58598799197136, confidence = 0.55391526222229}, Detection {class_label = cat, object_id = None, x = 543.9706135079285, y = -28.49276078567814, w = 628.9888683736083, h = 208.26440643845945, confidence = 0.29432976245880127}]\n",
      "x 1089 y 58 cat 0.9520514607429504 w 240.75187635743507 h 175.77731393255524 new_H 175 new_W 240\n",
      "x 1383 y 958 cat 0.7120698094367981 w 131.25291782641702 h 83.52129797478598 new_H 83 new_W 131\n",
      "x 1225 y 944 cat 0.6750535368919373 w 144.94473526062754 h 92.84909457105053 new_H 92 new_W 144\n",
      "x 1384 y 204 cat 0.6093252301216125 w 119.01636615294998 h 95.97525259164664 new_H 95 new_W 119\n",
      "x 1135 y 364 cat 0.55391526222229 w 128.70569193604504 h 98.58598799197136 new_H 98 new_W 128\n",
      "x 543 y -28 cat 0.29432976245880127 w 628.9888683736083 h 208.26440643845945 new_H 180 new_W 628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detection {class_label = cat, object_id = None, x = 1354.096464870108, y = 400.6454748650473, w = 216.36846717906548, h = 138.40749837898534, confidence = 0.9605494737625122}, Detection {class_label = cat, object_id = None, x = -5.943969561825236, y = 185.25661584851554, w = 237.71432581604253, h = 132.75240598773829, confidence = 0.9474706649780273}, Detection {class_label = cat, object_id = None, x = 1118.3477063301282, y = 363.335615932861, w = 155.09463513331858, h = 163.55053595621416, confidence = 0.9283941984176636}, Detection {class_label = cat, object_id = None, x = 786.9292631368085, y = 323.7179671685223, w = 175.4594800694269, h = 114.35592639011894, confidence = 0.9276727437973022}, Detection {class_label = cat, object_id = None, x = 710.0936880587889, y = 65.63395511766194, w = 136.40925233663336, h = 128.92309487943868, confidence = 0.8179194331169128}, Detection {class_label = cat, object_id = None, x = 955.8383228955804, y = 36.46913877994265, w = 134.03563645912408, h = 143.21492101177674, confidence = 0.7223904132843018}, Detection {class_label = cat, object_id = None, x = 1366.0904961095648, y = 961.4107097672065, w = 170.80281443731025, h = 123.32776389591768, confidence = 0.6791070103645325}, Detection {class_label = cat, object_id = None, x = 513.3785510764592, y = 239.03875938343455, w = 197.58486588409878, h = 168.54613154072834, confidence = 0.6705304384231567}, Detection {class_label = cat, object_id = None, x = 2202.0852284708167, y = 10.542578652159245, w = 238.5080645480137, h = 156.22373791487433, confidence = 0.5396207571029663}, Detection {class_label = cat, object_id = None, x = 11.256800354251013, y = 551.7056553643725, w = 222.38445756631666, h = 486.51949434885296, confidence = 0.4342052638530731}, Detection {class_label = cat, object_id = None, x = 1867.0873476509785, y = 456.075325784413, w = 163.40990403724908, h = 163.56637429097083, confidence = 0.2580805718898773}, Detection {class_label = cat, object_id = None, x = -3.0419330880066004, y = 384.31249472840756, w = 86.11229076720122, h = 281.4660272225034, confidence = 0.24769647419452667}]\n",
      "x 1354 y 400 cat 0.9605494737625122 w 216.36846717906548 h 138.40749837898534 new_H 138 new_W 216\n",
      "x -5 y 185 cat 0.9474706649780273 w 237.71432581604253 h 132.75240598773829 new_H 132 new_W 232\n",
      "x 1118 y 363 cat 0.9283941984176636 w 155.09463513331858 h 163.55053595621416 new_H 163 new_W 155\n",
      "x 786 y 323 cat 0.9276727437973022 w 175.4594800694269 h 114.35592639011894 new_H 114 new_W 175\n",
      "x 710 y 65 cat 0.8179194331169128 w 136.40925233663336 h 128.92309487943868 new_H 128 new_W 136\n",
      "x 955 y 36 cat 0.7223904132843018 w 134.03563645912408 h 143.21492101177674 new_H 143 new_W 134\n",
      "x 1366 y 961 cat 0.6791070103645325 w 170.80281443731025 h 123.32776389591768 new_H 123 new_W 170\n",
      "x 513 y 239 cat 0.6705304384231567 w 197.58486588409878 h 168.54613154072834 new_H 168 new_W 197\n",
      "x 2202 y 10 cat 0.5396207571029663 w 238.5080645480137 h 156.22373791487433 new_H 156 new_W 238\n",
      "x 11 y 551 cat 0.4342052638530731 w 222.38445756631666 h 486.51949434885296 new_H 486 new_W 222\n",
      "x 1867 y 456 cat 0.2580805718898773 w 163.40990403724908 h 163.56637429097083 new_H 163 new_W 163\n",
      "x -3 y 384 cat 0.24769647419452667 w 86.11229076720122 h 281.4660272225034 new_H 281 new_W 83\n",
      "[Detection {class_label = cat, object_id = None, x = 1115.675101214575, y = 59.961202397520246, w = 184.2229204885712, h = 175.3473233159898, confidence = 0.9348772168159485}, Detection {class_label = cat, object_id = None, x = 1368.0846947220816, y = 193.3682378647942, w = 137.37527362859524, h = 117.69184148585106, confidence = 0.7854673862457275}, Detection {class_label = cat, object_id = None, x = 1136.1443203863023, y = 364.8273606190958, w = 125.96102695233427, h = 110.82658058815157, confidence = 0.7508086562156677}, Detection {class_label = cat, object_id = None, x = 1385.7194115848517, y = 953.555103955803, w = 133.71713886955973, h = 89.21382583844678, confidence = 0.7060739994049072}, Detection {class_label = cat, object_id = None, x = 1235.7393092105265, y = 941.2488349780702, w = 130.2972949152855, h = 101.12747460080867, confidence = 0.545142650604248}, Detection {class_label = cat, object_id = None, x = -0.3730988496067392, y = 703.0159175733806, w = 78.632386654173, h = 398.76858664652923, confidence = 0.21480602025985718}, Detection {class_label = cat, object_id = None, x = 597.530786099865, y = -21.922754038039812, w = 617.0827093085779, h = 204.12582483948003, confidence = 0.20829488337039948}]\n",
      "x 1115 y 59 cat 0.9348772168159485 w 184.2229204885712 h 175.3473233159898 new_H 175 new_W 184\n",
      "x 1368 y 193 cat 0.7854673862457275 w 137.37527362859524 h 117.69184148585106 new_H 117 new_W 137\n",
      "x 1136 y 364 cat 0.7508086562156677 w 125.96102695233427 h 110.82658058815157 new_H 110 new_W 125\n",
      "x 1385 y 953 cat 0.7060739994049072 w 133.71713886955973 h 89.21382583844678 new_H 89 new_W 133\n",
      "x 1235 y 941 cat 0.545142650604248 w 130.2972949152855 h 101.12747460080867 new_H 101 new_W 130\n",
      "x 0 y 703 cat 0.21480602025985718 w 78.632386654173 h 398.76858664652923 new_H 398 new_W 78\n",
      "x 597 y -21 cat 0.20829488337039948 w 617.0827093085779 h 204.12582483948003 new_H 183 new_W 617\n",
      "[Detection {class_label = cat, object_id = None, x = 1342.0271592442646, y = 393.4705660635965, w = 224.94914857192563, h = 139.3841653224106, confidence = 0.9632251858711243}, Detection {class_label = cat, object_id = None, x = -3.5479691849063766, y = 182.22742045167004, w = 233.8151542467949, h = 138.01290650567225, confidence = 0.958043098449707}, Detection {class_label = cat, object_id = None, x = 1125.8713968665654, y = 376.79838267543863, w = 146.54291043300861, h = 141.16296518508562, confidence = 0.9573594331741333}, Detection {class_label = cat, object_id = None, x = 722.180068372554, y = 75.28261138874832, w = 112.88253178770243, h = 122.92614433092949, confidence = 0.8730481863021851}, Detection {class_label = cat, object_id = None, x = 525.5637355294788, y = 249.56228518260798, w = 170.09446215919155, h = 177.42569805768179, confidence = 0.8589845895767212}, Detection {class_label = cat, object_id = None, x = 802.5506764771003, y = 334.9064687710864, w = 149.6711572397415, h = 115.32753079268936, confidence = 0.8386501669883728}, Detection {class_label = cat, object_id = None, x = 93.26788643078928, y = 686.3520633012821, w = 127.05841402164516, h = 140.77881073533445, confidence = 0.7957573533058167}, Detection {class_label = cat, object_id = None, x = 957.6886360281715, y = 32.128524059547914, w = 133.8705117332469, h = 145.1701679924722, confidence = 0.6365965008735657}, Detection {class_label = cat, object_id = None, x = 1454.7817349865047, y = 1381.5146655701756, w = 545.171672043691, h = 114.02140826638411, confidence = 0.29904282093048096}, Detection {class_label = cat, object_id = None, x = -4.794655659581647, y = 381.3764813174764, w = 87.95703380342759, h = 292.9098682892628, confidence = 0.24529585242271423}]\n",
      "x 1342 y 393 cat 0.9632251858711243 w 224.94914857192563 h 139.3841653224106 new_H 139 new_W 224\n",
      "x -3 y 182 cat 0.958043098449707 w 233.8151542467949 h 138.01290650567225 new_H 138 new_W 230\n",
      "x 1125 y 376 cat 0.9573594331741333 w 146.54291043300861 h 141.16296518508562 new_H 141 new_W 146\n",
      "x 722 y 75 cat 0.8730481863021851 w 112.88253178770243 h 122.92614433092949 new_H 122 new_W 112\n",
      "x 525 y 249 cat 0.8589845895767212 w 170.09446215919155 h 177.42569805768179 new_H 177 new_W 170\n",
      "x 802 y 334 cat 0.8386501669883728 w 149.6711572397415 h 115.32753079268936 new_H 115 new_W 149\n",
      "x 93 y 686 cat 0.7957573533058167 w 127.05841402164516 h 140.77881073533445 new_H 140 new_W 127\n",
      "x 957 y 32 cat 0.6365965008735657 w 133.8705117332469 h 145.1701679924722 new_H 145 new_W 133\n",
      "x 1454 y 1381 cat 0.29904282093048096 w 545.171672043691 h 114.02140826638411 new_H 99 new_W 545\n",
      "x -4 y 381 cat 0.24529585242271423 w 87.95703380342759 h 292.9098682892628 new_H 292 new_W 83\n",
      "current image is :Baseline_1_MMStack_1-Pos_003_002.ome.tif in Baseline and it has 2 timepoints and length df: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detection {class_label = cat, object_id = None, x = 2078.5431980642716, y = 972.3726594129555, w = 174.276251047729, h = 123.19490148052675, confidence = 0.8865308165550232}, Detection {class_label = cat, object_id = None, x = 1047.6900448612519, y = 809.5588467864372, w = 191.5182240598115, h = 142.77295729087595, confidence = 0.8713799715042114}, Detection {class_label = cat, object_id = None, x = 1582.685307017544, y = 416.6638226425439, w = 130.16462771355222, h = 131.3266825605179, confidence = 0.8281444907188416}, Detection {class_label = cat, object_id = None, x = 995.4315048814947, y = 1270.302433894231, w = 225.38439694300357, h = 167.78953546068448, confidence = 0.6763175129890442}, Detection {class_label = cat, object_id = None, x = 527.311808762441, y = 565.2471322537112, w = 144.62038126133393, h = 133.41713452049595, confidence = 0.48840025067329407}, Detection {class_label = cat, object_id = None, x = 174.019310831541, y = 78.04548329959515, w = 105.29700407164621, h = 113.85335533564229, confidence = 0.2881785035133362}, Detection {class_label = cat, object_id = None, x = 1363.9623028424428, y = 1048.8272815452092, w = 176.68656709287492, h = 133.67144585942773, confidence = 0.24676211178302765}]\n",
      "x 2078 y 972 cat 0.8865308165550232 w 174.276251047729 h 123.19490148052675 new_H 123 new_W 174\n",
      "x 1047 y 809 cat 0.8713799715042114 w 191.5182240598115 h 142.77295729087595 new_H 142 new_W 191\n",
      "x 1582 y 416 cat 0.8281444907188416 w 130.16462771355222 h 131.3266825605179 new_H 131 new_W 130\n",
      "x 995 y 1270 cat 0.6763175129890442 w 225.38439694300357 h 167.78953546068448 new_H 167 new_W 225\n",
      "x 527 y 565 cat 0.48840025067329407 w 144.62038126133393 h 133.41713452049595 new_H 133 new_W 144\n",
      "x 174 y 78 cat 0.2881785035133362 w 105.29700407164621 h 113.85335533564229 new_H 113 new_W 105\n",
      "x 1363 y 1048 cat 0.24676211178302765 w 176.68656709287492 h 133.67144585942773 new_H 133 new_W 176\n",
      "[Detection {class_label = cat, object_id = None, x = 707.858361536353, y = 431.72515498481783, w = 212.49516792657727, h = 151.77501387087761, confidence = 0.9587690830230713}, Detection {class_label = cat, object_id = None, x = 434.2932817508013, y = 614.8613861125169, w = 157.4282322110113, h = 129.09125192413126, confidence = 0.9521913528442383}, Detection {class_label = cat, object_id = None, x = 1869.231886808367, y = 1156.4738186361337, w = 144.11234422444332, h = 163.6053649655238, confidence = 0.9212594032287598}, Detection {class_label = cat, object_id = None, x = 1559.91891763664, y = 316.4856915802126, w = 189.9148952468687, h = 109.87132207584767, confidence = 0.9009707570075989}, Detection {class_label = cat, object_id = None, x = 940.858720004639, y = 76.32354266826924, w = 180.99969573027371, h = 141.43170932043904, confidence = 0.7761902213096619}, Detection {class_label = cat, object_id = None, x = 679.071062384025, y = 648.268221259278, w = 189.47857970779563, h = 147.27657541540148, confidence = 0.7478073239326477}, Detection {class_label = cat, object_id = None, x = 1580.416455802969, y = 1394.7948164431511, w = 378.8677515603914, h = 99.88583114562248, confidence = 0.5314728021621704}, Detection {class_label = cat, object_id = None, x = 161.76543719951925, y = 52.28967005102902, w = 152.7206808854694, h = 165.32617335763538, confidence = 0.518130362033844}, Detection {class_label = cat, object_id = None, x = 15.659616653092318, y = 780.5193836454116, w = 53.25532694416329, h = 356.32822647815453, confidence = 0.39415690302848816}, Detection {class_label = cat, object_id = None, x = 2.7696913746204457, y = 852.7342774755399, w = 51.7460650857161, h = 220.4323990753627, confidence = 0.3305419981479645}, Detection {class_label = cat, object_id = None, x = -4.345150184373946, y = 333.39473420630907, w = 89.48292786550587, h = 371.739251552484, confidence = 0.28499385714530945}]\n",
      "x 707 y 431 cat 0.9587690830230713 w 212.49516792657727 h 151.77501387087761 new_H 151 new_W 212\n",
      "x 434 y 614 cat 0.9521913528442383 w 157.4282322110113 h 129.09125192413126 new_H 129 new_W 157\n",
      "x 1869 y 1156 cat 0.9212594032287598 w 144.11234422444332 h 163.6053649655238 new_H 163 new_W 144\n",
      "x 1559 y 316 cat 0.9009707570075989 w 189.9148952468687 h 109.87132207584767 new_H 109 new_W 189\n",
      "x 940 y 76 cat 0.7761902213096619 w 180.99969573027371 h 141.43170932043904 new_H 141 new_W 180\n",
      "x 679 y 648 cat 0.7478073239326477 w 189.47857970779563 h 147.27657541540148 new_H 147 new_W 189\n",
      "x 1580 y 1394 cat 0.5314728021621704 w 378.8677515603914 h 99.88583114562248 new_H 86 new_W 378\n",
      "x 161 y 52 cat 0.518130362033844 w 152.7206808854694 h 165.32617335763538 new_H 165 new_W 152\n",
      "x 15 y 780 cat 0.39415690302848816 w 53.25532694416329 h 356.32822647815453 new_H 356 new_W 53\n",
      "x 2 y 852 cat 0.3305419981479645 w 51.7460650857161 h 220.4323990753627 new_H 220 new_W 51\n",
      "x -4 y 333 cat 0.28499385714530945 w 89.48292786550587 h 371.739251552484 new_H 371 new_W 85\n",
      "[Detection {class_label = cat, object_id = None, x = 2042.3184147267207, y = 958.8717869644063, w = 216.85885690130527, h = 142.98472506668566, confidence = 0.9016116261482239}, Detection {class_label = cat, object_id = None, x = 1572.4131122954623, y = 395.121605094467, w = 163.32358055783993, h = 165.3698361457279, confidence = 0.849159300327301}, Detection {class_label = cat, object_id = None, x = 1071.0174002087551, y = 804.8678886217949, w = 154.01738109923247, h = 142.49097766953443, confidence = 0.7545015811920166}, Detection {class_label = cat, object_id = None, x = 1011.7928040127363, y = 1259.9295609817814, w = 195.50546301714323, h = 175.7953646887652, confidence = 0.6789085268974304}, Detection {class_label = cat, object_id = None, x = 540.6559897151232, y = 561.4771660973347, w = 136.2784201432819, h = 140.39741530527792, confidence = 0.6055877804756165}, Detection {class_label = cat, object_id = None, x = 174.183043033327, y = 65.18178822958839, w = 106.04076160013918, h = 135.7955136112517, confidence = 0.41436517238616943}, Detection {class_label = cat, object_id = None, x = 1052.122592200152, y = 1285.4912017122133, w = 121.70185536990765, h = 109.76939451807102, confidence = 0.2246658354997635}]\n",
      "x 2042 y 958 cat 0.9016116261482239 w 216.85885690130527 h 142.98472506668566 new_H 142 new_W 216\n",
      "x 1572 y 395 cat 0.849159300327301 w 163.32358055783993 h 165.3698361457279 new_H 165 new_W 163\n",
      "x 1071 y 804 cat 0.7545015811920166 w 154.01738109923247 h 142.49097766953443 new_H 142 new_W 154\n",
      "x 1011 y 1259 cat 0.6789085268974304 w 195.50546301714323 h 175.7953646887652 new_H 175 new_W 195\n",
      "x 540 y 561 cat 0.6055877804756165 w 136.2784201432819 h 140.39741530527792 new_H 140 new_W 136\n",
      "x 174 y 65 cat 0.41436517238616943 w 106.04076160013918 h 135.7955136112517 new_H 135 new_W 106\n",
      "x 1052 y 1285 cat 0.2246658354997635 w 121.70185536990765 h 109.76939451807102 new_H 109 new_W 121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detection {class_label = cat, object_id = None, x = 433.365209993885, y = 616.3248118041498, w = 158.4434473446989, h = 129.64253529331143, confidence = 0.952037513256073}, Detection {class_label = cat, object_id = None, x = 708.8660284086117, y = 430.911192117915, w = 198.54583764944965, h = 154.4677520216557, confidence = 0.9460753798484802}, Detection {class_label = cat, object_id = None, x = 1866.0655733383942, y = 1165.4126259910595, w = 133.09950888526907, h = 141.3560184782494, confidence = 0.9262139201164246}, Detection {class_label = cat, object_id = None, x = 677.4025322094299, y = 653.280475075911, w = 191.05090859190494, h = 146.795347720827, confidence = 0.9177709221839905}, Detection {class_label = cat, object_id = None, x = 1587.7409763516364, y = 1320.6715138959178, w = 316.4425363476299, h = 164.07566069527033, confidence = 0.8321356773376465}, Detection {class_label = cat, object_id = None, x = 1562.4790796853915, y = 295.03124209261136, w = 186.64064163846365, h = 133.40989860091938, confidence = 0.8313180804252625}, Detection {class_label = cat, object_id = None, x = 1069.7387767796897, y = 823.9290707236843, w = 150.70528206973265, h = 148.71010738892755, confidence = 0.8241329789161682}, Detection {class_label = cat, object_id = None, x = 923.6113070386303, y = 66.27165306595816, w = 197.8916376399608, h = 162.89158574772267, confidence = 0.7926746606826782}, Detection {class_label = cat, object_id = None, x = 1009.5186429866735, y = 1231.9364430457154, w = 235.86403871193912, h = 233.23932601372724, confidence = 0.6880461573600769}, Detection {class_label = cat, object_id = None, x = 6.412596214798942, y = 862.5590945512821, w = 55.2770376681638, h = 199.77292467289772, confidence = 0.5763947367668152}, Detection {class_label = cat, object_id = None, x = 1149.1539832152498, y = 291.86638621794873, w = 162.30495569226554, h = 112.84368426983174, confidence = 0.49143150448799133}, Detection {class_label = cat, object_id = None, x = 175.48574281350162, y = 49.93804824561404, w = 120.188077568847, h = 172.14840916519063, confidence = 0.4449312686920166}]\n",
      "x 433 y 616 cat 0.952037513256073 w 158.4434473446989 h 129.64253529331143 new_H 129 new_W 158\n",
      "x 708 y 430 cat 0.9460753798484802 w 198.54583764944965 h 154.4677520216557 new_H 154 new_W 198\n",
      "x 1866 y 1165 cat 0.9262139201164246 w 133.09950888526907 h 141.3560184782494 new_H 141 new_W 133\n",
      "x 677 y 653 cat 0.9177709221839905 w 191.05090859190494 h 146.795347720827 new_H 146 new_W 191\n",
      "x 1587 y 1320 cat 0.8321356773376465 w 316.4425363476299 h 164.07566069527033 new_H 160 new_W 316\n",
      "x 1562 y 295 cat 0.8313180804252625 w 186.64064163846365 h 133.40989860091938 new_H 133 new_W 186\n",
      "x 1069 y 823 cat 0.8241329789161682 w 150.70528206973265 h 148.71010738892755 new_H 148 new_W 150\n",
      "x 923 y 66 cat 0.7926746606826782 w 197.8916376399608 h 162.89158574772267 new_H 162 new_W 197\n",
      "x 1009 y 1231 cat 0.6880461573600769 w 235.86403871193912 h 233.23932601372724 new_H 233 new_W 235\n",
      "x 6 y 862 cat 0.5763947367668152 w 55.2770376681638 h 199.77292467289772 new_H 199 new_W 55\n",
      "x 1149 y 291 cat 0.49143150448799133 w 162.30495569226554 h 112.84368426983174 new_H 112 new_W 162\n",
      "x 175 y 49 cat 0.4449312686920166 w 120.188077568847 h 172.14840916519063 new_H 172 new_W 120\n",
      "\\\n",
      "From the same core directory\n",
      "current image is :Baseline_1_MMStack_1-Pos_000_003.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "[Detection {class_label = cat, object_id = None, x = 1424.1996154373314, y = 398.4109812542173, w = 187.23547066754176, h = 146.70934959751392, confidence = 0.9631985425949097}, Detection {class_label = cat, object_id = None, x = 588.666003763917, y = 1102.834519441633, w = 228.42980808767715, h = 165.70254528956858, confidence = 0.9295817613601685}, Detection {class_label = cat, object_id = None, x = 767.3051369032557, y = 666.8211190536438, w = 146.93681255139805, h = 127.98357058794072, confidence = 0.883554995059967}, Detection {class_label = cat, object_id = None, x = 2018.5356649586708, y = 236.56511602774967, w = 206.0132806239984, h = 112.77046613397226, confidence = 0.8726407289505005}, Detection {class_label = cat, object_id = None, x = 1015.2972795947201, y = 1271.514528508772, w = 134.29010396898195, h = 130.236661553222, confidence = 0.8380724191665649}, Detection {class_label = cat, object_id = None, x = 521.1398817054657, y = 677.919457974865, w = 117.30703632390774, h = 117.72986910635966, confidence = 0.8093457818031311}, Detection {class_label = cat, object_id = None, x = 1625.533403445513, y = 949.7584846280365, w = 148.92993098167597, h = 154.0523113297065, confidence = 0.6504329442977905}, Detection {class_label = cat, object_id = None, x = 1775.047075320513, y = 1022.9805768176451, w = 131.4546386059801, h = 122.69022211854758, confidence = 0.3439410924911499}]\n",
      "x 1424 y 398 cat 0.9631985425949097 w 187.23547066754176 h 146.70934959751392 new_H 146 new_W 187\n",
      "x 588 y 1102 cat 0.9295817613601685 w 228.42980808767715 h 165.70254528956858 new_H 165 new_W 228\n",
      "x 767 y 666 cat 0.883554995059967 w 146.93681255139805 h 127.98357058794072 new_H 127 new_W 146\n",
      "x 2018 y 236 cat 0.8726407289505005 w 206.0132806239984 h 112.77046613397226 new_H 112 new_W 206\n",
      "x 1015 y 1271 cat 0.8380724191665649 w 134.29010396898195 h 130.236661553222 new_H 130 new_W 134\n",
      "x 521 y 677 cat 0.8093457818031311 w 117.30703632390774 h 117.72986910635966 new_H 117 new_W 117\n",
      "x 1625 y 949 cat 0.6504329442977905 w 148.92993098167597 h 154.0523113297065 new_H 154 new_W 148\n",
      "x 1775 y 1022 cat 0.3439410924911499 w 131.4546386059801 h 122.69022211854758 new_H 122 new_W 131\n",
      "[Detection {class_label = cat, object_id = None, x = 282.02884121172826, y = 626.9302752825574, w = 151.84758129454497, h = 117.31805938844256, confidence = 0.9418582916259766}, Detection {class_label = cat, object_id = None, x = 580.3934215797908, y = 306.37456113992914, w = 140.86539449962046, h = 88.36080071864984, confidence = 0.9260132908821106}, Detection {class_label = cat, object_id = None, x = 2378.7584819922404, y = 647.0121905575237, w = 151.55666088768345, h = 292.93795302747554, confidence = 0.5255148410797119}, Detection {class_label = cat, object_id = None, x = 586.4353623692646, y = 1102.4492978238868, w = 195.3753726356908, h = 157.27705875453358, confidence = 0.4462932050228119}, Detection {class_label = cat, object_id = None, x = 8.98816062113856, y = 768.1575178179825, w = 66.84103274120172, h = 176.67072875811826, confidence = 0.4396250247955322}, Detection {class_label = cat, object_id = None, x = 1239.5438411985494, y = 1289.710315452092, w = 118.40603715945514, h = 78.35543053095479, confidence = 0.30949822068214417}, Detection {class_label = cat, object_id = None, x = 4.51851943372554, y = 910.3594751602565, w = 75.26645420501751, h = 309.30656616375677, confidence = 0.22764869034290314}, Detection {class_label = cat, object_id = None, x = 1567.2211577998482, y = -3.874704790823212, w = 553.8826260174174, h = 164.84939653445514, confidence = 0.2170211523771286}]\n",
      "x 282 y 626 cat 0.9418582916259766 w 151.84758129454497 h 117.31805938844256 new_H 117 new_W 151\n",
      "x 580 y 306 cat 0.9260132908821106 w 140.86539449962046 h 88.36080071864984 new_H 88 new_W 140\n",
      "x 2378 y 647 cat 0.5255148410797119 w 151.55666088768345 h 292.93795302747554 new_H 292 new_W 150\n",
      "x 586 y 1102 cat 0.4462932050228119 w 195.3753726356908 h 157.27705875453358 new_H 157 new_W 195\n",
      "x 8 y 768 cat 0.4396250247955322 w 66.84103274120172 h 176.67072875811826 new_H 176 new_W 66\n",
      "x 1239 y 1289 cat 0.30949822068214417 w 118.40603715945514 h 78.35543053095479 new_H 78 new_W 118\n",
      "x 4 y 910 cat 0.22764869034290314 w 75.26645420501751 h 309.30656616375677 new_H 309 new_W 75\n",
      "x 1567 y -3 cat 0.2170211523771286 w 553.8826260174174 h 164.84939653445514 new_H 161 new_W 553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detection {class_label = cat, object_id = None, x = 1424.055521729504, y = 398.5305040696694, w = 186.15603024049005, h = 149.20895636966515, confidence = 0.9454817175865173}, Detection {class_label = cat, object_id = None, x = 726.6383839142628, y = 653.8553923119097, w = 216.9232123371078, h = 159.51852800006327, confidence = 0.918810248374939}, Detection {class_label = cat, object_id = None, x = 988.7947610914306, y = 1273.9726588857964, w = 178.2682271898195, h = 139.7384260540549, confidence = 0.7566810250282288}, Detection {class_label = cat, object_id = None, x = 1613.0498284096661, y = 915.4202460779353, w = 161.99962851747006, h = 219.9188830418143, confidence = 0.6664296984672546}, Detection {class_label = cat, object_id = None, x = -18.377088374293606, y = 346.3052805541498, w = 183.37540690104169, h = 900.8150369538631, confidence = 0.5516310930252075}, Detection {class_label = cat, object_id = None, x = 518.4911707416077, y = 690.901426492915, w = 120.62107447574014, h = 119.5399161685012, confidence = 0.487222820520401}, Detection {class_label = cat, object_id = None, x = 2161.283595858637, y = -47.06367029352227, w = 468.54458515203277, h = 254.81087766742579, confidence = 0.323055237531662}, Detection {class_label = cat, object_id = None, x = 1.6829955066263917, y = 646.3412802589406, w = 124.65269200457575, h = 408.57234667573385, confidence = 0.2545628845691681}]\n",
      "x 1424 y 398 cat 0.9454817175865173 w 186.15603024049005 h 149.20895636966515 new_H 149 new_W 186\n",
      "x 726 y 653 cat 0.918810248374939 w 216.9232123371078 h 159.51852800006327 new_H 159 new_W 216\n",
      "x 988 y 1273 cat 0.7566810250282288 w 178.2682271898195 h 139.7384260540549 new_H 139 new_W 178\n",
      "x 1613 y 915 cat 0.6664296984672546 w 161.99962851747006 h 219.9188830418143 new_H 219 new_W 161\n",
      "x -18 y 346 cat 0.5516310930252075 w 183.37540690104169 h 900.8150369538631 new_H 900 new_W 165\n",
      "x 518 y 690 cat 0.487222820520401 w 120.62107447574014 h 119.5399161685012 new_H 119 new_W 120\n",
      "x 2161 y -47 cat 0.323055237531662 w 468.54458515203277 h 254.81087766742579 new_H 207 new_W 367\n",
      "x 1 y 646 cat 0.2545628845691681 w 124.65269200457575 h 408.57234667573385 new_H 408 new_W 124\n",
      "[Detection {class_label = cat, object_id = None, x = 971.3632746605095, y = 1025.7558382886302, w = 199.51058354551495, h = 120.97196451822917, confidence = 0.9232482314109802}, Detection {class_label = cat, object_id = None, x = 1179.8139799995784, y = 1226.1556200447033, w = 191.714530913936, h = 138.32420721839154, confidence = 0.8162416815757751}, Detection {class_label = cat, object_id = None, x = 596.1157733953273, y = 1113.6371747427463, w = 172.67430174463354, h = 152.65655970605602, confidence = 0.7265763878822327}, Detection {class_label = cat, object_id = None, x = 252.4248462012905, y = 551.7756199392713, w = 197.3008039837424, h = 179.95230938580679, confidence = 0.68648362159729}, Detection {class_label = cat, object_id = None, x = 2261.063907515182, y = 602.0293416835358, w = 235.17574138358216, h = 148.31140301456014, confidence = 0.6821162700653076}, Detection {class_label = cat, object_id = None, x = 556.6730881252109, y = 231.9882667531208, w = 163.73274838425692, h = 155.53886333264805, confidence = 0.6661224365234375}, Detection {class_label = cat, object_id = None, x = 13.721646081098179, y = 771.9397694205466, w = 100.04111710315453, h = 179.4726303862496, confidence = 0.48243966698646545}, Detection {class_label = cat, object_id = None, x = 911.3614678221998, y = 416.0318509615385, w = 227.57323658643304, h = 210.52832525461793, confidence = 0.4803241193294525}, Detection {class_label = cat, object_id = None, x = 1050.6236636513158, y = 426.296028909413, w = 228.83150573812839, h = 178.4784332563681, confidence = 0.4751213490962982}, Detection {class_label = cat, object_id = None, x = 2017.7400261470987, y = 0.32993710990215924, w = 638.4772412175271, h = 257.257919908696, confidence = 0.3026469349861145}, Detection {class_label = cat, object_id = None, x = -1.0121632935064524, y = 247.7294631937416, w = 78.28332511294387, h = 326.61074726140777, confidence = 0.298695832490921}, Detection {class_label = cat, object_id = None, x = 19.97793797378437, y = 947.9081714954455, w = 135.5115948675776, h = 552.4903101541414, confidence = 0.276368647813797}, Detection {class_label = cat, object_id = None, x = 211.53044805899967, y = 59.26238956013833, w = 189.57970038245404, h = 125.26100379027497, confidence = 0.261031836271286}, Detection {class_label = cat, object_id = None, x = 1825.482788250675, y = 1283.4857587930162, w = 234.94510295420042, h = 159.02561351451797, confidence = 0.25370270013809204}, Detection {class_label = cat, object_id = None, x = 2334.871953019568, y = 401.00883255313767, w = 226.75375568014087, h = 237.2186392965587, confidence = 0.2502748966217041}, Detection {class_label = cat, object_id = None, x = 1263.644971427969, y = 1444.060913250675, w = 268.4190915991903, h = 33.07292218536501, confidence = 0.22758954763412476}]\n",
      "x 971 y 1025 cat 0.9232482314109802 w 199.51058354551495 h 120.97196451822917 new_H 120 new_W 199\n",
      "x 1179 y 1226 cat 0.8162416815757751 w 191.714530913936 h 138.32420721839154 new_H 138 new_W 191\n",
      "x 596 y 1113 cat 0.7265763878822327 w 172.67430174463354 h 152.65655970605602 new_H 152 new_W 172\n",
      "x 252 y 551 cat 0.68648362159729 w 197.3008039837424 h 179.95230938580679 new_H 179 new_W 197\n",
      "x 2261 y 602 cat 0.6821162700653076 w 235.17574138358216 h 148.31140301456014 new_H 148 new_W 235\n",
      "x 556 y 231 cat 0.6661224365234375 w 163.73274838425692 h 155.53886333264805 new_H 155 new_W 163\n",
      "x 13 y 771 cat 0.48243966698646545 w 100.04111710315453 h 179.4726303862496 new_H 179 new_W 100\n",
      "x 911 y 416 cat 0.4803241193294525 w 227.57323658643304 h 210.52832525461793 new_H 210 new_W 227\n",
      "x 1050 y 426 cat 0.4751213490962982 w 228.83150573812839 h 178.4784332563681 new_H 178 new_W 228\n",
      "x 2017 y 0 cat 0.3026469349861145 w 638.4772412175271 h 257.257919908696 new_H 257 new_W 511\n",
      "x -1 y 247 cat 0.298695832490921 w 78.28332511294387 h 326.61074726140777 new_H 326 new_W 77\n",
      "x 19 y 947 cat 0.276368647813797 w 135.5115948675776 h 552.4903101541414 new_H 533 new_W 135\n",
      "x 211 y 59 cat 0.261031836271286 w 189.57970038245404 h 125.26100379027497 new_H 125 new_W 189\n",
      "x 1825 y 1283 cat 0.25370270013809204 w 234.94510295420042 h 159.02561351451797 new_H 159 new_W 234\n",
      "x 2334 y 401 cat 0.2502748966217041 w 226.75375568014087 h 237.2186392965587 new_H 237 new_W 194\n",
      "x 1263 y 1444 cat 0.22758954763412476 w 268.4190915991903 h 33.07292218536501 new_H 33 new_W 268\n",
      "current image is :Baseline_1_MMStack_1-Pos_001_000.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "[Detection {class_label = cat, object_id = None, x = 1180.941846427969, y = 1017.8025735914306, w = 129.31957381810898, h = 118.77267443699394, confidence = 0.8863032460212708}, Detection {class_label = cat, object_id = None, x = 956.5790936551114, y = 270.69221148574564, w = 143.16104204226764, h = 139.89519563538505, confidence = 0.8364134430885315}, Detection {class_label = cat, object_id = None, x = 816.1695620888158, y = 637.8518287154184, w = 120.31559113001856, h = 129.45306091720437, confidence = 0.7859861254692078}, Detection {class_label = cat, object_id = None, x = 1638.9557739752026, y = 1403.9583017037787, w = 423.90119981443996, h = 90.76290477593096, confidence = 0.29279524087905884}, Detection {class_label = cat, object_id = None, x = 2.0020364408711835, y = 601.9699967316127, w = 81.91869795949836, h = 373.43602263621796, confidence = 0.2572571635246277}]\n",
      "x 1180 y 1017 cat 0.8863032460212708 w 129.31957381810898 h 118.77267443699394 new_H 118 new_W 129\n",
      "x 956 y 270 cat 0.8364134430885315 w 143.16104204226764 h 139.89519563538505 new_H 139 new_W 143\n",
      "x 816 y 637 cat 0.7859861254692078 w 120.31559113001856 h 129.45306091720437 new_H 129 new_W 120\n",
      "x 1638 y 1403 cat 0.29279524087905884 w 423.90119981443996 h 90.76290477593096 new_H 77 new_W 423\n",
      "x 2 y 601 cat 0.2572571635246277 w 81.91869795949836 h 373.43602263621796 new_H 373 new_W 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detection {class_label = cat, object_id = None, x = 244.05304342210695, y = 567.5992746288799, w = 180.08532797212382, h = 150.26104085615933, confidence = 0.9463828206062317}, Detection {class_label = cat, object_id = None, x = 677.1822791466346, y = 806.4341788967612, w = 182.20076728028005, h = 115.82899563643936, confidence = 0.9431463479995728}, Detection {class_label = cat, object_id = None, x = 525.2643038071441, y = 120.78904932101891, w = 132.76067003257845, h = 117.71150600829749, confidence = 0.9223216772079468}, Detection {class_label = cat, object_id = None, x = 843.2755771075828, y = 328.370819627193, w = 170.32973365938133, h = 166.55521251765984, confidence = 0.9010586738586426}, Detection {class_label = cat, object_id = None, x = 152.28954501544578, y = 1095.0828193530701, w = 176.50961241934465, h = 140.22155382823044, confidence = 0.8857040405273438}, Detection {class_label = cat, object_id = None, x = 1154.3805035425103, y = 1032.4772267206479, w = 133.4026106243674, h = 106.14875379554657, confidence = 0.8741595149040222}, Detection {class_label = cat, object_id = None, x = 1230.0342811656546, y = 1401.1241117366735, w = 229.73305446609314, h = 85.32490298622534, confidence = 0.790859580039978}, Detection {class_label = cat, object_id = None, x = 1379.2147883982796, y = 1381.4823902454455, w = 340.0438935849992, h = 123.65882023079033, confidence = 0.7824482917785645}, Detection {class_label = cat, object_id = None, x = 800.0680793216516, y = 629.4839822663631, w = 142.89778991781589, h = 115.8648108354947, confidence = 0.7625579833984375}, Detection {class_label = cat, object_id = None, x = 2019.7156924763833, y = 1246.6885569542849, w = 234.61646726868253, h = 190.1051895203378, confidence = 0.7139737010002136}, Detection {class_label = cat, object_id = None, x = 2.1472331058641196, y = 518.0518619264508, w = 218.61214884604843, h = 195.51276400793904, confidence = 0.6503405570983887}, Detection {class_label = cat, object_id = None, x = 1291.694727353239, y = 5.322513389844804, w = 111.0366174695302, h = 79.58759961662345, confidence = 0.6310102939605713}, Detection {class_label = cat, object_id = None, x = 2165.542272899798, y = -50.28453947368421, w = 471.57804922085865, h = 242.62038340291838, confidence = 0.4624941647052765}]\n",
      "x 244 y 567 cat 0.9463828206062317 w 180.08532797212382 h 150.26104085615933 new_H 150 new_W 180\n",
      "x 677 y 806 cat 0.9431463479995728 w 182.20076728028005 h 115.82899563643936 new_H 115 new_W 182\n",
      "x 525 y 120 cat 0.9223216772079468 w 132.76067003257845 h 117.71150600829749 new_H 117 new_W 132\n",
      "x 843 y 328 cat 0.9010586738586426 w 170.32973365938133 h 166.55521251765984 new_H 166 new_W 170\n",
      "x 152 y 1095 cat 0.8857040405273438 w 176.50961241934465 h 140.22155382823044 new_H 140 new_W 176\n",
      "x 1154 y 1032 cat 0.8741595149040222 w 133.4026106243674 h 106.14875379554657 new_H 106 new_W 133\n",
      "x 1230 y 1401 cat 0.790859580039978 w 229.73305446609314 h 85.32490298622534 new_H 79 new_W 229\n",
      "x 1379 y 1381 cat 0.7824482917785645 w 340.0438935849992 h 123.65882023079033 new_H 99 new_W 340\n",
      "x 800 y 629 cat 0.7625579833984375 w 142.89778991781589 h 115.8648108354947 new_H 115 new_W 142\n",
      "x 2019 y 1246 cat 0.7139737010002136 w 234.61646726868253 h 190.1051895203378 new_H 190 new_W 234\n",
      "x 2 y 518 cat 0.6503405570983887 w 218.61214884604843 h 195.51276400793904 new_H 195 new_W 218\n",
      "x 1291 y 5 cat 0.6310102939605713 w 111.0366174695302 h 79.58759961662345 new_H 79 new_W 111\n",
      "x 2165 y -50 cat 0.4624941647052765 w 471.57804922085865 h 242.62038340291838 new_H 192 new_W 363\n",
      "[Detection {class_label = cat, object_id = None, x = 1165.7179922085863, y = 1009.196097967274, w = 136.44047350761218, h = 134.6351506159856, confidence = 0.9083572626113892}, Detection {class_label = cat, object_id = None, x = 826.8928825594636, y = 650.9466567560729, w = 115.71479564671897, h = 102.07208095452725, confidence = 0.6785563826560974}, Detection {class_label = cat, object_id = None, x = 938.7140767332996, y = 280.4330086032389, w = 179.31816432607962, h = 135.84171417689356, confidence = 0.46719416975975037}, Detection {class_label = cat, object_id = None, x = 1653.117770010965, y = 1387.4352094930837, w = 405.117455362791, h = 106.18942330755526, confidence = 0.364978164434433}, Detection {class_label = cat, object_id = None, x = 3.001654003313196, y = 594.2349548751687, w = 79.69544865534856, h = 382.41173838668186, confidence = 0.22335965931415558}]\n",
      "x 1165 y 1009 cat 0.9083572626113892 w 136.44047350761218 h 134.6351506159856 new_H 134 new_W 136\n",
      "x 826 y 650 cat 0.6785563826560974 w 115.71479564671897 h 102.07208095452725 new_H 102 new_W 115\n",
      "x 938 y 280 cat 0.46719416975975037 w 179.31816432607962 h 135.84171417689356 new_H 135 new_W 179\n",
      "x 1653 y 1387 cat 0.364978164434433 w 405.117455362791 h 106.18942330755526 new_H 93 new_W 405\n",
      "x 3 y 594 cat 0.22335965931415558 w 79.69544865534856 h 382.41173838668186 new_H 382 new_W 79\n",
      "[Detection {class_label = cat, object_id = None, x = 233.1966913508983, y = 557.6137056131917, w = 196.64872529599992, h = 172.61737744206522, confidence = 0.9501796364784241}, Detection {class_label = cat, object_id = None, x = 175.03341975450195, y = 1096.2967880187248, w = 156.9667991813217, h = 119.69809128816634, confidence = 0.9113819003105164}, Detection {class_label = cat, object_id = None, x = 13.933862848320471, y = 517.1789705634278, w = 176.5577260788314, h = 168.44996929297403, confidence = 0.9037507176399231}, Detection {class_label = cat, object_id = None, x = 539.3751798930922, y = 123.9252738592274, w = 113.71571669276106, h = 111.18352225402751, confidence = 0.8639844059944153}, Detection {class_label = cat, object_id = None, x = 1169.0297528677463, y = 1020.3492008265857, w = 101.27014975605707, h = 124.7555305594214, confidence = 0.8555775284767151}, Detection {class_label = cat, object_id = None, x = 679.2354062552716, y = 778.9158205760797, w = 218.33875862564315, h = 148.62371883829917, confidence = 0.8298282027244568}, Detection {class_label = cat, object_id = None, x = 798.9378182723938, y = 625.0466456857288, w = 150.94117825362687, h = 138.2844096607203, confidence = 0.8282315135002136}, Detection {class_label = cat, object_id = None, x = 1284.8589176893556, y = 5.320535224780702, w = 122.03702420583461, h = 77.46999343686741, confidence = 0.6586335897445679}, Detection {class_label = cat, object_id = None, x = 88.96280710320724, y = 912.0677768640352, w = 142.42593247880822, h = 108.25609824403256, confidence = 0.5724930167198181}, Detection {class_label = cat, object_id = None, x = 840.4383157789306, y = 311.80077202471324, w = 160.95199490237013, h = 196.5986725141806, confidence = 0.28478848934173584}, Detection {class_label = cat, object_id = None, x = 1.4621698171021003, y = 191.58289183746626, w = 77.31296357066043, h = 334.6415247949351, confidence = 0.27413323521614075}]\n",
      "x 233 y 557 cat 0.9501796364784241 w 196.64872529599992 h 172.61737744206522 new_H 172 new_W 196\n",
      "x 175 y 1096 cat 0.9113819003105164 w 156.9667991813217 h 119.69809128816634 new_H 119 new_W 156\n",
      "x 13 y 517 cat 0.9037507176399231 w 176.5577260788314 h 168.44996929297403 new_H 168 new_W 176\n",
      "x 539 y 123 cat 0.8639844059944153 w 113.71571669276106 h 111.18352225402751 new_H 111 new_W 113\n",
      "x 1169 y 1020 cat 0.8555775284767151 w 101.27014975605707 h 124.7555305594214 new_H 124 new_W 101\n",
      "x 679 y 778 cat 0.8298282027244568 w 218.33875862564315 h 148.62371883829917 new_H 148 new_W 218\n",
      "x 798 y 625 cat 0.8282315135002136 w 150.94117825362687 h 138.2844096607203 new_H 138 new_W 150\n",
      "x 1284 y 5 cat 0.6586335897445679 w 122.03702420583461 h 77.46999343686741 new_H 77 new_W 122\n",
      "x 88 y 912 cat 0.5724930167198181 w 142.42593247880822 h 108.25609824403256 new_H 108 new_W 142\n",
      "x 840 y 311 cat 0.28478848934173584 w 160.95199490237013 h 196.5986725141806 new_H 196 new_W 160\n",
      "x 1 y 191 cat 0.27413323521614075 w 77.31296357066043 h 334.6415247949351 new_H 334 new_W 77\n",
      "current image is :Baseline_1_MMStack_1-Pos_003_000.ome.tif in Baseline and it has 2 timepoints and length df: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detection {class_label = cat, object_id = None, x = 1089.081483004386, y = 58.04560981781377, w = 240.75187635743507, h = 175.77731393255524, confidence = 0.9520514607429504}, Detection {class_label = cat, object_id = None, x = 1383.7221936677633, y = 958.0848937246964, w = 131.25291782641702, h = 83.52129797478598, confidence = 0.7120698094367981}, Detection {class_label = cat, object_id = None, x = 1225.1677868800607, y = 944.3262351341094, w = 144.94473526062754, h = 92.84909457105053, confidence = 0.6750535368919373}, Detection {class_label = cat, object_id = None, x = 1384.9366829031715, y = 204.131538092527, w = 119.01636615294998, h = 95.97525259164664, confidence = 0.6093252301216125}, Detection {class_label = cat, object_id = None, x = 1135.6647715291836, y = 364.35884784075574, w = 128.70569193604504, h = 98.58598799197136, confidence = 0.55391526222229}, Detection {class_label = cat, object_id = None, x = 543.9706135079285, y = -28.49276078567814, w = 628.9888683736083, h = 208.26440643845945, confidence = 0.29432976245880127}]\n",
      "x 1089 y 58 cat 0.9520514607429504 w 240.75187635743507 h 175.77731393255524 new_H 175 new_W 240\n",
      "x 1383 y 958 cat 0.7120698094367981 w 131.25291782641702 h 83.52129797478598 new_H 83 new_W 131\n",
      "x 1225 y 944 cat 0.6750535368919373 w 144.94473526062754 h 92.84909457105053 new_H 92 new_W 144\n",
      "x 1384 y 204 cat 0.6093252301216125 w 119.01636615294998 h 95.97525259164664 new_H 95 new_W 119\n",
      "x 1135 y 364 cat 0.55391526222229 w 128.70569193604504 h 98.58598799197136 new_H 98 new_W 128\n",
      "x 543 y -28 cat 0.29432976245880127 w 628.9888683736083 h 208.26440643845945 new_H 180 new_W 628\n",
      "[Detection {class_label = cat, object_id = None, x = 1354.096464870108, y = 400.6454748650473, w = 216.36846717906548, h = 138.40749837898534, confidence = 0.9605494737625122}, Detection {class_label = cat, object_id = None, x = -5.943969561825236, y = 185.25661584851554, w = 237.71432581604253, h = 132.75240598773829, confidence = 0.9474706649780273}, Detection {class_label = cat, object_id = None, x = 1118.3477063301282, y = 363.335615932861, w = 155.09463513331858, h = 163.55053595621416, confidence = 0.9283941984176636}, Detection {class_label = cat, object_id = None, x = 786.9292631368085, y = 323.7179671685223, w = 175.4594800694269, h = 114.35592639011894, confidence = 0.9276727437973022}, Detection {class_label = cat, object_id = None, x = 710.0936880587889, y = 65.63395511766194, w = 136.40925233663336, h = 128.92309487943868, confidence = 0.8179194331169128}, Detection {class_label = cat, object_id = None, x = 955.8383228955804, y = 36.46913877994265, w = 134.03563645912408, h = 143.21492101177674, confidence = 0.7223904132843018}, Detection {class_label = cat, object_id = None, x = 1366.0904961095648, y = 961.4107097672065, w = 170.80281443731025, h = 123.32776389591768, confidence = 0.6791070103645325}, Detection {class_label = cat, object_id = None, x = 513.3785510764592, y = 239.03875938343455, w = 197.58486588409878, h = 168.54613154072834, confidence = 0.6705304384231567}, Detection {class_label = cat, object_id = None, x = 2202.0852284708167, y = 10.542578652159245, w = 238.5080645480137, h = 156.22373791487433, confidence = 0.5396207571029663}, Detection {class_label = cat, object_id = None, x = 11.256800354251013, y = 551.7056553643725, w = 222.38445756631666, h = 486.51949434885296, confidence = 0.4342052638530731}, Detection {class_label = cat, object_id = None, x = 1867.0873476509785, y = 456.075325784413, w = 163.40990403724908, h = 163.56637429097083, confidence = 0.2580805718898773}, Detection {class_label = cat, object_id = None, x = -3.0419330880066004, y = 384.31249472840756, w = 86.11229076720122, h = 281.4660272225034, confidence = 0.24769647419452667}]\n",
      "x 1354 y 400 cat 0.9605494737625122 w 216.36846717906548 h 138.40749837898534 new_H 138 new_W 216\n",
      "x -5 y 185 cat 0.9474706649780273 w 237.71432581604253 h 132.75240598773829 new_H 132 new_W 232\n",
      "x 1118 y 363 cat 0.9283941984176636 w 155.09463513331858 h 163.55053595621416 new_H 163 new_W 155\n",
      "x 786 y 323 cat 0.9276727437973022 w 175.4594800694269 h 114.35592639011894 new_H 114 new_W 175\n",
      "x 710 y 65 cat 0.8179194331169128 w 136.40925233663336 h 128.92309487943868 new_H 128 new_W 136\n",
      "x 955 y 36 cat 0.7223904132843018 w 134.03563645912408 h 143.21492101177674 new_H 143 new_W 134\n",
      "x 1366 y 961 cat 0.6791070103645325 w 170.80281443731025 h 123.32776389591768 new_H 123 new_W 170\n",
      "x 513 y 239 cat 0.6705304384231567 w 197.58486588409878 h 168.54613154072834 new_H 168 new_W 197\n",
      "x 2202 y 10 cat 0.5396207571029663 w 238.5080645480137 h 156.22373791487433 new_H 156 new_W 238\n",
      "x 11 y 551 cat 0.4342052638530731 w 222.38445756631666 h 486.51949434885296 new_H 486 new_W 222\n",
      "x 1867 y 456 cat 0.2580805718898773 w 163.40990403724908 h 163.56637429097083 new_H 163 new_W 163\n",
      "x -3 y 384 cat 0.24769647419452667 w 86.11229076720122 h 281.4660272225034 new_H 281 new_W 83\n",
      "[Detection {class_label = cat, object_id = None, x = 1115.675101214575, y = 59.961202397520246, w = 184.2229204885712, h = 175.3473233159898, confidence = 0.9348772168159485}, Detection {class_label = cat, object_id = None, x = 1368.0846947220816, y = 193.3682378647942, w = 137.37527362859524, h = 117.69184148585106, confidence = 0.7854673862457275}, Detection {class_label = cat, object_id = None, x = 1136.1443203863023, y = 364.8273606190958, w = 125.96102695233427, h = 110.82658058815157, confidence = 0.7508086562156677}, Detection {class_label = cat, object_id = None, x = 1385.7194115848517, y = 953.555103955803, w = 133.71713886955973, h = 89.21382583844678, confidence = 0.7060739994049072}, Detection {class_label = cat, object_id = None, x = 1235.7393092105265, y = 941.2488349780702, w = 130.2972949152855, h = 101.12747460080867, confidence = 0.545142650604248}, Detection {class_label = cat, object_id = None, x = -0.3730988496067392, y = 703.0159175733806, w = 78.632386654173, h = 398.76858664652923, confidence = 0.21480602025985718}, Detection {class_label = cat, object_id = None, x = 597.530786099865, y = -21.922754038039812, w = 617.0827093085779, h = 204.12582483948003, confidence = 0.20829488337039948}]\n",
      "x 1115 y 59 cat 0.9348772168159485 w 184.2229204885712 h 175.3473233159898 new_H 175 new_W 184\n",
      "x 1368 y 193 cat 0.7854673862457275 w 137.37527362859524 h 117.69184148585106 new_H 117 new_W 137\n",
      "x 1136 y 364 cat 0.7508086562156677 w 125.96102695233427 h 110.82658058815157 new_H 110 new_W 125\n",
      "x 1385 y 953 cat 0.7060739994049072 w 133.71713886955973 h 89.21382583844678 new_H 89 new_W 133\n",
      "x 1235 y 941 cat 0.545142650604248 w 130.2972949152855 h 101.12747460080867 new_H 101 new_W 130\n",
      "x 0 y 703 cat 0.21480602025985718 w 78.632386654173 h 398.76858664652923 new_H 398 new_W 78\n",
      "x 597 y -21 cat 0.20829488337039948 w 617.0827093085779 h 204.12582483948003 new_H 183 new_W 617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detection {class_label = cat, object_id = None, x = 1342.0271592442646, y = 393.4705660635965, w = 224.94914857192563, h = 139.3841653224106, confidence = 0.9632251858711243}, Detection {class_label = cat, object_id = None, x = -3.5479691849063766, y = 182.22742045167004, w = 233.8151542467949, h = 138.01290650567225, confidence = 0.958043098449707}, Detection {class_label = cat, object_id = None, x = 1125.8713968665654, y = 376.79838267543863, w = 146.54291043300861, h = 141.16296518508562, confidence = 0.9573594331741333}, Detection {class_label = cat, object_id = None, x = 722.180068372554, y = 75.28261138874832, w = 112.88253178770243, h = 122.92614433092949, confidence = 0.8730481863021851}, Detection {class_label = cat, object_id = None, x = 525.5637355294788, y = 249.56228518260798, w = 170.09446215919155, h = 177.42569805768179, confidence = 0.8589845895767212}, Detection {class_label = cat, object_id = None, x = 802.5506764771003, y = 334.9064687710864, w = 149.6711572397415, h = 115.32753079268936, confidence = 0.8386501669883728}, Detection {class_label = cat, object_id = None, x = 93.26788643078928, y = 686.3520633012821, w = 127.05841402164516, h = 140.77881073533445, confidence = 0.7957573533058167}, Detection {class_label = cat, object_id = None, x = 957.6886360281715, y = 32.128524059547914, w = 133.8705117332469, h = 145.1701679924722, confidence = 0.6365965008735657}, Detection {class_label = cat, object_id = None, x = 1454.7817349865047, y = 1381.5146655701756, w = 545.171672043691, h = 114.02140826638411, confidence = 0.29904282093048096}, Detection {class_label = cat, object_id = None, x = -4.794655659581647, y = 381.3764813174764, w = 87.95703380342759, h = 292.9098682892628, confidence = 0.24529585242271423}]\n",
      "x 1342 y 393 cat 0.9632251858711243 w 224.94914857192563 h 139.3841653224106 new_H 139 new_W 224\n",
      "x -3 y 182 cat 0.958043098449707 w 233.8151542467949 h 138.01290650567225 new_H 138 new_W 230\n",
      "x 1125 y 376 cat 0.9573594331741333 w 146.54291043300861 h 141.16296518508562 new_H 141 new_W 146\n",
      "x 722 y 75 cat 0.8730481863021851 w 112.88253178770243 h 122.92614433092949 new_H 122 new_W 112\n",
      "x 525 y 249 cat 0.8589845895767212 w 170.09446215919155 h 177.42569805768179 new_H 177 new_W 170\n",
      "x 802 y 334 cat 0.8386501669883728 w 149.6711572397415 h 115.32753079268936 new_H 115 new_W 149\n",
      "x 93 y 686 cat 0.7957573533058167 w 127.05841402164516 h 140.77881073533445 new_H 140 new_W 127\n",
      "x 957 y 32 cat 0.6365965008735657 w 133.8705117332469 h 145.1701679924722 new_H 145 new_W 133\n",
      "x 1454 y 1381 cat 0.29904282093048096 w 545.171672043691 h 114.02140826638411 new_H 99 new_W 545\n",
      "x -4 y 381 cat 0.24529585242271423 w 87.95703380342759 h 292.9098682892628 new_H 292 new_W 83\n",
      "current image is :Baseline_1_MMStack_1-Pos_003_002.ome.tif in Baseline and it has 2 timepoints and length df: 1\n",
      "[Detection {class_label = cat, object_id = None, x = 2078.5431980642716, y = 972.3726594129555, w = 174.276251047729, h = 123.19490148052675, confidence = 0.8865308165550232}, Detection {class_label = cat, object_id = None, x = 1047.6900448612519, y = 809.5588467864372, w = 191.5182240598115, h = 142.77295729087595, confidence = 0.8713799715042114}, Detection {class_label = cat, object_id = None, x = 1582.685307017544, y = 416.6638226425439, w = 130.16462771355222, h = 131.3266825605179, confidence = 0.8281444907188416}, Detection {class_label = cat, object_id = None, x = 995.4315048814947, y = 1270.302433894231, w = 225.38439694300357, h = 167.78953546068448, confidence = 0.6763175129890442}, Detection {class_label = cat, object_id = None, x = 527.311808762441, y = 565.2471322537112, w = 144.62038126133393, h = 133.41713452049595, confidence = 0.48840025067329407}, Detection {class_label = cat, object_id = None, x = 174.019310831541, y = 78.04548329959515, w = 105.29700407164621, h = 113.85335533564229, confidence = 0.2881785035133362}, Detection {class_label = cat, object_id = None, x = 1363.9623028424428, y = 1048.8272815452092, w = 176.68656709287492, h = 133.67144585942773, confidence = 0.24676211178302765}]\n",
      "x 2078 y 972 cat 0.8865308165550232 w 174.276251047729 h 123.19490148052675 new_H 123 new_W 174\n",
      "x 1047 y 809 cat 0.8713799715042114 w 191.5182240598115 h 142.77295729087595 new_H 142 new_W 191\n",
      "x 1582 y 416 cat 0.8281444907188416 w 130.16462771355222 h 131.3266825605179 new_H 131 new_W 130\n",
      "x 995 y 1270 cat 0.6763175129890442 w 225.38439694300357 h 167.78953546068448 new_H 167 new_W 225\n",
      "x 527 y 565 cat 0.48840025067329407 w 144.62038126133393 h 133.41713452049595 new_H 133 new_W 144\n",
      "x 174 y 78 cat 0.2881785035133362 w 105.29700407164621 h 113.85335533564229 new_H 113 new_W 105\n",
      "x 1363 y 1048 cat 0.24676211178302765 w 176.68656709287492 h 133.67144585942773 new_H 133 new_W 176\n",
      "[Detection {class_label = cat, object_id = None, x = 707.858361536353, y = 431.72515498481783, w = 212.49516792657727, h = 151.77501387087761, confidence = 0.9587690830230713}, Detection {class_label = cat, object_id = None, x = 434.2932817508013, y = 614.8613861125169, w = 157.4282322110113, h = 129.09125192413126, confidence = 0.9521913528442383}, Detection {class_label = cat, object_id = None, x = 1869.231886808367, y = 1156.4738186361337, w = 144.11234422444332, h = 163.6053649655238, confidence = 0.9212594032287598}, Detection {class_label = cat, object_id = None, x = 1559.91891763664, y = 316.4856915802126, w = 189.9148952468687, h = 109.87132207584767, confidence = 0.9009707570075989}, Detection {class_label = cat, object_id = None, x = 940.858720004639, y = 76.32354266826924, w = 180.99969573027371, h = 141.43170932043904, confidence = 0.7761902213096619}, Detection {class_label = cat, object_id = None, x = 679.071062384025, y = 648.268221259278, w = 189.47857970779563, h = 147.27657541540148, confidence = 0.7478073239326477}, Detection {class_label = cat, object_id = None, x = 1580.416455802969, y = 1394.7948164431511, w = 378.8677515603914, h = 99.88583114562248, confidence = 0.5314728021621704}, Detection {class_label = cat, object_id = None, x = 161.76543719951925, y = 52.28967005102902, w = 152.7206808854694, h = 165.32617335763538, confidence = 0.518130362033844}, Detection {class_label = cat, object_id = None, x = 15.659616653092318, y = 780.5193836454116, w = 53.25532694416329, h = 356.32822647815453, confidence = 0.39415690302848816}, Detection {class_label = cat, object_id = None, x = 2.7696913746204457, y = 852.7342774755399, w = 51.7460650857161, h = 220.4323990753627, confidence = 0.3305419981479645}, Detection {class_label = cat, object_id = None, x = -4.345150184373946, y = 333.39473420630907, w = 89.48292786550587, h = 371.739251552484, confidence = 0.28499385714530945}]\n",
      "x 707 y 431 cat 0.9587690830230713 w 212.49516792657727 h 151.77501387087761 new_H 151 new_W 212\n",
      "x 434 y 614 cat 0.9521913528442383 w 157.4282322110113 h 129.09125192413126 new_H 129 new_W 157\n",
      "x 1869 y 1156 cat 0.9212594032287598 w 144.11234422444332 h 163.6053649655238 new_H 163 new_W 144\n",
      "x 1559 y 316 cat 0.9009707570075989 w 189.9148952468687 h 109.87132207584767 new_H 109 new_W 189\n",
      "x 940 y 76 cat 0.7761902213096619 w 180.99969573027371 h 141.43170932043904 new_H 141 new_W 180\n",
      "x 679 y 648 cat 0.7478073239326477 w 189.47857970779563 h 147.27657541540148 new_H 147 new_W 189\n",
      "x 1580 y 1394 cat 0.5314728021621704 w 378.8677515603914 h 99.88583114562248 new_H 86 new_W 378\n",
      "x 161 y 52 cat 0.518130362033844 w 152.7206808854694 h 165.32617335763538 new_H 165 new_W 152\n",
      "x 15 y 780 cat 0.39415690302848816 w 53.25532694416329 h 356.32822647815453 new_H 356 new_W 53\n",
      "x 2 y 852 cat 0.3305419981479645 w 51.7460650857161 h 220.4323990753627 new_H 220 new_W 51\n",
      "x -4 y 333 cat 0.28499385714530945 w 89.48292786550587 h 371.739251552484 new_H 371 new_W 85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detection {class_label = cat, object_id = None, x = 2042.3184147267207, y = 958.8717869644063, w = 216.85885690130527, h = 142.98472506668566, confidence = 0.9016116261482239}, Detection {class_label = cat, object_id = None, x = 1572.4131122954623, y = 395.121605094467, w = 163.32358055783993, h = 165.3698361457279, confidence = 0.849159300327301}, Detection {class_label = cat, object_id = None, x = 1071.0174002087551, y = 804.8678886217949, w = 154.01738109923247, h = 142.49097766953443, confidence = 0.7545015811920166}, Detection {class_label = cat, object_id = None, x = 1011.7928040127363, y = 1259.9295609817814, w = 195.50546301714323, h = 175.7953646887652, confidence = 0.6789085268974304}, Detection {class_label = cat, object_id = None, x = 540.6559897151232, y = 561.4771660973347, w = 136.2784201432819, h = 140.39741530527792, confidence = 0.6055877804756165}, Detection {class_label = cat, object_id = None, x = 174.183043033327, y = 65.18178822958839, w = 106.04076160013918, h = 135.7955136112517, confidence = 0.41436517238616943}, Detection {class_label = cat, object_id = None, x = 1052.122592200152, y = 1285.4912017122133, w = 121.70185536990765, h = 109.76939451807102, confidence = 0.2246658354997635}]\n",
      "x 2042 y 958 cat 0.9016116261482239 w 216.85885690130527 h 142.98472506668566 new_H 142 new_W 216\n",
      "x 1572 y 395 cat 0.849159300327301 w 163.32358055783993 h 165.3698361457279 new_H 165 new_W 163\n",
      "x 1071 y 804 cat 0.7545015811920166 w 154.01738109923247 h 142.49097766953443 new_H 142 new_W 154\n",
      "x 1011 y 1259 cat 0.6789085268974304 w 195.50546301714323 h 175.7953646887652 new_H 175 new_W 195\n",
      "x 540 y 561 cat 0.6055877804756165 w 136.2784201432819 h 140.39741530527792 new_H 140 new_W 136\n",
      "x 174 y 65 cat 0.41436517238616943 w 106.04076160013918 h 135.7955136112517 new_H 135 new_W 106\n",
      "x 1052 y 1285 cat 0.2246658354997635 w 121.70185536990765 h 109.76939451807102 new_H 109 new_W 121\n",
      "[Detection {class_label = cat, object_id = None, x = 433.365209993885, y = 616.3248118041498, w = 158.4434473446989, h = 129.64253529331143, confidence = 0.952037513256073}, Detection {class_label = cat, object_id = None, x = 708.8660284086117, y = 430.911192117915, w = 198.54583764944965, h = 154.4677520216557, confidence = 0.9460753798484802}, Detection {class_label = cat, object_id = None, x = 1866.0655733383942, y = 1165.4126259910595, w = 133.09950888526907, h = 141.3560184782494, confidence = 0.9262139201164246}, Detection {class_label = cat, object_id = None, x = 677.4025322094299, y = 653.280475075911, w = 191.05090859190494, h = 146.795347720827, confidence = 0.9177709221839905}, Detection {class_label = cat, object_id = None, x = 1587.7409763516364, y = 1320.6715138959178, w = 316.4425363476299, h = 164.07566069527033, confidence = 0.8321356773376465}, Detection {class_label = cat, object_id = None, x = 1562.4790796853915, y = 295.03124209261136, w = 186.64064163846365, h = 133.40989860091938, confidence = 0.8313180804252625}, Detection {class_label = cat, object_id = None, x = 1069.7387767796897, y = 823.9290707236843, w = 150.70528206973265, h = 148.71010738892755, confidence = 0.8241329789161682}, Detection {class_label = cat, object_id = None, x = 923.6113070386303, y = 66.27165306595816, w = 197.8916376399608, h = 162.89158574772267, confidence = 0.7926746606826782}, Detection {class_label = cat, object_id = None, x = 1009.5186429866735, y = 1231.9364430457154, w = 235.86403871193912, h = 233.23932601372724, confidence = 0.6880461573600769}, Detection {class_label = cat, object_id = None, x = 6.412596214798942, y = 862.5590945512821, w = 55.2770376681638, h = 199.77292467289772, confidence = 0.5763947367668152}, Detection {class_label = cat, object_id = None, x = 1149.1539832152498, y = 291.86638621794873, w = 162.30495569226554, h = 112.84368426983174, confidence = 0.49143150448799133}, Detection {class_label = cat, object_id = None, x = 175.48574281350162, y = 49.93804824561404, w = 120.188077568847, h = 172.14840916519063, confidence = 0.4449312686920166}]\n",
      "x 433 y 616 cat 0.952037513256073 w 158.4434473446989 h 129.64253529331143 new_H 129 new_W 158\n",
      "x 708 y 430 cat 0.9460753798484802 w 198.54583764944965 h 154.4677520216557 new_H 154 new_W 198\n",
      "x 1866 y 1165 cat 0.9262139201164246 w 133.09950888526907 h 141.3560184782494 new_H 141 new_W 133\n",
      "x 677 y 653 cat 0.9177709221839905 w 191.05090859190494 h 146.795347720827 new_H 146 new_W 191\n",
      "x 1587 y 1320 cat 0.8321356773376465 w 316.4425363476299 h 164.07566069527033 new_H 160 new_W 316\n",
      "x 1562 y 295 cat 0.8313180804252625 w 186.64064163846365 h 133.40989860091938 new_H 133 new_W 186\n",
      "x 1069 y 823 cat 0.8241329789161682 w 150.70528206973265 h 148.71010738892755 new_H 148 new_W 150\n",
      "x 923 y 66 cat 0.7926746606826782 w 197.8916376399608 h 162.89158574772267 new_H 162 new_W 197\n",
      "x 1009 y 1231 cat 0.6880461573600769 w 235.86403871193912 h 233.23932601372724 new_H 233 new_W 235\n",
      "x 6 y 862 cat 0.5763947367668152 w 55.2770376681638 h 199.77292467289772 new_H 199 new_W 55\n",
      "x 1149 y 291 cat 0.49143150448799133 w 162.30495569226554 h 112.84368426983174 new_H 112 new_W 162\n",
      "x 175 y 49 cat 0.4449312686920166 w 120.188077568847 h 172.14840916519063 new_H 172 new_W 120\n",
      "Total Time is 64.43768835067749\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#work\n",
    "#path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline3\"\n",
    "\n",
    "#home\n",
    "#path = f\"C:{os.sep}Users{os.sep}William{os.sep}Documents{os.sep}Baseline\"\n",
    "\n",
    "#analysis\n",
    "#path = f\"D:{os.sep}William{os.sep}2018-12-04 Test data from 08-3\"\n",
    "\n",
    "\n",
    "dataframes = []\n",
    "dfs = Parameters.iterate_through_files()\n",
    "\n",
    "\n",
    "for index, items in enumerate(dfs):\n",
    "    save_path = f'{data_path}{os.sep}{index}.pkl'\n",
    "    items['Total'].to_pickle(save_path)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "print (f\"Total Time is {end_time - start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Organize and output the dataframes to excel files\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sub_dataframe = dfs[0][\"Total\"]\n",
    "columns = sub_dataframe.columns\n",
    "sub_dataframe.loc[:, pd.IndexSlice[1,0,:]].mean()\n",
    "\n",
    "#work\n",
    "writer = pd.ExcelWriter(\"D:/Documents/Documents/0000 New Scope/Baseline3/test.xlsx\", engine='xlsxwriter')\n",
    "\n",
    "#home\n",
    "#writer = pd.ExcelWriter(\"C:{os.sep}Users{os.sep}William{os.sep}Documents{os.sep}Baseline{os.sep}test.xlsx\", engine='xlsxwriter')\n",
    "#print (sub_dataframe)\n",
    "\n",
    "sub_dataframe.to_excel(writer, \"Raw_Data\")\n",
    "create_summary_columns(sub_dataframe).to_excel(writer, \"Summary\")\n",
    "\n",
    "cell_cell_comparison = create_cell_comparisons(sub_dataframe, Parameters)\n",
    "for key in cell_cell_comparison:\n",
    "    cell_cell_comparison[key].to_excel(writer, key)\n",
    "\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Cells beyond this point are not part of the main program...\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagingParameters():\n",
    "    #Note: the input to __init__ may be replaced by just the config file path\n",
    "    def __init__(self, data_path,\n",
    "                 numerical_aperture=None, \n",
    "                 index_of_refraction=None, \n",
    "                 magnification = None, \n",
    "                 gFactor = None, \n",
    "                 channel_array = [1], \n",
    "                 image_type_array = ['Intensity'], \n",
    "                 channel_thresholds = 0, \n",
    "                 timepoints = 1, \n",
    "                 same_cells = False, \n",
    "                 max_filter_region = 5,\n",
    "                 max_threshold =  600,\n",
    "                 root_dir_same_treatment = True, \n",
    "                 suffix = \"ome.tif\", \n",
    "                 machine_learning_mode = False, \n",
    "                 debug_mode = False,\n",
    "                 weights_path = \"final.pt\"):\n",
    "        \n",
    "        \n",
    "\n",
    "        #    for key, value in **kwargs.iteritems():\n",
    "        #        setattr(self, key, value)\n",
    "        \n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.numerical_aperture = numerical_aperture\n",
    "        self.index_of_refraction = index_of_refraction\n",
    "        self.magnification = magnification\n",
    "        self.gFactor = gFactor\n",
    "        self.channel_array = channel_array\n",
    "        self.image_type_array = image_type_array\n",
    "        self.max_filter_region = max_filter_region\n",
    "        self.max_threhsold = max_threshold\n",
    "        self.root_dir_same_treatment = root_dir_same_treatment\n",
    "        self.suffix = suffix\n",
    "        self.channel_thresholds = channel_thresholds\n",
    "        self.machine_learning_mode = machine_learning_mode\n",
    "        self.debug_mode = debug_mode\n",
    "        \n",
    "        \n",
    "        self.weights_path = weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create_cell_comparisons(sub_dataframe, Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"D://Documents//Documents//0000 New Scope//Baseline3//Treat1//Baseline_1//Baseline_1_MMStack_1-Pos_000_003.ome.tif\"\n",
    "image = np.asarray(bioformats.load_image(image_path))\n",
    "image = np.dstack([image, image*0.9, image*0.8])\n",
    "print (\"Max 1\", np.amax(image))\n",
    "image = ((image/np.amax(image))*255).astype('uint8')\n",
    "print (\"Max 2\", np.amax(image))\n",
    "#print (image)\n",
    "image2 = cv2.rectangle(image, (200,0), (400, 1000), (255,0,0), 20)\n",
    "plt.imshow(image2)\n",
    "\n",
    "save_path = \"D://Documents//Documents//0000 New Scope//Baseline3//debug//Treat1//Baseline_1//Baseline_1_MMStack_1-Pos_000_003.jpg\"\n",
    "\n",
    "\n",
    "imageio.imwrite(save_path, image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (dfs[3])\n",
    "for items in dfs:\n",
    "    for keys in items:\n",
    "        print (type(items[keys]), keys)\n",
    "        #items[keys].pop(\"ROI\")\n",
    "        items[keys].to_csv(\"D:/Documents/Documents/0000 New Scope/Baseline3/test.csv\")\n",
    "\n",
    "\n",
    "\"\"\"final_dataframe = pd.DataFrame([])\n",
    "\n",
    "for filenames in dfs[-1]:\n",
    "    print (f\"current filename is: {filenames}\")\n",
    "    df_interest = dfs[-1][filenames]\n",
    "    print (type(df_interest))\n",
    "    #print (df_interest)\n",
    "    if len(final_dataframe)==0:\n",
    "        print (\"need a new dataframe\")\n",
    "        final_dataframe = df_interest\n",
    "    else:\n",
    "        print (\"Appending\")\n",
    "        final_dataframe = final_dataframe.append(df_interest, ignore_index = True, sort = False)\n",
    "\n",
    "print (final_dataframe)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.ones((5,6))\n",
    "array = np.pad(array, ((2,3), (0,1)), 'constant')\n",
    "print (array)\n",
    "print (array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([], columns=[\"Image\", \"Index\", \"ROI\"])\n",
    "df.head()\n",
    "\n",
    "imparameters = ImageParams(f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline{os.sep}Baseline_1\",\n",
    "                         \"Baseline_1_MMStack_1-Pos_002_002.ome.tif\", Parameters.channel_array, Parameters.image_type_array)\n",
    "\n",
    "df2 = pd.DataFrame({\"Image\": [imparameters, 2], \"ROI\": [3,4]})\n",
    "df3 = df.append(df2, sort=False)\n",
    "df3.head()\n",
    "\n",
    "print (df3.at[0, \"Image\"])\n",
    "\n",
    "#for index, items in enumerate(df3[\"Image\"]):\n",
    "#    print (index, items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array = []\n",
    "array.append({\"array\": 1})\n",
    "print (\"array\" in array[-1])\n",
    "array.append([2,3])\n",
    "print (array[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example full program::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline_1\"\n",
    "dir_list = find_files(path)\n",
    "iterate_through_files (dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff  = pd.DataFrame({(\"A\", \"B\"): [1,2,3], (\"A\", \"C\"): [2,5,6], (\"G\"):[1,2,3]})\n",
    "dff.at[2, (\"A\", \"B\")]= 100\n",
    "for columns in dff.columns:\n",
    "    print (columns[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1, 2, 3, 43, 6, 5])\n",
    "arr2 = np.array([True, True, True, False, False, True])\n",
    "arr4 = arr1[:4].copy()\n",
    "arr3 = np.multiply (arr1, arr2)\n",
    "print (arr3)\n",
    "print (np.mean(arr3[arr3 !=0]))\n",
    "\n",
    "print (arr4)\n",
    "arr4[2] = 100\n",
    "print (arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = \"D:/Documents/Documents/0000 New Scope/Baseline3/Treat1/Baseline_1/Baseline_1_MMStack_1-Pos_000_003.ome.tif\"\n",
    "\n",
    "import_image = np.asarray(bioformats.load_image(new_path, t=0, rescale = False)).astype('float')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_image = import_image.copy()\n",
    "\n",
    "new_image [new_image <  10000] = np.nan\n",
    "\n",
    "plt.imshow(new_image)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "\n",
    "fgmask = fgbg.apply(import_image)\n",
    "cv2.imshow('frame',fgmask)\n",
    "k = cv2.waitKey(30) & 0xff\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BF Matcher\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "bio_loc = f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_002_002.ome.tif'\n",
    "\n",
    "bio_para_import = np.asarray(bioformats.load_image(bio_loc, \n",
    "                                          c = 0, z=0, t=1, rescale=False))\n",
    "\n",
    "bio_perp_import = np.asarray(bioformats.load_image(bio_loc, \n",
    "                                          c = 0, z=0, t=2, rescale=False))\n",
    "\n",
    "bio_para = skimage.img_as_ubyte(bio_para_import)\n",
    "bio_perp = skimage.img_as_ubyte(bio_perp_import)\n",
    "\n",
    "filtered_para = cv2.bilateralFilter(bio_para, 9, 75, 75)\n",
    "\n",
    "print (type(bio_para[0,0]))\n",
    "print(cv2.imread(bio_loc, 0).shape)\n",
    "#bio_para = cv2.imread(bio_loc, 0)\n",
    "\n",
    "#bio_perp = cv2.imread(bio_loc, 0)\n",
    "\n",
    "print (type(bio_para[0,0]))\n",
    "\n",
    "b = cv2.normalize(bio_para_import, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n",
    "\n",
    "\n",
    "\n",
    "print (bio_para.shape)\n",
    "print (bio_para[:4,:4], bio_perp[:4, :4])\n",
    "print (b[:4,:4])\n",
    "print(type(b[0,0]))\n",
    "\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "kp1, des1 = orb.detectAndCompute(bio_para, None)\n",
    "kp2, des2 = orb.detectAndCompute(bio_perp, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "\n",
    "matches = bf.match(des1, des2)\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "\n",
    "img3 = cv2.drawMatches(bio_para, kp1, bio_perp, kp2, matches[:10], None, flags = 2)\n",
    "cv2.imshow(\"Matches\", img3)\n",
    "#plt.imshow(bio_para)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#fig, axs = plt.subpolots(1, 1)\n",
    "#axs = plt.hist(bio_para)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "cv2.imshow(\"Para\", bio_para)\n",
    "cv2.imshow(\"Bilateral\", filtered_para)\n",
    "cv2.imshow(\"Perp\", bio_perp)\n",
    "cv2.imshow(\"Difference\", (bio_para - bio_perp)*100)\n",
    "cv2.imshow(\"Normalizes\", b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#print (bioformats.get_omexml_metadata(path=f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_001.ome.tif'))\n",
    "\n",
    "\n",
    "print (kp1, des1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,2,3,4], [5,6,7,8], 'ro')\n",
    "plt.axis([0,10,0,20])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bio_para_reshape = bio_para_import.reshape(-1, 1)\n",
    "print (bio_para_reshape.shape)\n",
    "bio_para_reshape2 = filtered_para.reshape(-1, 1)\n",
    "\n",
    "x = 100+ 15*np.random.randn(10000)\n",
    "#n, bins, patches = plt.hist(bio_para_reshape, 50)\n",
    "n, bins, patches = plt.hist(bio_para_reshape2, 50)\n",
    "print (max(bio_para_reshape2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def find_maxima (image, sigma = 9, h_value = None):\n",
    "    \n",
    "    if not h_value:\n",
    "        h_value = max(image)/1000\n",
    "              \n",
    "    \n",
    "    proc_image = cv2.GaussianBlur(img, (sigma, sigma), 0)\n",
    "    \n",
    "    local_maxima = extrema.h_maxima(proc_image, h_value)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (local_maxima)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "local_maximums = find_maxima(bio_para_import, 1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize= (15,5))\n",
    "\n",
    "ax[0].imshow(bio_para_import)\n",
    "\n",
    "ax[1].imshow(local_maximums)\n",
    "\n",
    "print (find_maxima(bio_para_import, 1, 1))\n",
    "\n",
    "x = np.arange(bio_para_import.shape[1])\n",
    "y = np.arange(bio_para_import.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "#x, y = np.meshgrid(x, y)\n",
    "#ax[2].scatter(x, y, c=local_maximums[x,y])\n",
    "#ax[2].show()\n",
    "\n",
    "plt.imshow(find_maxima(bio_para_import, 1, 50))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "xy = peak_local_max(bio_para_import, min_distance=5,threshold_abs=1200)\n",
    "plt.scatter(xy[:, 0], xy[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "y = np.arange(16)\n",
    "test_data = np.random.randint(low=0,high=65535, size=(10, 16))\n",
    "\n",
    "#scatter plot the measurements with\n",
    "# x - measurement index (0-9 in this case)\n",
    "# y - byte value index (0-15 in this case) \n",
    "# c = test_data[x,y]\n",
    "\n",
    "x, y = np.meshgrid(x,y)\n",
    "plt.scatter(x,y,c=test_data[x,y])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline_1\"\n",
    "\n",
    "print (os.listdir(data_path)[4])\n",
    "print (f'{data_path}{os.sep}{os.listdir(data_path)[4]}')\n",
    "\n",
    "img = cv2.imread(f'{data_path}{os.sep}{os.listdir(data_path)[4]}')*100\n",
    "#cv2.imshow(\"image\", (img[:,:,1]*1000))\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "cv2.circle(img, (2000,1000), 400, (255,255,255), -1)\n",
    "points = np.array([[1,1], [33,4], [100,20], [50, 400]], np.int32)\n",
    "cv2.polylines(img, [points], True, (0,255,255), 3)\n",
    "cv2.putText(img, \"Hello, world!\", (0,100), cv2.FONT_HERSHEY_COMPLEX, 4, (255, 0, 0))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "#img = np.ones((100,100,3))*1\n",
    "#img[:,:,2] = np.arange(0, 100*100, 1).resize((100,100))\n",
    "print (img[:,:,2])\n",
    "\n",
    "gg = calculate_anisotropy(image = img, Parameters = Parameters)\n",
    "\n",
    "\n",
    "print (gg.shape)\n",
    "cv2.imwrite(f'{path}{os.sep}{os.listdir(path)[7]}2.tiff', gg)\n",
    "\n",
    "#print (sum(sum(img-gg)))\n",
    "\n",
    "#cv2.imshow(\"image\", (img-gg)*1000)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Thresholding options\n",
    "Works Well\n",
    "\n",
    "from skimage.feature import peak_local_max\n",
    "xy = peak_local_max(bio_para_import, min_distance=2,threshold_abs=1500)\n",
    "plt.scatter(xy[:, 0], xy[:, 1])\n",
    "\n",
    "\n",
    "Works Better:\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fname = '/tmp/slice0000.png'\n",
    "neighborhood_size = 40\n",
    "threshold = 700\n",
    "\n",
    "\n",
    "data = bio_para_import\n",
    "#data = scipy.misc.imread(fname)\n",
    "\n",
    "data_max = filters.maximum_filter(data, neighborhood_size)\n",
    "maxima = (data == data_max)\n",
    "data_min = filters.minimum_filter(data, neighborhood_size)\n",
    "diff = ((data_max - data_min) > threshold)\n",
    "maxima[diff == 0] = 0\n",
    "\n",
    "labeled, num_objects = ndimage.label(maxima)\n",
    "slices = ndimage.find_objects(labeled)\n",
    "x, y = [], []\n",
    "for dy,dx in slices:\n",
    "    x_center = (dx.start + dx.stop - 1)/2\n",
    "    x.append(x_center)\n",
    "    y_center = (dy.start + dy.stop - 1)/2    \n",
    "    y.append(y_center)\n",
    "\n",
    "plt.imshow(data)\n",
    "#plt.savefig('/tmp/data.png', bbox_inches = 'tight')\n",
    "\n",
    "plt.autoscale(False)\n",
    "plt.plot(x,y, 'ro')\n",
    "#plt.savefig('/tmp/result.png', bbox_inches = 'tight')\n",
    "\n",
    "print (x, y)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all of the files in the current path\n",
    "print(os.path.isdir(path))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"for items in os.listdir(path):\n",
    "    #print (items, \"file:\",  os.path.isfile(f\"{path}/{items}\"), \"dir:\",  os.path.isdir(f'{path}/{items}'))\n",
    "    img = cv2.imread(f'{path}/{items}')\n",
    "    cv2.imshow('image', img*100)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Options for going up ap directory:\n",
    "\n",
    "1) split path by \"/\" __file__.rsplit(os.sep, 2)  or print(path.rsplit('/')[-3])\n",
    "2) iterate up twice os.path.dirname(os.path.dirname(path))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing the find_files function\n",
    "\"\"\"\n",
    "\n",
    "path2 = \"D:\\\\Documents\\\\Documents\\\\0000 New Scope\\\\2018-08-01 Nuclear Parameter Test\"\n",
    "#path2 = \"D:/Documents/Documents/0000 New Scope/2018-08-01 Nuclear Parameter Test/N2(600-40)/Baseline/Baseline_1\"\n",
    "dir_list = {}\n",
    "result = find_files(path2, dir_list)\n",
    "\n",
    "\n",
    "for items in result:\n",
    "    print (f'{items}, {result[items]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"D:{os.sep}Documents{os.sep}Documents{os.sep}0000 New Scope{os.sep}Baseline_1\"\n",
    "print (data_path)\n",
    "directory_list = find_files(data_path, {})\n",
    "print (directory_list)\n",
    "iterate_through_files(directory_list)\n",
    "\n",
    "\n",
    "bio_im = np.asarray(bioformats.load_image(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_001.ome.tif', \n",
    "                                          c = 0, z=0, t=6, rescale=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "img=mpimg.imread(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_000.ome.tif')\n",
    "print (img.shape)\n",
    "\n",
    "im = io.imread(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_000.ome.tif')\n",
    "print ((im.shape))\n",
    "\n",
    "pilim = Image.open(f'{data_path}{os.sep}Baseline_1_MMStack_1-Pos_000_000.ome.tif')\n",
    "print (pilim.n_frames)\n",
    "print (pilim)\n",
    "print (pilim.info)\n",
    "print (pilim.load())\n",
    "pilim.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
